[
["index.html", "The Examples Book Introduction How to contribute", " The Examples Book Introduction Click here for video This book contains a collection of examples that students can use to reinforce topics learned in The Data Mine seminar. It is an excellent resource for students to learn what they need to know in order to solve The Data Mine projects. How to contribute Contributing to this book is simple: Small changes and additions If you have a small change or addition you'd like to make to the book, the easiest way to quickly contribute would be the following method. Navigate to the page or section that needs to be edited Click on the &quot;Edit&quot; button towards the upper left side of the page: You'll be presented with the respective RMarkdown file. Make your modifications. In the &quot;Commit changes&quot; box, select the radio button that says Create a new branch for this commit and start a pull request. Give your pull request a title and a detailed description. Name the new branch, and click on &quot;Propose file change&quot;. You've successfully submitted a pull request. Our team will review and merge the request shortly thereafter. Larger changes or additions If you have larger changes or additions you'd like to make to the book, the easiest way is to edit the contents of the book on your local machine. Using git in the terminal Setup git following the directions here. Start by opening up a terminal and configuring git to work with GitHub. Navigate to the directory in which you would like to clone the-examples-book repository. For example, if I wanted to clone the repository in my ~/projects folder, I'd first execute: cd ~/projects. Clone the repository. In this example, let's assume I've cloned the repository into my ~/projects folder. Navigate into the project folder: cd ~/projects/the-examples-book At this point in time your current branch should be the master branch. You can verify by running: git branch Note: The highlighted branch starting with &quot;*&quot; is the current branch. or if you'd like just the name of the branch: git rev-parse --abbrev-ref HEAD Create a new branch with whatever name you'd like, and check that branch out. For example, fix-spelling-errors-01. Open up RStudio. In the &quot;Files&quot; tab in RStudio, navigate to the repository. In this example, we would navigate to /Users/kamstut/Documents/GitHub/the-examples-book. Click on the &quot;More&quot; dropdown and select &quot;Set As Working Directory&quot;. If you do not already have renv installed, install it by running the following commands in the console: install.packages(&quot;renv&quot;) Restore the environment by running the following commands in the console: renv::restore() In order to compile this book, you must have LaTeX installed. The easiest way to accomplish this is to run the following in the R console: install.packages(&quot;tinytex&quot;) library(tinytex) tinytex::install_tinytex() In addition, make sure to install both pandoc and pandoc-citeproc by following the instructions here. Modify the .Rmd files to your liking. Click the &quot;Knit&quot; button to compile the book. The resulting &quot;book&quot; is within the &quot;docs&quot; folder. Important note: If at any point in time you receive an error saying something similar to &quot;there is no package called my_package, simply install the missing package, and try to knit again: install.packages(&quot;my_package&quot;) library(my_package) To test the book out, navigate to the &quot;docs&quot; folder and open the index.html in the browser of your choice. When you are happy with the modifications you've made, commit your changes to the repository. You can continue to make modifications and commit your changes locally. When you are ready, you can push your branch to the remote repository (github.com). At this point in time, you can confirm that the branch has been succesfully pushed to github.com by navigating to the repository on github, and click on the &quot;branches&quot; tab: Next, create a pull request. Note that a &quot;Pull Request&quot; is a GitHub-specific concept. You cannot create a pull request using git. Navigate to the repository https://github.com/thedatamine/the-examples-book, and you should see a message asking if you'd like to create a pull request: Leave a detailed comment about what you've modified or added to the book. You can click on &quot;Preview&quot; to see what your comment will look like. GitHub's markdown applies here. Once satisfied, click &quot;Create pull request&quot;. At this point in time, the repository owners will receive a notification and will check and potentially merge the changes into the master branch. Using GitHub Desktop Setup GitHub Desktop following the directions here. When you are presented with the following screen, select &quot;Clone a Repository from the Internet...&quot;: 3. Click on the &quot;URL&quot; tab: In the first field, enter &quot;TheDataMine/the-examples-book&quot;. This is the repository for this book. In the second field, enter the location in which you'd like the repository to be cloned to. In this example, the repository will be cloned into /Users/kamstut/Documents/GitHub. The result will be a new folder called the-examples-book in /Users/kamstut/Documents/GitHub. Click &quot;Clone&quot;. Upon completion, you will be presented with a screen similar to this: At this point in time, your current branch will be the master branch. Create a new branch with whatever name you'd like. For example, fix-spelling-errors-01. Open up RStudio. In the &quot;Files&quot; tab in RStudio, navigate to the repository. In this example, we would navigate to /Users/kamstut/Documents/GitHub/the-examples-book. Click on the &quot;More&quot; dropdown and select &quot;Set As Working Directory&quot;. If you do not already have renv installed, install it by running the following commands in the console: install.packages(&quot;renv&quot;) Restore the environment by running the following commands in the console: renv::restore() In order to compile this book, you must have LaTeX installed. The easiest way to accomplish this is to run the following in the R console: install.packages(&quot;tinytex&quot;) library(tinytex) tinytex::install_tinytex() In addition, make sure to install both pandoc and pandoc-citeproc by following the instructions here. Modify the .Rmd files to your liking. Click the &quot;Knit&quot; button to compile the book. The resulting &quot;book&quot; is within the &quot;docs&quot; folder. Important note: If at any point in time you receive an error saying something similar to &quot;there is no package called my_package, simply install the missing package, and try to knit again: install.packages(&quot;my_package&quot;) library(my_package) To test the book out, navigate to the &quot;docs&quot; folder and open the index.html in the browser of your choice. When you are happy with the modifications you've made, commit your changes to the repository. You can continue to make modifications and commit your changes locally. When you are ready, you can publish your branch: Upon publishing your branch, within GitHub Desktop, you'll be presented with the option to create a pull request: At this point in time, the repository owners will receive a notification and will check and potentially merge the changes into the master branch. "],
["scholar.html", "Scholar Connecting to Scholar Other ways to connect Resources", " Scholar Connecting to Scholar There are a variety of ways to connect to Scholar; however, the primary method (and maybe the only method) we will use this semester is RStudio Server Pro. To see how one may approach solving a project this semester, watch Dr. Ward connect to RStudio Server Pro and demonstrate how to compile a project here. RStudio Server Pro Getting started with Scholar and RStudio: part I Getting started with Scholar and RStudio: part II Open a browser and navigate to https://rstudio.scholar.rcac.purdue.edu/. Enter your Purdue Career Account credentials (using BoilerKey, namely, your 4 digit code, then a comma, and then a BoilerKey numerical sequence). Congratulations, you should now be able to create and run R scripts on Scholar! Other ways to connect These are some other ways to connect to Scholar. Please feel free to explore; however, note that, at this time, there is no real reason to connect using these methods. You are encouraged to use RStudio Server Pro, and go through the video provided here to get started. ThinLinc web client Open a browser and navigating to https://desktop.scholar.rcac.purdue.edu/. Login with your Purdue Career Account credentials (using BoilerKey, namely, your 4 digit code, then a comma, and then a Boilerkey numerical sequence). Congratulations, you should now be connected to Scholar using the ThinLinc web client. ThinLinc client Navigate to https://www.cendio.com/thinlinc/download, and download the ThinLinc client application for your operating system. Install and launch the ThinLinc client: Enter your Purdue Career Account information (using BoilerKey, namely, your 4 digit code, then a comma, and then a Boilerkey numerical sequence), as well as the server: desktop.scholar.rcac.purdue.edu. Click on &quot;Options...&quot; and fill out the &quot;Screen&quot; tab as shown below: Click &quot;OK&quot; and then &quot;Connect&quot;. Make sure you are connected to Purdue's VPN using AnyConnect before clicking &quot;Connect&quot;! If you are presented with a choice like below, click &quot;Continue&quot;. Congratulations, you are now successfully connected to Scholar using the ThinLinc client. NOTE: If you do accidentally get stuck in full screen mode, the F8 key will help you to escape. NOTE: The very first time that you log onto Scholar, you will have an option of “use default config” or “one empty panel”. PLEASE choose the “use default config”. SSH Windows MacOS Linux JupyterHub Open a browser and navigate to https://notebook.scholar.rcac.purdue.edu/. Enter your Purdue Career Account credentials (using BoilerKey, namely, your 4 digit code, then a comma, and then a Boilerkey numerical sequence). Congratulations, you should now be able to create and run Jupyter notebooks on Scholar! Resources "],
["data-formats.html", "Data Formats HTML XML", " Data Formats HTML HTML stands for Hypertext Markup Language. It is the standard language of the web intended to be displayed using web browsers like Firefox, Chrome, and Edge. The following is a good example of an HTML document with examples of many basic HTML elements: &lt;!doctype html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;HTML5 Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;top&quot; class=&quot;page&quot; role=&quot;document&quot;&gt; &lt;header role=&quot;banner&quot;&gt; &lt;h1&gt;HTML5 Example&lt;/h1&gt; &lt;p&gt;This is an example page full of HTML.&lt;/p&gt; &lt;/header&gt; &lt;nav role=&quot;nav&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;a href=&quot;#tech&quot; class=&quot;big title&quot; custom-attr=&quot;ok&quot;&gt;Tech&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://google.com&quot;&gt;Google&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cloudflare.com&quot;&gt;Cloudflare&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://microsoft.com&quot;&gt;Microsoft&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;#news&quot; data-news=&quot;true&quot;&gt;News&lt;/a&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://nytimes.com&quot;&gt;NYTimes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://washingtonpost.com&quot;&gt;WAPO&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/nav&gt; &lt;main&gt; &lt;section id=&quot;headings&quot;&gt; &lt;div&gt; &lt;h1&gt;Heading 1&lt;/h1&gt; &lt;h2&gt;Heading 2&lt;/h2&gt; &lt;h3&gt;Heading 3&lt;/h3&gt; &lt;h4&gt;Heading 4&lt;/h4&gt; &lt;h5&gt;Heading 5&lt;/h5&gt; &lt;h6&gt;Heading 6&lt;/h6&gt; &lt;/div&gt; &lt;/section&gt; &lt;section id=&quot;other&quot;&gt; &lt;p&gt;This is a paragraph.&lt;/p&gt; &lt;p&gt;This is another paragraph.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Ordered list 1&lt;/li&gt; &lt;li&gt;Ordered list 2&lt;/li&gt; &lt;li&gt;Ordered list 3&lt;/li&gt; &lt;/ol&gt; &lt;ul&gt; &lt;li&gt;Unordered list 1&lt;/li&gt; &lt;li&gt;Unordered list 2&lt;/li&gt; &lt;li&gt;Unordered list 3&lt;/li&gt; &lt;/ul&gt; &lt;/section&gt; &lt;h3&gt;Horizontal rule&lt;/h3&gt; &lt;hr&gt; &lt;h3&gt;Line break&lt;/h3&gt; &lt;br&gt; &lt;section id=&quot;table&quot;&gt; &lt;table&gt; &lt;caption&gt;Caption&lt;/caption&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Heading 1&lt;/th&gt; &lt;th&gt;Heading 2&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tfoot&gt; &lt;tr&gt; &lt;th&gt;Footer 1&lt;/th&gt; &lt;th&gt;Footer 2&lt;/th&gt; &lt;/tr&gt; &lt;/tfoot&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Cell 1&lt;/td&gt; &lt;td&gt;Cell 2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Cell 1&lt;/td&gt; &lt;td&gt;Cell 2&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/section&gt; &lt;section&gt; &lt;div&gt; &lt;p&gt;This is a paragraph with text that has been modified to appear &lt;strong&gt;strong&lt;/strong&gt;, &lt;em&gt;emphasized&lt;/em&gt;, &lt;b&gt;bold&lt;/b&gt;, &lt;i&gt;italicized&lt;/i&gt;, &lt;u&gt;underlined&lt;/u&gt;, &lt;s&gt;struckthrough&lt;/s&gt;, etc. &lt;/p&gt; &lt;/div&gt; &lt;/section&gt; &lt;/main&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; An HTML document is comprised of elements. An element is the combination of a start tag, content, and end tag. For example, the following is an element: &lt;title&gt;HTML5 Example&lt;/title&gt; In that example, &quot;&lt;title&gt;&quot; is the start tag, &quot;HTML5 Example&quot; is the content, and &quot;&lt;/title&gt;&quot; is the end tag. HTML elements can be nested. For example: &lt;section&gt; &lt;div&gt; &lt;p&gt;This is a paragraph with text that has been modified to appear &lt;strong&gt;strong&lt;/strong&gt;, &lt;em&gt;emphasized&lt;/em&gt;, &lt;b&gt;bold&lt;/b&gt;, &lt;i&gt;italicized&lt;/i&gt;, &lt;u&gt;underlined&lt;/u&gt;, &lt;s&gt;struckthrough&lt;/s&gt;, etc. &lt;/p&gt; &lt;/div&gt; &lt;/section&gt; This is an element where &quot;&lt;section&gt;&quot; is the start tag, &quot;&lt;/section&gt;&quot; is the end tag, and the rest: &lt;div&gt; &lt;p&gt;This is a paragraph with text that has been modified to appear &lt;strong&gt;strong&lt;/strong&gt;, &lt;em&gt;emphasized&lt;/em&gt;, &lt;b&gt;bold&lt;/b&gt;, &lt;i&gt;italicized&lt;/i&gt;, &lt;u&gt;underlined&lt;/u&gt;, &lt;s&gt;struckthrough&lt;/s&gt;, etc. &lt;/p&gt; &lt;/div&gt; is the content. The content in this example is a nested element, where the start tag is &quot;&lt;div&gt;&quot;, the end tag is &quot;&lt;/div&gt;&quot; and the content is: &lt;p&gt;This is a paragraph with text that has been modified to appear &lt;strong&gt;strong&lt;/strong&gt;, &lt;em&gt;emphasized&lt;/em&gt;, &lt;b&gt;bold&lt;/b&gt;, &lt;i&gt;italicized&lt;/i&gt;, &lt;u&gt;underlined&lt;/u&gt;, &lt;s&gt;struckthrough&lt;/s&gt;, etc. &lt;/p&gt; ... yet another nested element. HTML has a variety of different tags, each with a distinct purpose. Whether or not a website uses a specific tag for it's intended purpose is another story. Certain HTML tags are oft &quot;misused&quot; in modern web development. HTML tags can have attributes. Attributes are always shown in the start tag, and can come in both name=&quot;value&quot; pairs, like class=&quot;h1-strong&quot;: &lt;div class=&quot;h1-strong&quot;&gt; , or alone, like async: &lt;script src=&quot;my_script.js&quot; async&gt; There are a variety of valid html attributes. It is important to note that if an attribute in an HTML tag is not one of the official attributes, the browser will ignore it. With that being said, the &quot;unofficial&quot; attributes will still be a part of the Document Object Model (DOM), and therefore accessible to javascript. For this reason, it is not uncommon to come across technically &quot;invalid&quot; HTML attributes in website's source code. In HTML5, there now exists an HTML compliant version of these custom attributes called data-*. The * in data-* is a wildcard that can represent anything as long as it is at least 1 character long and contains no uppercase letters. You can see an example of a data-* attribute in our example, where we use data-news to store whether or not the link is news data: &lt;a href=&quot;#news&quot; data-news=&quot;true&quot;&gt;News&lt;/a&gt; Unless you have a very good reason to use a custom attribute that is not a data-* attribute, you would be well-advised to just use data-* when possible. XML XML stands for Extensible Markup Language. XML and HTML appear and sound very similar but have different goals. Whereas HTML was designed to display data, XML was designed to store data. Like HTML, XML still has start tags, end tags, and content, however, rather than using a finite set of legal tags, XML tags are defined and created by the user, so XML like the following is perfectly legal. &lt;exam&gt; &lt;question&gt; &lt;text&gt;What is red?&lt;/text&gt; &lt;solution&gt;A color.&lt;/solution&gt; &lt;points&gt;2&lt;/points&gt; &lt;/question&gt; &lt;question&gt; &lt;text&gt;What is a square?&lt;/text&gt; &lt;solution&gt;A shape.&lt;/solution&gt; &lt;points&gt;1&lt;/points&gt; &lt;/question&gt; &lt;/exam&gt; Rather than opening that content in a web browser and expecting it to do something like we would for HTML, in order for that, valid, XML to do anything, someone must write software to send, receive, store, display, or do something with the data. XPath Expressions Xpath Expressions are expressions created to select nodes or node-sets from an XML document. The following table (from w3schools) shows some of the most useful expressions that can be used to select nodes programmatically. Expression Description nodename Selects all nodes with the name &quot;nodename&quot; / Selects from the root node // Selects nodes in the document from the current node that match the selection no matter where they are . Selects the current node .. Selects the parent of the current node @ Selects attributes Predicates A predicate is a way to filter a node-set by evaluating the expression contained within a set of square brackets []. For example, let's say you wanted to get all of the questions that have points &gt; 1. Doing this using predicates is easy: &lt;exam&gt; &lt;question&gt; &lt;text&gt;What is red?&lt;/text&gt; &lt;solution&gt;A color.&lt;/solution&gt; &lt;points&gt;2&lt;/points&gt; &lt;/question&gt; &lt;question&gt; &lt;text&gt;What is a square?&lt;/text&gt; &lt;solution&gt;A shape.&lt;/solution&gt; &lt;points&gt;1&lt;/points&gt; &lt;/question&gt; &lt;/exam&gt; //question[points &gt; 1] Operators In order to make comparisons, we need operators. The following is a list of xpath operators from here. Operator Description Example | Computes two node-sets. //book | //cd + Addition 6 + 4 - Subtraction 6 - 4 * Multiplication 6 * 4 div Division 8 div 4 = Equal to (relation, not assignment) price = 9.80 != Not equal price != 9.80 &lt; Less than price &lt; 9.80 &lt;= Less than or equal to price &lt;= 9.80 &gt; Greater than price &gt; 9.80 &gt;= Greater than or equal to price &gt;= 9.80 or Logical or price = 9.80 or price = 9.70 and Logical and price &gt; 9.00 and price &lt; 10.00 mod Modulus (division remainder) 5 mod 2 Function xpath functions are an easy way to filter data with more control. You can find a list of functions here. Of particular use are the contains and translate functions. contains allows you to see if the first argument string contains the second argument string. It is particularly useful to see if a class or attribute contains some substring. translate allows you to, among other things, change the case of some text prior to using the contains function, for example. Examples Given the following XML, answer the questions. &lt;html&gt; &lt;head&gt; &lt;title&gt;My Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt; &lt;div class=&quot;abc123 sktoe-sldjkt dkjfg3-dlgsk&quot;&gt; &lt;div class=&quot;glkjr-slkd dkgj-0 dklfgj-00&quot;&gt; &lt;a class=&quot;slkdg43lk dlks&quot; href=&quot;https://example.com/123456&quot;&gt; &lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div class=&quot;ldskfg4&quot;&gt; &lt;span class=&quot;slktjoe&quot; aria-label=&quot;123 comments, 43 Retweets, 4000 likes&quot;&gt;Love it.&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;div data-amount=&quot;12&quot;&gt;13&lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div class=&quot;abc123 sktoe-sls dkjfg-dlgsk&quot;&gt; &lt;div class=&quot;glkj-slkd dkgj-0 dklfj-00&quot;&gt; &lt;a class=&quot;slkd3lk dls&quot; href=&quot;https://example.com/123456&quot;&gt; &lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div class=&quot;ldg4&quot;&gt; &lt;span class=&quot;sktjoe&quot; aria-label=&quot;1000 comments, 455 Retweets, 40000 likes&quot;&gt;Love it.&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;div data-amount=&quot;122&quot;&gt;133&lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; Write an xpath expression to get the &quot;title&quot; element. Click here for solution //title Write an xpath expression to get the content of the &quot;title&quot; element. Click here for solution //title/text Write an xpath expression to get every &quot;div&quot; element. Click here for solution //div Write an xpath expression to get every &quot;div&quot; element with class=&quot;ldskfg4&quot;. Click here for solution //div[@class='ldskfg4'] Write an xpath expression to get every &quot;div&quot; element where &quot;abc123&quot; is in the class attribute's value. Click here for solution //div[contains(@class, 'abc123')] Write an xpath expression to get every &quot;div&quot; element with an aria-label attribute. Click here for solution //div[@aria-label] Resources XPath Tutorial A w3schools tutorial on XPath expressions. A nice, quick 1 page summary. "],
["unix.html", "Unix Getting started Standard utilities awk ~ &amp; . &amp; .. Piping &amp; Redirection Emacs Nano Vim Writing scripts", " Unix Getting started We made a video to remind people about how to get comfortable with UNIX commands: Click here for video This is the easiest book for learning this stuff; it is short and gets right to the point: https://go.oreilly.com/purdue-university/library/view/-/0596002610 you just log in and you can see it all; we suggest Chapters 1, 3, 4, 5, 7 (you can basically skip chapters 2 and 6 the first time through). It is a very short read (maybe, say, 2 or 3 hours altogether?), just a thin book that gets right to the details. Zoe Yang asked us about the difference in these 5 words: bash/Linux/terminal/shell/UNIX. Here you go: UNIX(Unix) and Linux are operating systems, just like Mac OS X and Windows 10 are operating systems. There are many variants. Within Linux, the main different is the kernel (the main piece of code that makes things work) and sometimes the default configurations, like the GUI (i.e., the way stuff looks when you log in and see your desktop and interact with the windows and folders and files). UNIX dates back to the 1970's, and was from AT&amp;T Bell Labs, and then people decided to make lots and lots of variants of this, and hence, the many flavors of Linux. OK? The terminal is an application that runs in UNIX or Linux. It is the thing that you open and type things into it, and you see the output. It is hard to tell the difference between the terminal and the shell. The shell is the way that you interact with UNIX/Linux directly (without pointing and clicking). You can tell the shell directly what you want to do with the files on the computer, for instance. You might think that the terminal and the shell are the same thing, but they are not quite. There are lots of different types of shells that can run in the terminal. To see which one you are using, you can type: echo $SHELL By default, it will say: /bin/bash There are other shells in your /bin directory. bash (Bourne Again SHell) is the default one. Many people consider this to be the &quot;best&quot; shell, or at least, the one that people know the most. Others are Bourne (sh), Korn (ksh), Z shell (zsh), C shell (csh), TENEX C shell (tcsh), and dozens more. Any of these shells would run in the terminal, just like bash does, and you might not even realize at the start which shell you are using, unless you type the command mentioned above: echo $SHELL They each have differences, but some of the differences are small. Again, bash is still the default on most Linux operating systems. A big recent change is that Mac OS Catalina just started using zsh instead of bash as the default shell but it is just because of a licensing issue, and Dr Ward thinks that Mac users who open the terminal and use the shell are very likely to switch from zsh back to bash. That's what Dr Ward did immediately when Apple made this change to zsh, i.e., he switched back to bash. Wow, sorry for the long-winded answer. Standard utilities man man stand for manual and is a command which presents all of the information you need in order to use a command. To use man simply execute man &lt;command&gt; where command is the command for which you want to read the manual. You can scroll up by typing &quot;k&quot; or the up arrow. You can scroll down by typing &quot;j&quot; or the down arrow. To exit the man pages, type &quot;q&quot; (for quit). How do I show the man pages for the wc utility? Click here for solution man wc cat cat stands for concatenate and print files. It is an extremely useful tool that prints the entire contents of a file by default. This is especially useful when we want to quickly check to see what is inside of a file. It can be used as a tool to output the contents of a file and immediately pipe the contents to another tool for some sort of analysis if the other tool doesn't natively support reading the contents from the file. A similar, but alternative UNIX command that incrementally shows the contents of the file is called less. less starts at the top of the file and scrolls through the rest of the file as the user pages down. head head is a simple utility that displays the first n lines of a file, or input. How do I show the first 5 lines of a file called input.txt? Click here for solution head -n5 input.txt Alternatively: cat input.txt | head -n5 tail tail is a similar utility to head, that displays the last n lines of a file, or input. How do I show the last 5 lines of a file called input.txt? Click here for solution tail -n5 input.txt Alternatively: cat input.txt | tail -n5 ls ls is a utility that lists files and folders. By default, ls will list the files and folders in your current working directory. To list files in a certain directory, simply provide the directory to ls as the first argument. How do I list the files in my $HOME directory? Click here for solution ls $HOME # or ls ~ How do I list the files in the directory /home/$USER/projects? Click here for solution ls /home/$USER/projects How do I list all files and folders, including hidden files and folders in /home/$USER/projects? Click here for solution ls -a /home/$USER/projects How do I list all files and folders in /home/$USER/projects in a list format, including information like permissions, filesize, etc? Click here for solution ls -l /home/$USER/projects How do I list all files and folders, including hidden files and folders in /home/$USER/projects in a list format, including information like permissions, filesize, etc? Click here for solution ls -la /home/$USER/projects # or ls -al /home/$USER/projects # or ls -l -a /home/$USER/projects du du is a tool used to get file space usage. Examples How do I get the size of a file called ./metadata.csv in bytes? Click here for solution du -b ./metadata.csv ## 1834669 ./metadata.csv How do I get the size of a file called ./metadata.csv in kilobytes? Click here for solution du -k ./metadata.csv ## 1792 ./metadata.csv Why is the result of du -b ./metadata.csv divided by 1024 not the result of du -k ./metadata.csv? Click here for solution du reports disk usage by default not necessarily actual size. File systems typically divide a disk into blocks. When a program tells the file system it wants say 3 bytes of space, if the block size is 1024 bytes, the file system may allocate 1024 bytes of space to store the 3 bytes of data. To see the apparent size, do this: du -b ./metadata.csv du -k --apparent-size ./metadata.csv ## 1834669 ./metadata.csv ## 1792 ./metadata.csv cp cp is a utility used for copying files an folders from one location to another. How do I copy /home/$USER/some_file.txt to /home/$USER/projects/same_file.txt? Click here for solution cp /home/$USER/some_file.txt /home/$USER/projects/same_file.txt # If currently in /home/$USER cd $HOME cp some_file.txt projects/same_file.txt # If currently in /home/$USER/projects cd $HOME/projects cp ../some_file.txt . mv mv very similar to cp, but rather than copy a file, mv moves the file. Moving a file removes it from its old location and places it in the new location. How do I move /home/$USER/some_file.txt to /home/$USER/projects/same_file.txt? Click here for solution mv /home/$USER/some_file.txt /home/$USER/projects/same_file.txt # If currently in /home/$USER cd $HOME mv some_file.txt projects/same_file.txt # If currently in /home/$USER/projects cd $HOME/projects mv ../some_file.txt . touch touch is a command used to update the access and modification times of a file to the current time. More commonly, it is used to create an empty file that you can add contents to later on. To use this command, type touch followed by the file name (with the intended file path added when necessary). mkdir mkdir is the command to create a directory. It is simple to use, just type mkdir followed by a path to the new directory. Examples How do I create a new directory called my_directory in the current directory? Click here for solution mkdir my_directory How do I create a new directory called my_directory in the parent directory? Click here for solution mkdir ../my_directory How do I create a set of two new nested directories in the current directory? Click here for solution # You can either make the directories one at a time like this: mkdir first_dir cd first_dir mkdir second_dir # Or, you can use the -p option: mkdir -p first_dir/second_dir rm rm is the command to remove files or directories. You can find the available options by checking its manual page. Examples How do I remove a folder called my_folder and all of its contents recursively. Assume my_folder is in /home/user/projects. Click here for solution rm -r /home/user/projects/my_folder How do I remove all files in a folder ending in .txt? Assume we are looking at files in /home/user/projects. Click here for solution rm /home/user/projects/*.txt rmdir rmdir is a tool to remove empty directories. Simply type rmdir followed by the path to the empty directory you'd like to remove. Note that this command only removes empty directories. For this reason, rm is better suited to remove directories with content. pwd pwd stands for print working directory and it does just that -- it prints the current working directory to standard output. type type is a useful command to find the location of some command, or whether the command is an alias, function, or something else. Where is the file that is executed when I type ls? Click here for solution type ls ## ls is /bin/ls uniq uniq reads the lines of a specified input file and compares each adjacent line and returns each unique line. Repeated lines in the input will not be detected if they are not adjacent. What this means is you must sort prior to using uniq if you want to ensure you have no duplicates. wc You can think of wc as standing for &quot;word count&quot;. wc displays the number of lines, words, and bytes from the input file. How do I count the number of lines of an input file called input.txt? Click here for solution wc -l input.txt How do I count the number of characters of an input file called input.txt? Click here for solution wc -m input.txt How do I count the number of words of an input file called input.txt? Click here for solution wc -w input.txt ssh mosh scp cut cut is a tool to cut out parts of a line based on position/character/delimiter/etc and directing the output to stdout. It is particularly useful to get a certain column of data. How do I get the first column of a csv file called 'office.csv`? Click here for solution cut -d, -f1 office.csv How do I get the first and third column of a csv file called 'office.csv`? Click here for solution cut -d, -f1,3 office.csv How do I get the first and third column of a file with columns separated by the &quot;|&quot; character? Click here for solution cut -d &#39;|&#39; -f1,3 office.csv sed grep It is very simple to get started searching for patterns in files using grep. How do I search for lines with the word &quot;Exact&quot; in the file located /home/john/report.txt? Click here for solution grep Exact /home/john/report.txt # or grep &#39;Exact&#39; &#39;/home/john/report.txt&#39; How do I search for lines with the word &quot;Exact&quot; or &quot;exact&quot; in the file located /home/john/report.txt? Click here for solution # The -i option means that the text we are searching for is # not case-sensitive. So the following lines will match # lines that contain &quot;Exact&quot; or &quot;exact&quot; or &quot;ExAcT&quot;. grep -i Exact /home/john/report.txt # or grep -i &#39;Exact&#39; &#39;/home/john/report.txt&#39; How do I search for lines with a string containing multiple words, like &quot;how do I&quot;? Click here for solution # The -i option means that the text we are searching for is # not case-sensitive. So the following lines will match # lines that contain &quot;Exact&quot; or &quot;exact&quot; or &quot;ExAcT&quot;. # By adding quotes, we are able to search for the entire # string &quot;how do i&quot;. Without the quotes this would only # search for &quot;how&quot;. grep -i &#39;how do i&#39; /home/john/report.txt How do I search for lines with the word &quot;Exact&quot; or &quot;exact&quot; in the files in the folder and all sub-folders located /home/john/? Click here for solution # The -R option means to search recursively in the folder # /home/john. A recursive search means that it will search # all folders and sub-folders starting with /home/john. grep -Ri Exact /home/john How do I search for the lines that don't contain the words &quot;Exact&quot; or &quot;exact&quot; in the folder and all sub-folders located /home/john/? Click here for solution # The -v option means to search for an inverted match. # In this case it means search for all lines of text # where the word &quot;exact&quot; is not found. grep -Rvi Exact /home/john How do I search for lines where one or more of the words &quot;first&quot; or &quot;second&quot; appears in the current folder and all sub-folders? Click here for solution # The &quot;|&quot; character in grep is the logical OR operator. # If we do not escape the &quot;|&quot; character with a preceding # &quot;\\&quot; grep searches for the literal string &quot;first|second&quot; # instead of &quot;first&quot; OR &quot;second&quot;. grep -Ri &#39;first\\|second&#39; . How do I search for lines that begin with the word &quot;Exact&quot; (case insensitive) in the folder and all sub-folders located in the current directory? Click here for solution The &quot;^&quot; is called an anchor and indicates the start of a line. grep -Ri &#39;^Exact&#39; . How do I search for lines that end with the word &quot;Exact&quot; (case insensitive) in the files in the current folder and all sub-folders? Click here for solution The &quot;$&quot; is called an anchor and indicates the end of a line. grep -Ri &#39;Exact$&#39; . How do I search for lines that contain only the word &quot;Exact&quot; (case insensitive) in the files in the current folder and all sub-folders? Click here for solution grep -Ri &#39;^Exact$&#39; . How do I search for strings or sub-strings where the first character could be anything, but the next two characters are &quot;at&quot;? For example: &quot;cat&quot;, &quot;bat&quot;, &quot;hat&quot;, &quot;rat&quot;, &quot;pat&quot;, &quot;mat&quot;, etc. Click here for solution The &quot;.&quot; is a wildcard, meaning it matches any character (including spaces). grep -Ri &#39;.at&#39; . How do I search for zero or one of, zero or more of, one or more of, exactly n of a certain character using grep and regular expressions? Click here for solution &quot;*&quot; stands for 0+ of the previous character. &quot;+&quot; stands for 1+ of the previous character. &quot;?&quot; stands for 0 or 1 of the previous character. &quot;{n}&quot; stands for exactly n of the previous character. # Matches any lines with text like &quot;cat&quot;, &quot;bat&quot;, &quot;hat&quot;, &quot;rat&quot;, &quot;pat&quot;, &quot;mat&quot;, etc. # Does NOT match &quot;at&quot;, but does match &quot; at&quot;. The &quot;.&quot; indicates a single character. grep -Ri &#39;.at&#39; . # Matches any lines with text like &quot;cat&quot;, &quot;bat&quot;, &quot;hat&quot;, &quot;rat&quot;, &quot;pat&quot;, &quot;mat&quot;, etc. # Matches &quot;at&quot; as well as &quot; at&quot;. The &quot;.&quot; followed by the &quot;?&quot; means # 0 or 1 of any character. grep -Ri &#39;.?at&#39; . # Matches any lines with any amount of text followed by &quot;at&quot;. grep -Ri &#39;.*at&#39; . # Only matches words that end in &quot;at&quot;: &quot;bat&quot;, &quot;cat&quot;, &quot;spat&quot;, &quot;at&quot;. Does not match &quot;spatula&quot;. grep -Ri &#39;.*at$&#39; . # Matches lines that contain consecutive &quot;e&quot;&#39;s. grep -Ri &#39;.*e{2}.*&#39; . # Matches any line. 0+ of the previous character, which in this case is the wildcard &quot;.&quot; # that represents any character. So 0+ of any character. grep -Ri &#39;.*&#39; Resources Regex Tester https://regex101.com/ is an excellent tool that helps you quickly test and better understand writing regular expressions. It allows you to test four different &quot;flavors&quot; or regular expressions: PCRE (PHP), ECMAScript (JavaScript), Python, and Golang. regex101 also provides a library of useful, pre-made regular expressions. Lookahead and Lookbehinds This is an excellent resource to better understand positive and negative lookahead and lookbehind operations using grep. ReExCheatsheet An excellent quick reference for regular expressions. Examples using grep in R. ripgrep ripgrep is a &quot;line-oriented search tool that recursively searches your current directory for a regex pattern.&quot; You can read about why you may want to use ripgrep here. Generally, ripgrep is frequently faster than grep. If you are working with code it has sane defaults (respects .gitignore). You can easily search for specific types of files. How do I exclude a filetype when searching for foo in my_directory? Click here for solution # exclude javascript (.js) files rg -Tjs foo my_directory # exclude r (.r) files rg -Tr foo my_directory # exclude Python (.py) files rg -Tpy foo my_directory How do I search for a particular filetype when searching for foo in my_directory? Click here for solution # search javascript (.js) files rg -tjs foo my_directory # search r (.r) files rg -tr foo my_directory # search Python (.py) files rg -tpy foo my_directory How do I search for a specific word, where the word isn't part of another word? Click here for solution # this is roughly equivalent to putting \\b before and after all search patterns in grep rg -w foo my_directory How do I replace every match foo in my_directory with the text given, bar, when printing results? Click here for solution rg foo my_directory -r bar How do I trim whitespace from the beginning and ending of each printed line? Click here for solution rg foo my_directory --trim How do I follow symbolic links when searching a directory, my_directory? Click here for solution rg -L foo my_directory find find is an aptly named tool that traverses directories and searches for files. Examples How do I find a file named foo.txt in the current working directory or subdirectories? Click here for solution find . -name foo.txt How do I find a file named foo.txt or Foo.txt or FoO.txt (i.e. ignoring case) in the current working directory or subdirectories? Click here for solution find . -iname foo.txt # or find . -i -name foo.txt How do I find a directory named foo in the current working directory or subdirectories? Click here for solution find . -type d -name foo How do I find all of the Python files in the current working directory or subdirectories? Click here for solution find . -name &quot;*.py&quot; How do I find files over 1gb in size in the current working directory or subdirectories? Click here for solution find . -size +1G How do I find files under 10mb in size in the current working directory or subdirectories? Click here for solution find . -size -10M less less is a utility that opens a page of text from a file and allows the user to scroll forward or backward in the file using &quot;j&quot; and &quot;k&quot; keys or down and up arrows. less does not read the entire file into memory at once, and is therefore faster when loading large files. How do I display the contents of a file, foo.txt? Click here for solution less foo.txt How do I scroll up and down in less? Click here for solution To scroll down use &quot;j&quot; or the down arrow. To scroll up use &quot;k&quot; or the up arrow. How do I exit less? Click here for solution Press the &quot;q&quot; key on your keyboard. sort sort is a utility that sorts lines of text. Examples How do I sort a csv, flights_sample.csv alphabetically by the 18th column? Click here for solution # the r option sorts ascending sort -t, -k18,18 flights_sample.csv ## 1990,10,18,7,729,730,847,849,PS,1451,NA,78,79,NA,-2,-1,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1991,10,19,1,749,730,922,849,PS,1451,NA,93,79,NA,33,19,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1991,10,21,3,728,730,848,849,PS,1451,NA,80,79,NA,-1,-2,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1991,10,22,4,728,730,852,849,PS,1451,NA,84,79,NA,3,-2,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1991,10,23,5,731,730,902,849,PS,1451,NA,91,79,NA,13,1,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1991,10,24,6,744,730,908,849,PS,1451,NA,84,79,NA,19,14,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## Year,Month,DayofMonth,DayOfWeek,DepTime,CRSDepTime,ArrTime,CRSArrTime,UniqueCarrier,FlightNum,TailNum,ActualElapsedTime,CRSElapsedTime,AirTime,ArrDelay,DepDelay,Origin,Dest,Distance,TaxiIn,TaxiOut,Cancelled,CancellationCode,Diverted,CarrierDelay,WeatherDelay,NASDelay,SecurityDelay,LateAircraftDelay ## 1987,10,14,3,741,730,912,849,PS,1451,NA,91,79,NA,23,11,SAN,SFO,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1990,10,15,4,729,730,903,849,PS,1451,NA,94,79,NA,14,-1,SAN,SFO,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1990,10,17,6,741,730,918,849,PS,1451,NA,97,79,NA,29,11,SAN,SFO,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA How do I sort a csv, flights_sample.csv alphabetically by the 18th column, and then in descending order by the 4th column? Click here for solution sort -t, -k18,18 -k4,4r flights_sample.csv ## 1990,10,18,7,729,730,847,849,PS,1451,NA,78,79,NA,-2,-1,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1991,10,24,6,744,730,908,849,PS,1451,NA,84,79,NA,19,14,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1991,10,23,5,731,730,902,849,PS,1451,NA,91,79,NA,13,1,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1991,10,22,4,728,730,852,849,PS,1451,NA,84,79,NA,3,-2,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1991,10,21,3,728,730,848,849,PS,1451,NA,80,79,NA,-1,-2,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1991,10,19,1,749,730,922,849,PS,1451,NA,93,79,NA,33,19,SAN,ABC,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## Year,Month,DayofMonth,DayOfWeek,DepTime,CRSDepTime,ArrTime,CRSArrTime,UniqueCarrier,FlightNum,TailNum,ActualElapsedTime,CRSElapsedTime,AirTime,ArrDelay,DepDelay,Origin,Dest,Distance,TaxiIn,TaxiOut,Cancelled,CancellationCode,Diverted,CarrierDelay,WeatherDelay,NASDelay,SecurityDelay,LateAircraftDelay ## 1990,10,17,6,741,730,918,849,PS,1451,NA,97,79,NA,29,11,SAN,SFO,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1990,10,15,4,729,730,903,849,PS,1451,NA,94,79,NA,14,-1,SAN,SFO,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA ## 1987,10,14,3,741,730,912,849,PS,1451,NA,91,79,NA,23,11,SAN,SFO,447,NA,NA,0,NA,0,NA,NA,NA,NA,NA git See here. awk awk is a powerful programming language that specializes in processing and manipulating text data. In awk, a command looks something like this: awk -F, 'BEGIN{ } { } END{ }' The delimiter is specified with the -F option (in this case our delimiter is a comma). The BEGIN chunk is run only once at the start of execution. The middle chunk is run once per line of the file. The END chunk is run only once, at the end of execution. The BEGIN and END portions are always optional. The variables: $1, $2, $3, etc., refer to the 1st, 2nd, and 3rd fields in a line of data. For example, the following would print the 4th field of every row in a csv file: awk -F, &#39;{print $4}&#39; $0 represents the entire row. awk is very powerful. We can achieve the same effect as using cut: head 5000_products.csv | cut -d, -f3 # or head 5000_products.csv | awk -F, &#39;{print $3}&#39; Built in variables awk has some special built in variables that can be very useful. See here. Examples How do I print only rows where the DAYOFWEEK is 5? Click here for solution head metadata.csv | awk -F, &#39;{if ($3 == 5) {print $0}}&#39; ## 01/01/2015,,5,0,0,1,2015,CHRISTMAS PEAK,0,5,nyd,1,,,,0,0,CHRISTMAS PEAK,73.02,59.81,66.41,,0,,0,,0,,0,,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,17:42,1,1,0,0,18,19,17,0,0,0,0,0,0,0,1,13,17,15,0,0,0,0,1,0,14,16,14,0,1,0,0,0,0,11,15,12,8:00,25:00,17,7:00,25:00,8:00,26:00,18,8:00,25:00,17,8:00,21:00,13,8:00,21:00,8:00,25:00,17,8:00,21:00,13,8:00,22:00,14,8:00,22:00,8:00,24:00,16,8:00,22:00,14,8:00,19:00,11,8:00,19:00,8:00,22:00,14,8:00,20:00,12,1,1,0,0,NONE,53.375714286,70.3,50.2,0.12,616246,367265,296273,236654,53904354,34718635,26907827,20971646,1600,1000,2,12:00,15:30,Disney Festival of Fantasy Parade,1,22:15,,Main Street Electrical Parade,1,21:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,3,18:30,20:00,Fantasmic!,1,0,,,,,0,,, ## 01/08/2015,,5,7,1,1,2015,CHRISTMAS,8,0,,0,,marwk,,0,1,CHRISTMAS,59.44,38.7,49.07,,0,,0,,0,,0,,88%,94%,99%,78%,97%,83%,69%,94%,100%,100%,100%,76%,100%,100%,93%,100%,100%,100%,100%,100%,100%,63%,93%,17:47,1,0,0,0,13,12,12,0,0,0,0,0,0,0,1,12,12,14,0,0,0,0,0,0,10,10,10,0,1,0,0,0,0,8,9,9,9:00,21:00,12,8:00,21:00,9:00,21:00,12,9:00,21:00,12,9:00,21:00,12,9:00,21:00,9:00,21:00,12,9:00,21:00,12,9:00,19:00,10,9:00,19:00,9:00,19:00,10,9:00,19:00,10,9:00,17:00,8,9:00,17:00,9:00,17:00,8,9:00,18:00,9,1,1,0,0,NONE,48.372142857,70.3,49.4,0.08,615046,367265,296273,236654,53894754,34718635,26907827,20971646,1600,1000,1,15:00,,Disney Festival of Fantasy Parade,2,19:00,21:00,Main Street Electrical Parade,1,20:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,1,19:00,,Fantasmic!,1,0,,,,,0,,, How do I print the first, fourth, and fifth columns of rows where the DAYOFWEEK is 5? Click here for solution head metadata.csv | awk -F, &#39;{if ($3 == 5) {print $1, $4, $5}}&#39; ## 01/01/2015 0 0 ## 01/08/2015 7 1 How do I print only rows where DAYOFWEEK is 5 OR YEAR is 2015? Click here for solution head metadata.csv | awk -F, &#39;{if ($3 == 5 || $7 == 2015) {print $0}}&#39; ## 01/01/2015,,5,0,0,1,2015,CHRISTMAS PEAK,0,5,nyd,1,,,,0,0,CHRISTMAS PEAK,73.02,59.81,66.41,,0,,0,,0,,0,,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,17:42,1,1,0,0,18,19,17,0,0,0,0,0,0,0,1,13,17,15,0,0,0,0,1,0,14,16,14,0,1,0,0,0,0,11,15,12,8:00,25:00,17,7:00,25:00,8:00,26:00,18,8:00,25:00,17,8:00,21:00,13,8:00,21:00,8:00,25:00,17,8:00,21:00,13,8:00,22:00,14,8:00,22:00,8:00,24:00,16,8:00,22:00,14,8:00,19:00,11,8:00,19:00,8:00,22:00,14,8:00,20:00,12,1,1,0,0,NONE,53.375714286,70.3,50.2,0.12,616246,367265,296273,236654,53904354,34718635,26907827,20971646,1600,1000,2,12:00,15:30,Disney Festival of Fantasy Parade,1,22:15,,Main Street Electrical Parade,1,21:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,3,18:30,20:00,Fantasmic!,1,0,,,,,0,,, ## 01/02/2015,,6,1,0,1,2015,CHRISTMAS,2,5,,0,,,,0,0,CHRISTMAS,78,60.72,69.36,,0,,0,,0,,0,,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,17:43,0,1,0,0,17,18,16,0,0,0,0,0,1,0,0,15,13,12,0,0,1,0,0,0,14,14,14,0,0,0,0,0,0,12,11,11,8:00,25:00,17,8:00,25:00,8:00,25:00,17,9:00,25:00,16,8:00,21:00,13,8:00,23:00,8:00,21:00,13,9:00,21:00,12,8:00,22:00,14,8:00,22:00,8:00,22:00,14,9:00,22:00,13,8:00,20:00,12,8:00,20:00,8:00,19:00,11,8:00,19:00,11,1,1,0,0,NONE,53.750714286,70.3,50,0.12,616246,367265,296273,236654,53904354,34718635,26907827,20971646,1600,1000,2,12:00,15:30,Disney Festival of Fantasy Parade,1,22:15,,Main Street Electrical Parade,1,21:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,3,18:30,20:00,Fantasmic!,1,0,,,,,0,,, ## 01/03/2015,,7,2,0,1,2015,CHRISTMAS,3,0,,0,,,,0,0,CHRISTMAS,83.12,67.31,75.22,,0,,0,,0,,0,,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,17:44,0,0,0,0,16,17,15,0,0,0,0,0,0,1,0,12,15,12,1,0,0,0,0,0,14,14,11,0,0,1,0,0,0,11,12,12,9:00,25:00,16,9:00,25:00,8:00,25:00,17,9:00,24:00,15,9:00,21:00,12,9:00,21:00,8:00,21:00,13,9:00,21:00,12,9:00,22:00,13,8:00,22:00,8:00,22:00,14,9:00,20:00,11,8:00,19:00,11,8:00,19:00,8:00,20:00,12,9:00,20:00,11,1,1,0,0,NONE,49.212857143,70.3,49.9,0.07,616246,367265,296273,236654,53904354,34718635,26907827,20971646,1600,1000,2,12:00,15:30,Disney Festival of Fantasy Parade,1,22:15,,Main Street Electrical Parade,1,21:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,2,18:30,20:00,Fantasmic!,1,0,,,,,0,,, ## 01/04/2015,,1,3,1,1,2015,CHRISTMAS,4,0,,0,,,,0,0,CHRISTMAS,83.93,67.97,75.95,,0,,0,,0,,0,,67%,74%,77%,74%,74%,70%,66%,94%,68%,57%,56%,70%,79%,43%,93%,100%,100%,100%,100%,100%,48%,63%,84%,17:44,0,0,0,0,15,16,14,0,0,0,0,0,0,0,0,12,12,12,0,1,0,0,0,1,11,14,13,1,0,0,0,0,0,12,11,8,9:00,24:00,15,9:00,24:00,9:00,25:00,16,9:00,23:00,14,9:00,21:00,12,9:00,21:00,9:00,21:00,12,9:00,21:00,12,9:00,20:00,11,9:00,20:00,9:00,22:00,13,9:00,20:00,11,9:00,20:00,11,8:00,20:00,8:00,19:00,11,9:00,17:00,8,1,1,0,0,NONE,48.270714286,70.3,49.8,0.12,616246,367265,296273,236654,53904354,34718635,26907827,20971646,1600,1000,1,15:00,,Disney Festival of Fantasy Parade,2,20:00,22:00,Main Street Electrical Parade,1,21:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,2,19:00,20:30,Fantasmic!,1,0,,,,,0,,, ## 01/05/2015,,2,4,1,1,2015,CHRISTMAS,5,0,,0,,,,0,0,CHRISTMAS,72.3,56.89,64.6,,0,,0,,0,,0,,67%,74%,77%,74%,74%,70%,66%,94%,68%,57%,56%,70%,79%,43%,93%,100%,100%,100%,100%,100%,48%,63%,84%,17:45,0,0,0,0,14,15,12,0,0,0,0,1,0,0,0,12,12,13,0,0,0,1,0,0,13,11,10,0,1,0,0,0,0,8,12,8,9:00,23:00,14,9:00,23:00,9:00,24:00,15,9:00,21:00,12,9:00,21:00,12,9:00,21:00,9:00,21:00,12,9:00,21:00,12,9:00,20:00,11,9:00,22:00,9:00,20:00,11,9:00,19:00,10,9:00,17:00,8,9:00,17:00,9:00,20:00,11,9:00,17:00,8,1,1,0,0,NONE,48.971538462,70.3,49.6,0.12,616246,367265,306272,236654,53904354,34718635,27897728,20971646,1600,1000,1,15:00,,Disney Festival of Fantasy Parade,2,20:00,22:00,Main Street Electrical Parade,1,21:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,2,19:00,20:30,Fantasmic!,1,0,,,,,0,,, ## 01/06/2015,,3,5,1,1,2015,CHRISTMAS,6,0,,0,,,,0,0,CHRISTMAS,77.67,54.88,66.28,,0,,0,,0,,0,,86%,92%,98%,77%,96%,82%,69%,94%,100%,98%,98%,76%,100%,96%,93%,100%,100%,83%,100%,100%,92%,63%,93%,17:46,0,0,0,0,12,14,12,0,0,1,0,0,0,0,0,13,12,12,0,0,0,0,1,0,10,13,10,0,0,1,0,0,0,8,8,9,9:00,21:00,12,9:00,21:00,9:00,23:00,14,9:00,21:00,12,9:00,21:00,12,8:00,21:00,9:00,21:00,12,9:00,21:00,12,9:00,19:00,10,9:00,19:00,9:00,20:00,11,9:00,19:00,10,9:00,17:00,8,9:00,17:00,9:00,17:00,8,9:00,17:00,8,1,1,0,0,NONE,50.093571429,70.2,49.5,0.12,615046,367265,296273,236654,53894754,34718635,26907827,20971646,1600,1000,1,15:00,,Disney Festival of Fantasy Parade,0,,,,1,20:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,1,19:00,,Fantasmic!,1,0,,,,,0,,, ## 01/07/2015,,4,6,1,1,2015,CHRISTMAS,7,0,,0,,marwk,,0,1,CHRISTMAS,67.24,48.56,57.9,,0,,0,,0,,0,,88%,94%,99%,78%,97%,83%,69%,94%,100%,100%,100%,76%,100%,100%,93%,100%,100%,100%,100%,100%,100%,63%,93%,17:47,0,0,1,0,12,12,13,0,0,0,1,0,0,0,0,12,13,12,0,0,0,0,0,0,10,10,10,1,0,0,0,0,0,9,8,8,9:00,21:00,12,9:00,21:00,9:00,21:00,12,9:00,21:00,12,9:00,21:00,12,9:00,21:00,9:00,21:00,12,9:00,21:00,12,9:00,19:00,10,9:00,19:00,9:00,19:00,10,9:00,19:00,10,9:00,17:00,8,8:00,17:00,9:00,17:00,8,9:00,17:00,8,1,1,0,0,NONE,47.188571429,70.3,49.5,0.12,615046,367265,296273,236654,53894754,34718635,26907827,20971646,1600,1000,1,15:00,,Disney Festival of Fantasy Parade,0,,,,1,20:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,1,19:00,,Fantasmic!,1,0,,,,,0,,, ## 01/08/2015,,5,7,1,1,2015,CHRISTMAS,8,0,,0,,marwk,,0,1,CHRISTMAS,59.44,38.7,49.07,,0,,0,,0,,0,,88%,94%,99%,78%,97%,83%,69%,94%,100%,100%,100%,76%,100%,100%,93%,100%,100%,100%,100%,100%,100%,63%,93%,17:47,1,0,0,0,13,12,12,0,0,0,0,0,0,0,1,12,12,14,0,0,0,0,0,0,10,10,10,0,1,0,0,0,0,8,9,9,9:00,21:00,12,8:00,21:00,9:00,21:00,12,9:00,21:00,12,9:00,21:00,12,9:00,21:00,9:00,21:00,12,9:00,21:00,12,9:00,19:00,10,9:00,19:00,9:00,19:00,10,9:00,19:00,10,9:00,17:00,8,9:00,17:00,9:00,17:00,8,9:00,18:00,9,1,1,0,0,NONE,48.372142857,70.3,49.4,0.08,615046,367265,296273,236654,53894754,34718635,26907827,20971646,1600,1000,1,15:00,,Disney Festival of Fantasy Parade,2,19:00,21:00,Main Street Electrical Parade,1,20:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,1,19:00,,Fantasmic!,1,0,,,,,0,,, ## 01/09/2015,,6,8,1,1,2015,CHRISTMAS,9,0,,0,,marwk,,0,1,CHRISTMAS,54.89,45.37,50.13,,0,,0,,0,,0,,88%,94%,99%,78%,97%,83%,69%,94%,100%,100%,100%,76%,100%,100%,93%,100%,100%,100%,100%,100%,100%,63%,93%,17:48,0,1,0,0,12,13,14,0,1,0,0,0,1,0,0,14,12,12,0,0,1,0,0,0,10,10,12,0,0,0,0,0,0,9,8,11,9:00,21:00,12,9:00,21:00,9:00,21:00,12,9:00,23:00,14,9:00,21:00,12,9:00,23:00,9:00,21:00,12,9:00,21:00,12,9:00,19:00,10,9:00,19:00,9:00,19:00,10,9:00,20:00,11,9:00,18:00,9,9:00,18:00,9:00,17:00,8,9:00,20:00,11,1,1,0,0,NONE,51.094285714,70.3,49.3,0.11,615046,367265,296273,236654,53894754,34718635,26907827,20971646,1600,1000,1,15:00,,Disney Festival of Fantasy Parade,1,19:00,,Main Street Electrical Parade,1,20:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,1,19:00,,Fantasmic!,1,0,,,,,0,,, How do I print only rows where DAYOFWEEK is 5 AND YEAR is 2015? Click here for solution head metadata.csv | awk -F, &#39;{if ($3 == 5 &amp;&amp; $7 == 2015) {print $0}}&#39; ## 01/01/2015,,5,0,0,1,2015,CHRISTMAS PEAK,0,5,nyd,1,,,,0,0,CHRISTMAS PEAK,73.02,59.81,66.41,,0,,0,,0,,0,,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,0%,17:42,1,1,0,0,18,19,17,0,0,0,0,0,0,0,1,13,17,15,0,0,0,0,1,0,14,16,14,0,1,0,0,0,0,11,15,12,8:00,25:00,17,7:00,25:00,8:00,26:00,18,8:00,25:00,17,8:00,21:00,13,8:00,21:00,8:00,25:00,17,8:00,21:00,13,8:00,22:00,14,8:00,22:00,8:00,24:00,16,8:00,22:00,14,8:00,19:00,11,8:00,19:00,8:00,22:00,14,8:00,20:00,12,1,1,0,0,NONE,53.375714286,70.3,50.2,0.12,616246,367265,296273,236654,53904354,34718635,26907827,20971646,1600,1000,2,12:00,15:30,Disney Festival of Fantasy Parade,1,22:15,,Main Street Electrical Parade,1,21:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,3,18:30,20:00,Fantasmic!,1,0,,,,,0,,, ## 01/08/2015,,5,7,1,1,2015,CHRISTMAS,8,0,,0,,marwk,,0,1,CHRISTMAS,59.44,38.7,49.07,,0,,0,,0,,0,,88%,94%,99%,78%,97%,83%,69%,94%,100%,100%,100%,76%,100%,100%,93%,100%,100%,100%,100%,100%,100%,63%,93%,17:47,1,0,0,0,13,12,12,0,0,0,0,0,0,0,1,12,12,14,0,0,0,0,0,0,10,10,10,0,1,0,0,0,0,8,9,9,9:00,21:00,12,8:00,21:00,9:00,21:00,12,9:00,21:00,12,9:00,21:00,12,9:00,21:00,9:00,21:00,12,9:00,21:00,12,9:00,19:00,10,9:00,19:00,9:00,19:00,10,9:00,19:00,10,9:00,17:00,8,9:00,17:00,9:00,17:00,8,9:00,18:00,9,1,1,0,0,NONE,48.372142857,70.3,49.4,0.08,615046,367265,296273,236654,53894754,34718635,26907827,20971646,1600,1000,1,15:00,,Disney Festival of Fantasy Parade,2,19:00,21:00,Main Street Electrical Parade,1,20:00,,Wishes Nighttime Spectacular,1,21:00,,IllumiNations: Reflections of Earth,0,,,0,,,,1,19:00,,Fantasmic!,1,0,,,,,0,,, How do I get the average of values in a column containing the max temperature, WDWMAXTEMP? Click here for solution # Here NR represents the number of rows head metadata.csv | awk -F, &#39;{sum = sum + $19}END{print &quot;Average max temp: &quot; sum/NR}&#39; # Or alternatively we could track the number of rows as we go head metadata.csv | awk -F, &#39;{sum = sum + $19; count++}END{print &quot;Average max temp: &quot; sum/count}&#39; ## Average max temp: 64.961 ## Average max temp: 64.961 How do I get counts of each unique value in a column, SEASON? Click here for solution When executing the middle chunk of code, awk will create a set of values called seasons, whose elements are named by unique values in the 8-th column SEASON. For the SEASON value in a line, awk will add 1 to the corresponding element (this is ++). Thus, we get the count for each unique value. In the END chunk of code, we print out season by going through its elements. The season in for (season in seasons) refers to the name of the elements. To access the actual value, we use seasons[season]. This is just one example of arrays in awk. You can find more details here: https://www.gnu.org/software/gawk/manual/html_node/Arrays.html cat metadata.csv | awk -F, &#39;{seasons[$8]++}END{for (season in seasons) {print season, seasons[season]}}&#39; ## SUMMER BREAK 236 ## CHRISTMAS 245 ## JERSEY WEEK 50 ## SEPTEMBER LOW 140 ## PRESIDENTS WEEK 55 ## FALL 212 ## HALLOWEEN 26 ## MEMORIAL DAY 20 ## CHRISTMAS PEAK 176 ## SEASON 1 ## COLUMBUS DAY 20 ## SPRING 490 ## THANKSGIVING 60 ## EASTER 95 ## MARTIN LUTHER KING JUNIOR DAY 45 ## MARDI GRAS 15 ## JULY 4TH 25 ## WINTER 222 How do I get counts of each unique value in a column, SEASON, but only print the values for FALL, WINTER, SUMMER, and SPRING? Click here for solution cat metadata.csv | awk -F, &#39;{seasons[$8]++}END{for (season in seasons) {if (season == &quot;FALL&quot; || season == &quot;SUMMER&quot; || season == &quot;WINTER&quot; || season == &quot;SPRING&quot;) print season, seasons[season]}}&#39; ## FALL 212 ## SPRING 490 ## WINTER 222 Or a better solution would be to use the ~ operator: cat metadata.csv | awk -F, &#39;{seasons[$8]++}END{for (season in seasons) {if (season ~ /WINTER|SPRING|SUMMER|FALL/) print season, seasons[season]}}&#39; ## SUMMER BREAK 236 ## FALL 212 ## SPRING 490 ## WINTER 222 If you want to exclude &quot;SUMMER BREAK&quot;, use the $ regular expression anchor. This forces it to only accept strings where the entire string ends in &quot;SUMMER&quot; so &quot;SUMMER BREAK&quot; is excluded as it ends in &quot; BREAK&quot; not &quot;SUMMER&quot;: cat metadata.csv | awk -F, &#39;{seasons[$8]++}END{for (season in seasons) {if (season ~ /WINTER|SPRING|SUMMER$|FALL/) print season, seasons[season]}}&#39; ## FALL 212 ## SPRING 490 ## WINTER 222 ~ &amp; . &amp; .. ~ represents the location which is in the environment variable $HOME. If you change $HOME, ~ also changes. As you are navigating directories, to jump to the most previously visited directory, you can run ~-. For example, if you navigate to /home/$USER/projects/project1/output, then to /home/$USER, and you'd like to jump directly back to /home/$USER/projects/project1/output, simply run ~-. ~- is simply a reference to the location stored in $OLDPWD. . represents the current working directory. For example, if you are in your home directory /home/$USER, . means &quot;in this directory&quot;, and ./some_file.txt would represent a file named some_file.txt which is in your home directory /home/$USER. .. represents the parent directory. For example, /home is the parent directory of /home/$USER. If you are currently in /home/$USER/projects and you want to access some file in the home directory, you could do ../some_file.txt. ../some_file.txt is called a relative path as it is relative to your current location. If we accessed ../some_file.txt from the home directory, this would be different than accessing ../some_file.txt from a different directory. /home/$USER/some_file.txt is an absolute or full path of a file some_file.txt. Examples If I am in the directory /home/kamstut/projects directory, what is the relative path to /home/mdw/? Click here for solution ../../mdw If I am in the directory /home/kamstut/projects/project1, what is the absolute path to the file ../../scripts/runthis.sh? Click here for solution /home/kamstut/scripts/runthis.sh How can I navigate to my $HOME directory? Click here for solution cd cd ~ cd $HOME cd /home/$USER Piping &amp; Redirection Redirection is the act of writing standard input (stdin) or standard output (stdout) or standard error (stderr) somewhere else. stdin, stdout, and stderr all have numeric representations of 0, 1, &amp; 2 respectively. Piping is a form of redirection, but rather than redirect output to stdin, stdout, or stderr, we redirect the output to further commands for more processing. Redirection Examples For the following examples we use the example file redirection.txt. The contents of which are: cat redirection.txt ## This is a simple file with some text. ## It has a couple of lines of text. ## Here is some more. How do I redirect text from a command like ls to a file like redirection.txt, completely overwriting any text already within redirection.txt? Click here for solution # Save the stdout from the ls command to redirection.txt ls &gt; redirection.txt # The new contents of redirection.txt head redirection.txt ## 01-scholar.Rmd ## 02-data-formats.Rmd ## 03-unix.Rmd ## 04-sql.Rmd ## 05-r.Rmd ## 06-python.Rmd ## 07-tools.Rmd ## 08-faqs.Rmd ## 09-projects.Rmd ## 10-contributors.Rmd How do I redirect text from a command like ls to a file like redirection.txt, without overwriting any text, but rather appending the text to the end of the file? Click here for solution # Append the stdout from the ls command to the end of redirection.txt ls &gt;&gt; redirection.txt head redirection.txt ## This is a simple file with some text. ## It has a couple of lines of text. ## Here is some more. ## 01-scholar.Rmd ## 02-data-formats.Rmd ## 03-unix.Rmd ## 04-sql.Rmd ## 05-r.Rmd ## 06-python.Rmd ## 07-tools.Rmd How can I redirect text from a file to be used as stdin for another program or command? Click here for solution # Let&#39;s count the number of words in redirection.txt wc -w &lt; redirection.txt ## 20 How can I use multiple redirects in a single line? Click here for solution # Here we count the number of words in redirection.txt and then # save that value to value.txt. wc -w &lt; redirection.txt &gt; value.txt head value.txt ## 20 Piping Piping is the act of taking the output of one or more commands and making the output the input of another command. This is accomplished using the &quot;|&quot; character. Examples For the following examples we use the example file piping.txt. The contents of which are: cat piping.txt ## apples, oranges, grapes ## pears, apples, peaches, ## celery, carrots, peanuts ## fruits, vegetables, ok How can I use the output from a grep command to another command? Click here for solution grep -i &quot;p\\{2\\}&quot; piping.txt | wc -w ## 6 How can I chain multiple commands together? Click here for solution # Get the third column of piping.txt and # get all lines that end in &quot;s&quot; and sort # the words in reverse order, and append # to a file called food.txt. cut -d, -f3 piping.txt | grep -i &quot;.*s$&quot; | sort -r &gt; food.txt Resources Intro to I/O Redirection A quick introduction to stdin, stdout, stderr, redirection, and piping. Emacs Nano Vim Writing scripts bash stands for &quot;Bourne Again Shell&quot;. There are many types of shells, including but not limited to: ksh, zsh, csh, tcsh, fish. When you open a terminal emulator, it will typically run a shell. You can write a bash script, zsh script, csh script, etc. Typically, when you have an interpreter, you can write scripts for them. For example, even though R and Python are not shells, we can write scripts for those languages. As bash is the default shell for many linux operating systems today, we will keep referring to scripts as &quot;bash scripts&quot;, but take note that in general the same applies for other shells too. A bash script is more or less a series of bash commands used to perform a sequence of actions. It is similar to a .R script, but instead of R code, we have bash commands. A bash script starts with the &quot;shebang&quot; or &quot;bang&quot; line or &quot;hash-bang&quot; -- #!/bin/bash. The shebang is used to indicate which interpreter to use to execute the script. For example, if you were using zsh instead, your shebang might read #!/bin/zsh. Take the following bash script: #!/bin/bash echo &quot;First argument: $1&quot; echo &quot;Second argument: $2&quot; If you were to place that text inside of a file called my_script: echo &#39;#!/bin/bash echo &quot;First argument: $1&quot; echo &quot;Second argument: $2&quot;&#39; &gt; $HOME/my_script And then run it: cd $HOME chmod +x ./my_script ./my_script okay cool The second line of code is to set the permission so that your script is executable. You would get the following result: First argument: okay Second argument: cool The operating system would use the interpreter located /bin/bash to execute the script. This would produce the same results: cd $HOME /bin/bash my_script okay cool But instead we only have to run: cd $HOME ./my_script okay cool Note that if you were to change the shebang to say #!/usr/bin/python and try running the following: cd $HOME ./my_script okay cool You would get an error that reads: File &quot;./my_script&quot;, line 3 echo &quot;First argument: $1&quot; ^ SyntaxError: invalid syntax The reason is that the operating system is using the Python interpreter located /usr/bin/python to run the bash code in our script, my_script. Since our code is not Python code, we get this error. Arguments A bash script can accept arguments. This is just like many programs we've used to date (grep, cut, awk, etc.). For example: grep -i &#39;special&#39; Here, -i and 'special' are arguments to grep. -i is the first argument, and 'special' is the second. If you run the following script: #!/bin/bash echo &quot;First argument: $1&quot; echo &quot;Second argument: $2&quot; You can see that this is indeed the truth: cd $HOME ./my_script -i &#39;special&#39; First argument: -i Second argument: special In a bash script the first argument is denoted by $1 the second by $2 the third by $3 etc. In fact, $0 denotes the command used to run the script: #!/bin/bash echo &quot;Command: $0&quot; echo &quot;First argument: $1&quot; echo &quot;Second argument: $2&quot; cd $HOME ./my_script okay cool Command: ./my_script First argument: okay Second argument: cool Examples Write a script called indyflights.sh that takes a file from this directoy as its input: /class/datamine/data/flights/subset and returns the number of flights that have IND as the origin or destination. Click here for solution #!/bin/bash cat /class/datamine/data/flights/subset/$1 | cut -d, -f17,18 | grep IND | wc -l Modify your script from this problem to accept an argument containing an airport code (for example IND). Your script should determine how many flights have origin or destination IND (or your given airport code) altogether (across all years in all of the flights files). Click here for solution #!/bin/bash for i in {1987..2008}; do count=$(cat /class/datamine/data/flights/subset/$i.csv | cut -d, -f17,18 | grep $1 | wc -l) sum=$((sum + count)) done echo &quot;$sum&quot; or Note: This option would work better if you need to use variable substitution in your range (from 1987 to 2008). #!/bin/bash for ((i=1987; i&lt;=2008; i++)); do count=$(cat /class/datamine/data/flights/subset/$i.csv | cut -d, -f17,18 | grep $1 | wc -l) sum=$((sum + count)) done echo &quot;$sum&quot; "],
["sql.html", "SQL Joins Aliasing", " SQL library(RMariaDB) library(RSQLite) library(DBI) # Establish a connection to sqlite databases chinook &lt;- dbConnect(RSQLite::SQLite(), &quot;chinook.db&quot;) lahman &lt;- dbConnect(RSQLite::SQLite(), &quot;lahman.db&quot;) # Establish a connection to mysql databases connection &lt;- dbConnect(RMariaDB::MariaDB(), host=&quot;your-host.com&quot;, db=&quot;your-database-name&quot;, user=&quot;your-username&quot;, password=&quot;your-password&quot;) Joins Joins are SQL clauses that combine data from two tables. There are 4 primary types of SQL joins: INNER JOIN, LEFT OUTER JOIN, RIGHT OUTER JOIN, and FULL OUTER JOIN. When talking about an SQL JOIN statement, sometimes the first table in the SQL statement is referred to as the &quot;left&quot; table, and the second table is referred to as the right table. For instance, in the following query, A is the left table and B is the right table. SELECT * FROM A INNER JOIN B ON A.id=B.a_id; While there can be cases where using RIGHT JOIN and FULL JOIN can make your SQL statement more concise, both RIGHT JOIN and FULL JOIN are redundant and can be fully emulated using LEFT JOIN and UNION ALL clauses. For the purposes of illustration, we will be using a common example of a database for an online store. This online store has two primary tables, orders and customers, shown below. orders id description customer_id value 1 Water bottle 1 15.00 2 Key chain 1 7.50 3 Computer 3 2000.00 4 Thumb drive 3 25.00 5 Notebook 4 9.00 6 Shampoo 5.00 7 Paper 4.00 customers id first_name last_name email 1 Natalie Wright wright@example.com 2 Ana Sousa sousa@example.com 3 Ben Schwartz schwartz@example.com 4 Chen Xi xi@example.com 5 Frank Zhang zhang@example.com 6 Tianchi Liu liu@example.com 7 Jake Jons jons@example.com INNER JOIN An INNER JOIN, often referred to as simply JOIN, returns rows/records where there is a match in the right table from the left table. Records from the left table that don't have a match in the right table are excluded. Records from the right table that don't have a match in the left table are also excluded. This is appropriate any time you need data from two separate tables, but only when the two tables have something in common. For example, what if our online company decided it wanted to query the database to send an email of appreciation for all customers who have placed at least 1 order. In this case, we want only the emails of those who don't appear in both the customers and orders table. SELECT customers.email FROM orders INNER JOIN customers ON orders.customer_id=customers.id; Which would result in the following table. email wright@example.com schwartz@example.com xi@example.com LEFT OUTER JOIN A LEFT OUTER JOIN, often referred to as simply a LEFT JOIN, returns rows/records where every value in the left table is present in addition to additional data from the right table, when there exists a match in the right table. This is appropriate any time you want all of the data from the left table, and any extra data from the right table if there happens to be a match. For example, what if our online company wanted a list of all orders placed, and if the order wasn't placed from a guest account, send an email to the customer thanking them for their purchase? In this case, it would make sense to append email information to the order when there is a match. SELECT orders.description, orders.value, customers.email FROM orders LEFT JOIN customers ON order.customer_id=customers.id; Which would result in the following table, enabling the employee to see orders as well as send out thank you emails. description value first_name last_name email Water bottle 15.00 Natalie Wright wright@example.com Key chain 7.50 Natalie Wright wright@example.com Computer 2000.00 Ben Schwartz schwartz@example.com Thumb drive 25.00 Ben Schwartz schwartz@example.com Notebook 9.00 Chen Xi xi@example.com Shampoo 5.00 Paper 4.00 Had we instead used an INNER JOIN, our list would be missing critical order information. SELECT orders.description, orders.value, customers.email FROM orders INNER JOIN customers ON order.customer_id=customers.id; description value first_name last_name email Water bottle 15.00 Natalie Wright wright@example.com Key chain 7.50 Natalie Wright wright@example.com Computer 2000.00 Ben Schwartz schwartz@example.com Thumb drive 25.00 Ben Schwartz schwartz@example.com Notebook 9.00 Chen Xi xi@example.com Aliasing Aliasing is the process of giving a table or a table column a temporary name. Aliases are commonly used to either make the query easier to write, or more readable. An example of using table aliases to make a query shorter would be the following. SELECT orders.description, orders.value, customers.email FROM orders INNER JOIN customers ON order.customer_id=customers.id; By using table aliases, this can be reduced greatly. SELECT o.description, o.value, c.email FROM orders AS o INNER JOIN customers AS c ON o.customer_id=c.id; Note that aliases only last for the duration of a single query. If we were to subsequently use the following query, it would fail. SELECT o.description, o.value, c.email FROM o INNER JOIN c ON o.customer_id=c.id; In addition to table aliases, we can give fields aliases as well. For example, we could reduce customer_id to just c_id. SELECT orders.customer_id AS c_id FROM orders INNER JOIN customers ON order.c_id=customers.id; Alternatively, we could change customer_id to Customer ID, however, whenever we want an alias to contain spaces, we need to use either double quotes or square brackets. SELECT orders.customer_id AS &quot;Customer ID&quot; FROM orders INNER JOIN customers ON order.&quot;Customer ID&quot;=customers.id; RDBMS SQL in R Click here for video Examples Please see here for a variety of examples demonstrating using SQL within R. SQL in Python Examples The following examples use the lahman.db sqlite database. Display the first 10 ballparks in the ballparks table. Click here for solution SELECT * FROM parks LIMIT 10; Table 1: Displaying records 1 - 10 ID parkalias parkkey parkname city state country 1 NA ALB01 Riverside Park Albany NY US 2 NA ALT01 Columbia Park Altoona PA US 3 Edison Field; Anaheim Stadium ANA01 Angel Stadium of Anaheim Anaheim CA US 4 NA ARL01 Arlington Stadium Arlington TX US 5 The Ballpark in Arlington; Ameriquest Fl ARL02 Rangers Ballpark in Arlington Arlington TX US 6 NA ATL01 Atlanta-Fulton County Stadium Atlanta GA US 7 NA ATL02 Turner Field Atlanta GA US 8 NA ATL03 Suntrust Park Atlanta GA US 9 NA BAL01 Madison Avenue Grounds Baltimore MD US 10 NA BAL02 Newington Park Baltimore MD US Make a list of the names of all of the inactive teams in baseball history. Click here for solution Remove the LIMIT 10 for full results. SELECT franchName FROM teamsfranchises WHERE active==&#39;N&#39; LIMIT 10; Table 2: Displaying records 1 - 10 franchName Altoona Mountain City Philadelphia Athletics Buffalo Bisons Buffalo Bisons Baltimore Orioles Baltimore Terrapins Baltimore Monumentals Boston Reds Brooklyn Gladiators Boston Reds Find the player with the most Runs Batted In (RBIs) in a season in queries. In the first query find the playerID of the player with the most RBIs. In the second query find the player's name in the people table. Click here for solution In addition to his RBI record, Hack Wilson also held the NL home run record for a long time as well with 56. In 1999, Manny Ramirez tried to pursue the RBI record, but only was able to accrue 165 RBIs. -- Find the playerID SELECT playerID FROM batting WHERE RBI==191; -- Display the name SELECT nameFirst, nameLast FROM people WHERE playerID==&#39;wilsoha01&#39;; Table 3: 1 records playerID wilsoha01 Who was the manager of the 1976 &quot;Big Red Machine&quot; (CIN)? Complete this in 2 queries. Click here for solution The &quot;Big Red Machine&quot; was a famous nickname for the dominant Cincinnati Reds of the early 1970s. Many of its team members are Hall of Famers, including their manager, Sparky Anderson. SELECT playerID FROM managers WHERE yearID==1976 AND teamID==&#39;CIN&#39;; SELECT nameFirst, nameLast FROM people WHERE playerID==&#39;andersp01&#39;; Table 4: 1 records playerID andersp01 Make a list of the teamIDs that were managed by Tony LaRussa. Complete this in 2 queries. Click here for solution Tony LaRussa is very well known for being a manager that was involved in baseball for a very long time. He won the World Series with the St. Louis Cardinals and the Oakland Athletics. SELECT playerID FROM people WHERE nameLast==&#39;LaRussa&#39; AND nameFirst==&#39;Tony&#39;; SELECT DISTINCT teamID FROM managers WHERE playerID==&#39;larusto01&#39;; Table 5: 1 records playerID larusto01 What was Cecil Fielder's salary in 1987? Display the teamID with the salary. Click here for solution Cecil Fielder was a power hitting DH in the 1980s and 1990s. His son, Prince Fielder, played in the major leagues as well. SELECT playerID FROM people WHERE nameFirst==&#39;Cecil&#39; AND nameLast==&#39;Fielder&#39;; SELECT teamID, salary FROM salaries WHERE playerID==&#39;fieldce01&#39; AND yearID==1987; Table 6: 1 records playerID fieldce01 Make a list of all the teams who have lost a World Series (WS) since 1990. Put the list in ascending order by yearID. Click here for solution SELECT teamIDloser, yearID FROM seriespost WHERE yearID &gt;= 1990 AND round==&#39;WS&#39; ORDER BY yearID ASC LIMIT 10; Table 7: Displaying records 1 - 10 teamIDloser yearID OAK 1990 ATL 1991 ATL 1992 PHI 1993 CLE 1995 ATL 1996 CLE 1997 SDN 1998 ATL 1999 NYN 2000 Let's find out about Cal Ripken, Jr. What was his height and weight? Did he bat right or left handed? When did he play his final game? Find all of this information in one query. Click here for solution Cal Ripken, Jr's nickname is the &quot;Iron Man&quot; of baseball due to the fact that he started in 2,632 straight games. That means in just over 16 seasons, Cal Ripken, Jr. never missed a game! SELECT height, weight, bats, finalgame FROM people WHERE nameFirst==&#39;Cal&#39; AND nameLast==&#39;Ripken&#39; AND deathState IS NULL; Table 8: 1 records height weight bats finalGame 76 200 R 2001-10-06 Select all the playerIDs and yearIDs of the players who were inducted in the hall of fame and voted in by the Veterans committee, between 1990 and 2000. Put the list in descending order. Click here for solution The veterans committee in the Hall of Fame voting process place players in the Hall of Fame that are forgotten by the writers, fans, etc. This is a way for players to recognize who they think were the greatest players of all time, or are skipped over for a variety of reasons. This is one reason why there is a lot of scrutiny in the process for how players are selected to the baseball hall of fame. SELECT playerID, yearID FROM halloffame WHERE votedBy==&#39;Veterans&#39; AND inducted==&#39;Y&#39; AND yearID BETWEEN 1990 AND 2000 ORDER BY yearID DESC LIMIT 10; Table 9: Displaying records 1 - 10 playerID yearid andersp01 2000 mcphebi01 2000 steartu99 2000 cepedor01 1999 chylane99 1999 seleefr99 1999 willijo99 1999 davisge01 1998 dobyla01 1998 macphle99 1998 Get a list of the attendance by season of the Toronto Blue Jays (TOR). What season was the highest attendance? Click here for solution The Toronto Blue Jays were the 1993 season's World Series champion. This means that, yes, a non-USA team has won the World Series for baseball! SELECT yearkey, attendance FROM homegames WHERE teamkey==&#39;TOR&#39; ORDER BY attendance DESC LIMIT 10; Table 10: Displaying records 1 - 10 yearkey attendance 1993 4057747 1992 4028318 1991 4001526 1990 3884384 2016 3392099 2017 3203886 1994 2907949 1995 2826445 2015 2794891 1987 2778459 How many different leagues have represented Major League Baseball over time? Click here for solution Major League Baseball has had several leagues that have been represented in its history. There are only two current leagues: National League and the American League. SELECT DISTINCT league FROM leagues; Table 11: 8 records league American Association American League Federal League Major League National Association National League Players' League Union Association Find the teams that have won the World Series. Click here for solution SELECT teamID, yearID FROM teams WHERE WSWin==&#39;Y&#39; LIMIT 10; Table 12: Displaying records 1 - 10 teamID yearID PRO 1884 SL4 1886 DTN 1887 NY1 1888 NY1 1889 BOS 1903 NY1 1905 CHA 1906 CHN 1907 CHN 1908 List the top 10 season win totals of teams. Include the yearID and teamID. Click here for solution SELECT teamID, yearID, W FROM teams ORDER BY W DESC LIMIT 10; Table 13: Displaying records 1 - 10 teamID yearID W CHN 1906 116 SEA 2001 116 NYA 1998 114 CLE 1954 111 PIT 1909 110 NYA 1927 110 NYA 1961 109 BAL 1969 109 BAL 1970 108 CIN 1975 108 List the pitchers with their teamID, wins (W), and losses (L) that threw complete games (CG) in the 1995 season. Include their number of complete games as well. Click here for solution SELECT playerID, teamID, W, L, CG FROM pitching WHERE CG &gt; 0 AND yearID==1995 ORDER BY W DESC LIMIT 10; Table 14: Displaying records 1 - 10 playerID teamID W L CG maddugr01 ATL 19 2 10 mussimi01 BAL 19 9 7 johnsra05 SEA 18 2 6 schoupe01 CIN 18 7 2 martira02 LAN 17 7 4 rogerke01 TEX 17 7 3 glavito02 ATL 16 7 3 hershor01 CLE 16 6 1 nagych01 CLE 16 6 2 wakefti01 BOS 16 8 6 Get a printout of the Hits (H), and home runs (HR) of Ichiro Suzuki's career. Do this is in two queries. In the first query, find Ichiro Suzuki's playerID. In the second one list the teamID, yearID, hits and home runs. Click here for solution Ichiro Suzuki is regarded as one of the greatest hitters of all time because of his prowess in both American and Japanese professional baseball. SELECT playerID FROM people WHERE nameFirst==&#39;Ichiro&#39; AND nameLast==&#39;Suzuki&#39;; SELECT teamID, yearID, H, HR FROM batting WHERE playerID==&#39;suzukic01&#39;; Table 15: 1 records playerID suzukic01 How many walks (BB) and strikeouts (SO) did Mariano Rivera achieve in the playoffs? Which year did Mariano Rivera give up the most post-season walks? Click here for solution More men have walked on the moon than have scored a run on Mariano Rivera in a playoff game. Mariano Rivera made the hall of fame in 2019. SELECT playerID FROM people WHERE nameFirst==&#39;Mariano&#39; AND nameLast==&#39;Rivera&#39;; SELECT yearID, teamID, BB, SO FROM pitchingpost WHERE playerID==&#39;riverma01&#39; ORDER BY BB DESC; Table 16: 1 records playerID riverma01 Find the pitcher with most strikeouts (SO), and the batter that struck out the most in the 2014 season. Get the first and last name of the pitcher and batter, respectively. Click here for solution Corey Kluber is a two-time AL Cy Young winner. He is well known for his two-seam fastball that is difficult to hit. SELECT playerID, SO FROM pitching WHERE yearID==2014 ORDER BY SO DESC LIMIT(10); SELECT playerID, SO FROM batting WHERE yearID==2014 ORDER BY SO DESC LIMIT(10); SELECT nameFirst,nameLast FROM people WHERE playerID==&quot;klubeco01&quot; OR playerID==&quot;howarry01&quot;; Table 17: Displaying records 1 - 10 playerID SO klubeco01 269 scherma01 252 hernafe02 248 cuetojo01 242 strasst01 242 kershcl01 239 bumgama01 219 salech01 208 greinza01 207 kenneia01 207 How many different teams did Bartolo Colon pitch for? Click here for solution Bartolo Colon is a well-known journeyman pitcher in baseball. He has pitched with a lot of teams, but it wasn't until he played for the New York Mets when he needed to come to the plate. He had a weird batting stance that is funny to watch. He even hit a home run one season! SELECT playerID FROM people WHERE nameFirst==&#39;Bartolo&#39; AND nameLast==&#39;Colon&#39;; SELECT DISTINCT teamID FROM pitching WHERE playerID==&#39;colonba01&#39;; Table 18: 1 records playerID colonba01 How many times did Trevor Bauer come to bat (AB) in 2016? How many hits (H) did he get? Click here for solution Trevor Bauer is much more known for his pitching than he is known for hitting. This is common for pitchers, as many are not very good at hitting. SELECT playerID FROM people WHERE nameFirst==&quot;Trevor&quot; AND nameLast==&quot;Bauer&quot;; Table 19: 1 records playerID bauertr01 SELECT AB, H FROM batting WHERE playerID==&quot;bauertr01&quot; AND yearID==&quot;2016&quot;; Table 20: 1 records AB H 5 0 Let's compare Mike Trout and Giancarlo Stanton by season. Who has hit more RBIs in a season? Who has been caught stealing (CS) more in a season? Click here for solution Mike Trout and Giancarlo Stanton are considered two of the of the best hitters in Major League Baseball for very different reasons. Trout is an all-around player known for being indispensible, where Stanton is known as a power hitter. SELECT playerID, nameFirst, nameLast FROM people WHERE (nameFirst==&#39;Giancarlo&#39; AND nameLast==&#39;Stanton&#39;) OR (nameFirst==&#39;Mike&#39; AND nameLast==&#39;Trout&#39;); Table 21: 2 records playerID nameFirst nameLast stantmi03 Giancarlo Stanton troutmi01 Mike Trout SELECT playerID, yearID, teamID, RBI, CS FROM batting WHERE playerID==&#39;stantmi03&#39; OR playerID==&#39;troutmi01&#39; ORDER BY RBI DESC LIMIT 1; Table 22: 1 records playerID yearID teamID RBI CS stantmi03 2017 MIA 132 2 SELECT playerID, yearID, teamID, RBI, CS FROM batting WHERE playerID==&#39;stantmi03&#39; OR playerID==&#39;troutmi01&#39; ORDER BY CS DESC LIMIT 1; Table 23: 1 records playerID yearID teamID RBI CS troutmi01 2013 LAA 97 7 Make a list of players who walked (BB) more than they struck out (SO) between 1980 and 1985. Of these players, who walked the most? Use the BETWEEN command in this queries. Use a second query to get the player's first and last name. Click here for solution SELECT playerID, yearID, teamID, BB, SO FROM batting WHERE BB &gt; SO LIMIT 10; Table 24: Displaying records 1 - 10 playerID yearID teamID BB SO addybo01 1871 RC1 4 0 ansonca01 1871 RC1 2 1 barkeal01 1871 RC1 1 0 barnero01 1871 BS1 13 1 battijo01 1871 CL1 1 0 bealsto01 1871 WS3 2 0 bellast01 1871 TRO 9 2 berthha01 1871 WS3 4 2 biermch01 1871 FW1 1 0 birdge01 1871 RC1 3 2 SELECT nameFirst, nameLast FROM people WHERE playerID==&#39;randowi01&#39;; Table 25: 1 records nameFirst nameLast Willie Randolph How many different NL catchers (C) won gold glove winners between 1990 and 2000? Click here for solution There were 6 different catchers. SELECT DISTINCT playerID FROM awardsplayers WHERE awardID==&#39;Gold Glove&#39; AND notes==&#39;C&#39; AND lgID==&#39;NL&#39; AND yearID BETWEEN 1990 AND 2000; Table 26: 6 records playerID santibe01 pagnoto01 manwaki01 johnsch04 liebemi01 mathemi01 How many different 3rd Basemen played for the Seattle Mariners between 2000 and 2005? Who had the most Errors? Click here for solution SELECT DISTINCT playerID, yearID, E FROM fielding WHERE yearID BETWEEN 2000 AND 2005 AND teamID==&#39;SEA&#39; AND POS==&#39;3B&#39; ORDER BY E DESC LIMIT 10; Table 27: Displaying records 1 - 10 playerID yearID E guillca01 2000 17 bellda01 2001 14 beltrad01 2005 14 bellda01 2000 12 cirilje01 2002 9 leoneju01 2004 8 mclemma01 2001 7 spiezsc01 2004 7 bloomwi01 2004 5 mabryjo01 2000 4 SELECT nameFirst, nameLast FROM people WHERE playerID==&#39;camermi01&#39;; Table 28: 1 records nameFirst nameLast Mike Cameron Craig Biggio was more known for his play at second base over his major league baseball career, but he didn't always play second base. What seasons did Craig Biggio play Catcher? Click here for solution SELECT playerID FROM people WHERE nameFirst==&#39;Craig&#39; AND nameLast==&#39;Biggio&#39;; Table 29: 1 records playerID biggicr01 SELECT teamID, yearID, POS FROM fielding WHERE playerID==&#39;biggicr01&#39; AND POS==&#39;C&#39;; Table 30: 5 records teamID yearID POS HOU 1988 C HOU 1989 C HOU 1990 C HOU 1991 C HOU 2007 C Find the teams that have won the World Series that represented the National League. Display the list with the yearID and teamID in ascending order. Click here for solution SELECT teamID, yearID FROM teams WHERE WSWin==&#39;Y&#39; AND lgID==&#39;NL&#39; ORDER BY yearID ASC LIMIT 10; Table 31: Displaying records 1 - 10 teamID yearID PRO 1884 DTN 1887 NY1 1888 NY1 1889 NY1 1905 CHN 1907 CHN 1908 PIT 1909 BSN 1914 CIN 1919 List the pitchers that threw at least one complete game (CG) in the 1995 season. Please include the wins and losses of the top 10 pitchers. Use the playerID of the pitcher who threw the most complete games to find out the name of the pitcher that had the most complete games. Click here for solution SELECT playerID, W, L, CG FROM pitching WHERE CG &gt; 0 AND yearID==1995 ORDER BY CG DESC LIMIT 10; Table 32: Displaying records 1 - 10 playerID W L CG maddugr01 19 2 10 mcdowja01 15 10 8 ericksc01 9 4 7 leitema01 10 12 7 mussimi01 19 9 7 johnsra05 18 2 6 valdeis01 13 11 6 wakefti01 16 8 6 coneda01 9 6 5 fernaal01 12 8 5 SELECT nameFirst, nameLast FROM people WHERE playerID==&#39;maddugr01&#39;; Table 33: 1 records nameFirst nameLast Greg Maddux Who was the most recent player manager? Click here for solution SELECT playerID, yearID FROM managers WHERE plyrMgr==&#39;Y&#39; ORDER BY yearID DESC LIMIT 10; Table 34: Displaying records 1 - 10 playerID yearID rosepe01 1986 rosepe01 1985 rosepe01 1984 kessido01 1979 torrejo01 1977 robinfr02 1976 robinfr02 1975 tappeel01 1962 bauerha01 1961 hemusso01 1959 SELECT nameFirst, nameLast FROM people WHERE playerID==&#39;rosepe01&#39;; Table 35: 1 records nameFirst nameLast Pete Rose Get the at-bats, homeruns, stolen bases for Roberto Clemente by year in ascending order. Click here for solution Roberto Clemente is known as being a leader for the Pittsburgh Pirates. He died in a 1972 plane crash on a humanitarian mission to Puerto Rico, where he grew up. SELECT playerID FROM people WHERE nameFirst==&#39;Roberto&#39; AND nameLast==&#39;Clemente&#39;; Table 36: 1 records playerID clemero01 SELECT yearID,AB,HR,SB FROM battingpost WHERE playerID==&#39;clemero01&#39; ORDER BY yearID ASC; Table 37: 5 records yearID AB HR SB 1960 29 0 0 1970 14 0 0 1971 18 0 0 1971 29 2 0 1972 17 1 0 Get a list of distinct World Series winners from the years Tom Lasorda managed the Los Angeles Dodgers (LAN). First find the years Tom Lasorda was the manager of the Los Angeles Dodgers, and then find the distinct teams that won a World Series in that time frame. Click here for solution SELECT playerID FROM people WHERE nameFirst==&#39;Tom&#39; AND nameLast==&#39;Lasorda&#39;; Table 38: 1 records playerID lasorto01 SELECT yearID FROM managers WHERE playerID==&#39;lasorto01&#39; LIMIT 10; Table 39: Displaying records 1 - 10 yearID 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 SELECT DISTINCT teamID FROM teams WHERE WSWin==&#39;Y&#39; AND yearID BETWEEN 1976 AND 1996; Table 40: Displaying records 1 - 10 teamID CIN NYA PIT PHI LAN SLN BAL DET KCA NYN Which teams did Kenny Lofton steal more than 20 bases in a season after the year 2000? Click here for solution SELECT playerID FROM people WHERE nameFirst==&#39;Kenny&#39; AND nameLast==&#39;Lofton&#39;; Table 41: 1 records playerID loftoke01 SELECT teamID, yearID, SB FROM batting WHERE playerID==&#39;loftoke01&#39; AND SB &gt; 20 AND yearID &gt;2000; Table 42: 4 records teamID yearID SB CHA 2002 22 PHI 2005 22 LAN 2006 32 TEX 2007 21 How much did the Tampa Bay Rays (TBL) pay Wade Boggs in 1998? Who paid Boggs the most in a season during his career? Click here for solution SELECT playerID FROM people WHERE nameFirst==&#39;Wade&#39; AND nameLast==&#39;Boggs&#39;; Table 43: 1 records playerID boggswa01 SELECT teamID, yearID, salary FROM salaries WHERE playerID==&#39;boggswa01&#39; AND yearID==1998; Table 44: 1 records teamID yearID salary TBA 1998 1150000 SELECT teamID, yearID, salary FROM salaries WHERE playerID==&#39;boggswa01&#39; ORDER BY salary DESC LIMIT 10; Table 45: Displaying records 1 - 10 teamID yearID salary NYA 1995 4724316 NYA 1994 3200000 NYA 1993 2950000 BOS 1991 2750000 BOS 1992 2700000 NYA 1996 2050000 NYA 1997 2000000 BOS 1990 1900000 BOS 1989 1850000 BOS 1987 1675000 Click here for solution SELECT teamID, yearID, W, L, HR, HRA, attendance FROM teams WHERE teamID==&#39;DET&#39; AND (WSWin==&#39;Y&#39; OR LgWin==&#39;Y&#39;); Table 46: Displaying records 1 - 10 teamID yearID W L HR HRA attendance DET 1907 92 58 11 8 297079 DET 1908 90 63 19 12 436199 DET 1909 98 54 19 16 490490 DET 1934 101 53 74 86 919161 DET 1935 93 58 106 78 1034929 DET 1940 90 64 134 102 1112693 DET 1945 88 65 77 48 1280341 DET 1968 103 59 185 129 2031847 DET 1984 104 58 187 130 2704794 DET 2006 95 67 203 160 2595937 The standings you would find in a newspaper often have Wins and Losses in order of most to least wins. There are often other numbers that are involved like winning percentage, and other team statistics, but we won't deal with that for now. Get the NL East Standings in 2015. Click here for solution SELECT teamID, W, L FROM teams WHERE divID==&#39;E&#39; AND lgID==&#39;NL&#39; AND yearID==2015 ORDER BY teamrank ASC; Table 47: 5 records teamID W L NYN 90 72 WAS 83 79 MIA 71 91 ATL 67 95 PHI 63 99 Make a list of the teams, wins, losses, years for NL East teams that have won the World Series. Which team had the most wins? Click here for solution SELECT teamID, yearID, W, L FROM teams WHERE lgID==&#39;NL&#39; AND divID==&#39;E&#39; AND WSWin==&#39;Y&#39; ORDER BY W DESC; Table 48: Displaying records 1 - 10 teamID yearID W L NYN 1986 108 54 NYN 1969 100 62 PIT 1979 98 64 PIT 1971 97 65 WAS 2019 93 69 SLN 1982 92 70 FLO 1997 92 70 PHI 2008 92 70 PHI 1980 91 71 FLO 2003 91 71 Get a list of the playerIDs of managers who won more games than they lost between 1930 and 1950. Get the manager's name, and the name of the team of the manager with the most wins on the list. Click here for solution SELECT playerID, teamID, yearID, W, L FROM managers WHERE yearID BETWEEN 1930 AND 1950 AND W &gt; L ORDER BY W DESC LIMIT 10; Table 49: Displaying records 1 - 10 playerID teamID yearID W L mackco01 PHA 1931 107 45 mccarjo99 NYA 1932 107 47 mccarjo99 NYA 1939 106 45 southbi01 SLN 1942 106 48 southbi01 SLN 1943 105 49 southbi01 SLN 1944 105 49 durocle01 BRO 1942 104 50 cronijo01 BOS 1946 104 50 mccarjo99 NYA 1942 103 51 mackco01 PHA 1930 102 52 SELECT nameFirst, nameLast FROM people WHERE playerID==&#39;mackco01&#39;; Table 50: 1 records nameFirst nameLast Connie Mack SELECT franchName FROM teamsfranchises WHERE franchID==&#39;PHA&#39;; Table 51: 1 records franchName Philadelphia Athletics Get the top 5 seasons from Florida Teams (Florida Marlins, Tampa Bay Rays, and Miami Marlins) in attendance. How many have occured since 2000? Click here for solution Florida baseball teams are not known for their attendance for a variety of reasons. Both MLB franchises play in domed fields, but usually do not draw large crowds. SELECT franchID, franchName FROM teamsfranchises WHERE franchName==&#39;Tampa Bay Rays&#39; OR franchName==&#39;Florida Marlins&#39;; Table 52: 2 records franchID franchName FLA Florida Marlins TBD Tampa Bay Rays SELECT teamID, yearID, attendance FROM teams WHERE franchID==&#39;TBD&#39; OR franchID==&#39;FLA&#39; ORDER BY attendance DESC LIMIT 10; Table 53: Displaying records 1 - 10 teamID yearID attendance FLO 1993 3064847 TBA 1998 2506293 FLO 1997 2364387 MIA 2012 2219444 FLO 1994 1937467 TBA 2009 1874962 FLO 2005 1852608 TBA 2010 1843445 TBA 2008 1811986 MIA 2015 1752235 What pitcher has thrown the most Shutouts (SHO) in the AL since 2010? What about the NL? Please get their first and last names respectively. Click here for solution SELECT playerID,teamID, yearID, SHO FROM pitching WHERE yearID&gt;2010 AND lgID==&#39;NL&#39; ORDER BY SHO DESC LIMIT 10; Table 54: Displaying records 1 - 10 playerID teamID yearID SHO leecl02 PHI 2011 6 dickera01 NYN 2012 3 alvarhe01 MIA 2014 3 wainwad01 SLN 2014 3 arrieja01 CHN 2015 3 kershcl01 LAN 2015 3 scherma01 WAS 2015 3 kershcl01 LAN 2016 3 carpech01 SLN 2011 2 garcija02 SLN 2011 2 SELECT playerID,teamID, yearID, SHO FROM pitching WHERE yearID&gt;2010 AND lgID==&#39;AL&#39; ORDER BY SHO DESC LIMIT 10; Table 55: Displaying records 1 - 10 playerID teamID yearID SHO hernafe02 SEA 2012 5 hollade01 TEX 2011 4 shielja02 TBA 2011 4 harenda01 LAA 2011 3 vargaja01 SEA 2011 3 morrobr01 TOR 2012 3 colonba01 OAK 2013 3 masteju01 CLE 2013 3 porceri01 DET 2014 3 klubeco01 CLE 2017 3 SELECT nameFirst, nameLast FROM people WHERE playerID==&#39;leecl02&#39; OR playerID==&#39;hernafe02&#39;; Table 56: 2 records nameFirst nameLast Felix Hernandez Cliff Lee The following examples use the chinook.db sqlite database. dbListTables(chinook) ## [1] &quot;advisors&quot; &quot;albums&quot; &quot;artists&quot; &quot;customers&quot; ## [5] &quot;employees&quot; &quot;genres&quot; &quot;invoice_items&quot; &quot;invoices&quot; ## [9] &quot;media_types&quot; &quot;playlist_track&quot; &quot;playlists&quot; &quot;sqlite_sequence&quot; ## [13] &quot;sqlite_stat1&quot; &quot;students&quot; &quot;tracks&quot; How do I select all of the rows of a table called employees? Click here for solution SELECT * FROM employees; Table 57: 8 records EmployeeId LastName FirstName Title ReportsTo BirthDate HireDate Address City State Country PostalCode Phone Fax Email 1 Adams Andrew General Manager NA 1962-02-18 00:00:00 2002-08-14 00:00:00 11120 Jasper Ave NW Edmonton AB Canada T5K 2N1 +1 (780) 428-9482 +1 (780) 428-3457 andrew@chinookcorp.com 2 Edwards Nancy Sales Manager 1 1958-12-08 00:00:00 2002-05-01 00:00:00 825 8 Ave SW Calgary AB Canada T2P 2T3 +1 (403) 262-3443 +1 (403) 262-3322 nancy@chinookcorp.com 3 Peacock Jane Sales Support Agent 2 1973-08-29 00:00:00 2002-04-01 00:00:00 1111 6 Ave SW Calgary AB Canada T2P 5M5 +1 (403) 262-3443 +1 (403) 262-6712 jane@chinookcorp.com 4 Park Margaret Sales Support Agent 2 1947-09-19 00:00:00 2003-05-03 00:00:00 683 10 Street SW Calgary AB Canada T2P 5G3 +1 (403) 263-4423 +1 (403) 263-4289 margaret@chinookcorp.com 5 Johnson Steve Sales Support Agent 2 1965-03-03 00:00:00 2003-10-17 00:00:00 7727B 41 Ave Calgary AB Canada T3B 1Y7 1 (780) 836-9987 1 (780) 836-9543 steve@chinookcorp.com 6 Mitchell Michael IT Manager 1 1973-07-01 00:00:00 2003-10-17 00:00:00 5827 Bowness Road NW Calgary AB Canada T3B 0C5 +1 (403) 246-9887 +1 (403) 246-9899 michael@chinookcorp.com 7 King Robert IT Staff 6 1970-05-29 00:00:00 2004-01-02 00:00:00 590 Columbia Boulevard West Lethbridge AB Canada T1K 5N8 +1 (403) 456-9986 +1 (403) 456-8485 robert@chinookcorp.com 8 Callahan Laura IT Staff 6 1968-01-09 00:00:00 2004-03-04 00:00:00 923 7 ST NW Lethbridge AB Canada T1H 1Y8 +1 (403) 467-3351 +1 (403) 467-8772 laura@chinookcorp.com How do I select the first 5 rows of a table called employees? Click here for solution SELECT * FROM employees LIMIT 5; Table 58: 5 records EmployeeId LastName FirstName Title ReportsTo BirthDate HireDate Address City State Country PostalCode Phone Fax Email 1 Adams Andrew General Manager NA 1962-02-18 00:00:00 2002-08-14 00:00:00 11120 Jasper Ave NW Edmonton AB Canada T5K 2N1 +1 (780) 428-9482 +1 (780) 428-3457 andrew@chinookcorp.com 2 Edwards Nancy Sales Manager 1 1958-12-08 00:00:00 2002-05-01 00:00:00 825 8 Ave SW Calgary AB Canada T2P 2T3 +1 (403) 262-3443 +1 (403) 262-3322 nancy@chinookcorp.com 3 Peacock Jane Sales Support Agent 2 1973-08-29 00:00:00 2002-04-01 00:00:00 1111 6 Ave SW Calgary AB Canada T2P 5M5 +1 (403) 262-3443 +1 (403) 262-6712 jane@chinookcorp.com 4 Park Margaret Sales Support Agent 2 1947-09-19 00:00:00 2003-05-03 00:00:00 683 10 Street SW Calgary AB Canada T2P 5G3 +1 (403) 263-4423 +1 (403) 263-4289 margaret@chinookcorp.com 5 Johnson Steve Sales Support Agent 2 1965-03-03 00:00:00 2003-10-17 00:00:00 7727B 41 Ave Calgary AB Canada T3B 1Y7 1 (780) 836-9987 1 (780) 836-9543 steve@chinookcorp.com How do I select specific rows of a table called employees? Click here for solution SELECT LastName, FirstName FROM employees; Table 59: 8 records LastName FirstName Adams Andrew Edwards Nancy Peacock Jane Park Margaret Johnson Steve Mitchell Michael King Robert Callahan Laura You can switch the order in which the columns are displayed as well: SELECT FirstName, LastName FROM employees; Table 60: 8 records FirstName LastName Andrew Adams Nancy Edwards Jane Peacock Margaret Park Steve Johnson Michael Mitchell Robert King Laura Callahan How do I select only unique values from a column? Click here for solution SELECT DISTINCT Title FROM employees; Table 61: 5 records Title General Manager Sales Manager Sales Support Agent IT Manager IT Staff How can I filter that match a certain criteria? Click here for solution Select only employees with a FirstName &quot;Steve&quot;: SELECT * FROM employees WHERE FirstName=&#39;Steve&#39;; Table 62: 1 records EmployeeId LastName FirstName Title ReportsTo BirthDate HireDate Address City State Country PostalCode Phone Fax Email 5 Johnson Steve Sales Support Agent 2 1965-03-03 00:00:00 2003-10-17 00:00:00 7727B 41 Ave Calgary AB Canada T3B 1Y7 1 (780) 836-9987 1 (780) 836-9543 steve@chinookcorp.com Select only employees with FirstName &quot;Steve&quot; OR FirstName &quot;Laura&quot;: SELECT * FROM employees WHERE FirstName=&#39;Steve&#39; OR FirstName=&#39;Laura&#39;; Table 63: 2 records EmployeeId LastName FirstName Title ReportsTo BirthDate HireDate Address City State Country PostalCode Phone Fax Email 5 Johnson Steve Sales Support Agent 2 1965-03-03 00:00:00 2003-10-17 00:00:00 7727B 41 Ave Calgary AB Canada T3B 1Y7 1 (780) 836-9987 1 (780) 836-9543 steve@chinookcorp.com 8 Callahan Laura IT Staff 6 1968-01-09 00:00:00 2004-03-04 00:00:00 923 7 ST NW Lethbridge AB Canada T1H 1Y8 +1 (403) 467-3351 +1 (403) 467-8772 laura@chinookcorp.com Select only employees with FirstName &quot;Steve&quot; AND LastName &quot;Laura&quot;: SELECT * FROM employees WHERE FirstName=&#39;Steve&#39; AND LastName=&#39;Laura&#39;; Table 64: 0 records EmployeeId LastName FirstName Title ReportsTo BirthDate HireDate Address City State Country PostalCode Phone Fax Email As expected, there are no results! There is nobody with the full name &quot;Steve Laura&quot;. List the first 10 tracks from the tracks table. Click here for solution SELECT * FROM tracks LIMIT 10; Table 65: Displaying records 1 - 10 TrackId Name AlbumId MediaTypeId GenreId Composer Milliseconds Bytes UnitPrice 1 For Those About To Rock (We Salute You) 1 1 1 Angus Young, Malcolm Young, Brian Johnson 343719 11170334 0.99 2 Balls to the Wall 2 2 1 NA 342562 5510424 0.99 3 Fast As a Shark 3 2 1 F. Baltes, S. Kaufman, U. Dirkscneider &amp; W. Hoffman 230619 3990994 0.99 4 Restless and Wild 3 2 1 F. Baltes, R.A. Smith-Diesel, S. Kaufman, U. Dirkscneider &amp; W. Hoffman 252051 4331779 0.99 5 Princess of the Dawn 3 2 1 Deaffy &amp; R.A. Smith-Diesel 375418 6290521 0.99 6 Put The Finger On You 1 1 1 Angus Young, Malcolm Young, Brian Johnson 205662 6713451 0.99 7 Let's Get It Up 1 1 1 Angus Young, Malcolm Young, Brian Johnson 233926 7636561 0.99 8 Inject The Venom 1 1 1 Angus Young, Malcolm Young, Brian Johnson 210834 6852860 0.99 9 Snowballed 1 1 1 Angus Young, Malcolm Young, Brian Johnson 203102 6599424 0.99 10 Evil Walks 1 1 1 Angus Young, Malcolm Young, Brian Johnson 263497 8611245 0.99 How many rows or records are in the table named tracks? Click here for solution SELECT COUNT(*) FROM tracks; Table 66: 1 records COUNT(*) 3503 Are there any artists with the names: &quot;Elis Regina&quot;, &quot;Seu Jorge&quot;, or &quot;The Beatles&quot;? Click here for solution SELECT * FROM artists WHERE Name=&#39;Elis Regina&#39; OR Name=&#39;Seu Jorge&#39; OR Name=&#39;The Beatles&#39;; Table 67: 2 records ArtistId Name 41 Elis Regina 193 Seu Jorge What albums did the artist with ArtistId of 41 make? Click here for solution SELECT * FROM albums WHERE ArtistId=41; Table 68: 1 records AlbumId Title ArtistId 71 Elis Regina-Minha História 41 What are the tracks of the album with AlbumId of 71? Order the results from most Milliseconds to least. Click here for solution SELECT * FROM tracks WHERE AlbumId=71 ORDER BY Milliseconds DESC; Table 69: Displaying records 1 - 10 TrackId Name AlbumId MediaTypeId GenreId Composer Milliseconds Bytes UnitPrice 890 Aprendendo A Jogar 71 1 7 NA 290664 9391041 0.99 886 Saudosa Maloca 71 1 7 NA 278125 9059416 0.99 880 Dois Pra Lá, Dois Pra Cá 71 1 7 NA 263026 8684639 0.99 887 As Aparências Enganam 71 1 7 NA 247379 8014346 0.99 882 Romaria 71 1 7 NA 242834 7968525 0.99 883 Alô, Alô, Marciano 71 1 7 NA 241397 8137254 0.99 889 Maria Rosa 71 1 7 NA 232803 7592504 0.99 877 O Bêbado e a Equilibrista 71 1 7 NA 223059 7306143 0.99 884 Me Deixas Louca 71 1 7 NA 214831 6888030 0.99 878 O Mestre-Sala dos Mares 71 1 7 NA 186226 6180414 0.99 What are the tracks of the album with AlbumId of 71? Order the results from longest to shortest and convert Milliseconds to seconds. Use aliasing to name the calculated field Seconds. Click here for solution SELECT Milliseconds/1000.0 AS Seconds, * FROM tracks WHERE AlbumId=71 ORDER BY Seconds DESC; Table 70: Displaying records 1 - 10 Seconds TrackId Name AlbumId MediaTypeId GenreId Composer Milliseconds Bytes UnitPrice 290.664 890 Aprendendo A Jogar 71 1 7 NA 290664 9391041 0.99 278.125 886 Saudosa Maloca 71 1 7 NA 278125 9059416 0.99 263.026 880 Dois Pra Lá, Dois Pra Cá 71 1 7 NA 263026 8684639 0.99 247.379 887 As Aparências Enganam 71 1 7 NA 247379 8014346 0.99 242.834 882 Romaria 71 1 7 NA 242834 7968525 0.99 241.397 883 Alô, Alô, Marciano 71 1 7 NA 241397 8137254 0.99 232.803 889 Maria Rosa 71 1 7 NA 232803 7592504 0.99 223.059 877 O Bêbado e a Equilibrista 71 1 7 NA 223059 7306143 0.99 214.831 884 Me Deixas Louca 71 1 7 NA 214831 6888030 0.99 186.226 878 O Mestre-Sala dos Mares 71 1 7 NA 186226 6180414 0.99 What are the tracks that are at least 250 seconds long? Click here for solution SELECT Milliseconds/1000.0 AS Seconds, * FROM tracks WHERE Seconds &gt;= 250; Table 71: Displaying records 1 - 10 Seconds TrackId Name AlbumId MediaTypeId GenreId Composer Milliseconds Bytes UnitPrice 343.719 1 For Those About To Rock (We Salute You) 1 1 1 Angus Young, Malcolm Young, Brian Johnson 343719 11170334 0.99 342.562 2 Balls to the Wall 2 2 1 NA 342562 5510424 0.99 252.051 4 Restless and Wild 3 2 1 F. Baltes, R.A. Smith-Diesel, S. Kaufman, U. Dirkscneider &amp; W. Hoffman 252051 4331779 0.99 375.418 5 Princess of the Dawn 3 2 1 Deaffy &amp; R.A. Smith-Diesel 375418 6290521 0.99 263.497 10 Evil Walks 1 1 1 Angus Young, Malcolm Young, Brian Johnson 263497 8611245 0.99 263.288 12 Breaking The Rules 1 1 1 Angus Young, Malcolm Young, Brian Johnson 263288 8596840 0.99 270.863 14 Spellbound 1 1 1 Angus Young, Malcolm Young, Brian Johnson 270863 8817038 0.99 331.180 15 Go Down 4 1 1 AC/DC 331180 10847611 0.99 366.654 17 Let There Be Rock 4 1 1 AC/DC 366654 12021261 0.99 267.728 18 Bad Boy Boogie 4 1 1 AC/DC 267728 8776140 0.99 What are the tracks that are between 250 and 300 seconds long? Click here for solution SELECT Milliseconds/1000.0 AS Seconds, * FROM tracks WHERE Seconds BETWEEN 250 AND 300 ORDER BY Seconds; Table 72: Displaying records 1 - 10 Seconds TrackId Name AlbumId MediaTypeId GenreId Composer Milliseconds Bytes UnitPrice 250.017 1992 Lithium 163 1 1 Kurt Cobain 250017 8148800 0.99 250.031 3421 Nimrod (Adagio) from Variations On an Original Theme, Op. 36 &quot;Enigma&quot; 290 2 24 Edward Elgar 250031 4124707 0.99 250.070 2090 Romance Ideal 169 1 7 NA 250070 8260477 0.99 250.122 2451 Ela Desapareceu 199 1 1 Chico Amaral/Samuel Rosa 250122 8289200 0.99 250.226 2184 Thumbing My Way 180 1 1 Eddie Vedder 250226 8201437 0.99 250.253 2728 Pulse 220 1 4 The Tea Party 250253 8183872 0.99 250.357 974 Edge Of The World 77 1 4 Faith No More 250357 8235607 0.99 250.462 1530 Sem Sentido 123 1 7 NA 250462 8292108 0.99 250.565 3371 Wooden Jesus 269 2 23 NA 250565 4302603 0.99 250.697 2504 Real Love 202 1 4 Billy Corgan 250697 8025896 0.99 What is the GenreId of the genre with name Pop? Click here for solution SELECT GenreId FROM genres WHERE Name=&#39;Pop&#39;; Table 73: 1 records GenreId 9 What is the average length (in seconds) of a track with genre &quot;Pop&quot;? Click here for solution SELECT AVG(Milliseconds/1000.0) AS avg FROM tracks WHERE genreId=9; Table 74: 1 records avg 229.0341 What is the longest Bossa Nova track (in seconds)? Click here for solution What is the GenreId of Bossa Nova? SELECT GenreId FROM genres WHERE Name=&#39;Bossa Nova&#39;; Table 75: 1 records GenreId 11 SELECT *, MAX(Milliseconds/1000.0) AS Seconds FROM tracks WHERE genreId=11; Table 76: 1 records TrackId Name AlbumId MediaTypeId GenreId Composer Milliseconds Bytes UnitPrice Seconds 646 Samba Da Bênção 52 1 11 NA 409965 13490008 0.99 409.965 Get the average price per hour for Bossa Nova music (genreId of 11). Click here for solution SELECT AVG(UnitPrice/Milliseconds/1000.0/3600) AS &#39;Price per Hour&#39; FROM tracks WHERE genreId=11; Table 77: 1 records Price per Hour 0 Get the average time (in seconds) for tracks by genre. Click here for solution SELECT genreId, AVG(Milliseconds/1000.0) AS &#39;Average seconds per track&#39; FROM tracks GROUP BY genreId; Table 78: Displaying records 1 - 10 GenreId Average seconds per track 1 283.9100 2 291.7554 3 309.7494 4 234.3538 5 134.6435 6 270.3598 7 232.8593 8 247.1778 9 229.0341 10 244.3709 We can use an INNER JOIN to get the name of each genre as well. {#sql-inner-join} SELECT g.Name, track_time.&#39;Average seconds per track&#39; FROM genres AS g INNER JOIN (SELECT genreId, AVG(Milliseconds/1000.0) AS &#39;Average seconds per track&#39; FROM tracks GROUP BY genreId) AS track_time ON g.GenreId=track_time.GenreId ORDER BY track_time.&#39;Average seconds per track&#39; DESC; Table 79: Displaying records 1 - 10 Name Average seconds per track Sci Fi &amp; Fantasy 2911.7830 Science Fiction 2625.5491 Drama 2575.2838 TV Shows 2145.0410 Comedy 1585.2637 Metal 309.7494 Electronica/Dance 302.9858 Heavy Metal 297.4529 Classical 293.8676 Jazz 291.7554 What is the average price per track for each genre? Click here for solution SELECT genreId, AVG(UnitPrice) AS &#39;Average seconds per track&#39; FROM tracks GROUP BY genreId; Table 80: Displaying records 1 - 10 GenreId Average seconds per track 1 0.99 2 0.99 3 0.99 4 0.99 5 0.99 6 0.99 7 0.99 8 0.99 9 0.99 10 0.99 What is the average number of tracks per album? Click here for solution SELECT AVG(trackCount) FROM (SELECT COUNT(*) AS trackCount FROM tracks GROUP BY albumId) AS track_count; Table 81: 1 records AVG(trackCount) 10.0951 What is the average number of tracks per album per genre? Click here for solution SELECT genreId, AVG(trackCount) FROM (SELECT genreId, COUNT(*) AS trackCount FROM tracks GROUP BY albumId) AS track_count GROUP BY genreId; Table 82: Displaying records 1 - 10 genreId AVG(trackCount) 1 11.41379 2 10.00000 3 10.90625 4 14.43478 5 12.00000 6 13.85714 7 14.81579 8 15.00000 9 16.00000 10 10.75000 SELECT Name, avg_track_count.&#39;Average Track Count&#39; FROM genres AS g INNER JOIN (SELECT genreId, AVG(trackCount) AS &#39;Average Track Count&#39; FROM (SELECT genreId, COUNT(*) AS trackCount FROM tracks GROUP BY albumId) AS track_count GROUP BY genreId) AS avg_track_count ON g.GenreId=avg_track_count.genreId; Table 83: Displaying records 1 - 10 Name Average Track Count Rock 11.41379 Jazz 10.00000 Metal 10.90625 Alternative &amp; Punk 14.43478 Rock And Roll 12.00000 Blues 13.85714 Latin 14.81579 Reggae 15.00000 Pop 16.00000 Soundtrack 10.75000 The following examples us the lahman.db sqlite database. dbListTables(lahman) ## [1] &quot;allstarfull&quot; &quot;appearances&quot; &quot;awardsmanagers&quot; ## [4] &quot;awardsplayers&quot; &quot;awardssharemanagers&quot; &quot;awardsshareplayers&quot; ## [7] &quot;batting&quot; &quot;battingpost&quot; &quot;collegeplaying&quot; ## [10] &quot;divisions&quot; &quot;fielding&quot; &quot;fieldingof&quot; ## [13] &quot;fieldingofsplit&quot; &quot;fieldingpost&quot; &quot;halloffame&quot; ## [16] &quot;homegames&quot; &quot;leagues&quot; &quot;managers&quot; ## [19] &quot;managershalf&quot; &quot;parks&quot; &quot;people&quot; ## [22] &quot;pitching&quot; &quot;pitchingpost&quot; &quot;salaries&quot; ## [25] &quot;schools&quot; &quot;seriespost&quot; &quot;teams&quot; ## [28] &quot;teamsfranchises&quot; &quot;teamshalf&quot; "],
["r.html", "R Getting started Variables Logical operators Lists &amp; Vectors Basic R functions Data.frames Reading &amp; Writing data Control flow Apply functions Writing functions Plotting RMarkdown Tidyverse data.table SQL in R Scraping shiny", " R Getting started Examples using the 84.51 data set. Please see https://piazza.com/class/kdrxb6dxa8c6by?cid=110 for example code, to go along with this video. Click here for video Please see https://piazza.com/class/kdrxb6dxa8c6by?cid=110 for example code, to go along with this video. We read in the data from the 8451 data set (This is not the same data set from Project 2! It is only intended to give you an idea about how to use basic functions in R!) The read.csv function is used to read in a data frame. The variable myDF will be a data frame that stores the data. myDF &lt;- read.csv(&quot;/class/datamine/data/8451/The_Complete_Journey_2_Master/5000_transactions.csv&quot;) Please give the data frame a minute or two, to load. It is big! The data frame has 10625553 rows and 9 columns: dim(myDF) ## [1] 1000000 9 This is the data that describes the first 6 purchases: head(myDF) ## BASKET_NUM HSHD_NUM PURCHASE_ PRODUCT_NUM SPEND UNITS STORE_R WEEK_NUM YEAR ## 1 24 1809 03-JAN-16 5817389 -1.50 -1 SOUTH 1 2016 ## 2 24 1809 03-JAN-16 5829886 -1.50 -1 SOUTH 1 2016 ## 3 34 1253 03-JAN-16 539501 2.19 1 EAST 1 2016 ## 4 60 1595 03-JAN-16 5260099 0.99 1 WEST 1 2016 ## 5 60 1595 03-JAN-16 4535660 2.50 2 WEST 1 2016 ## 6 168 3393 03-JAN-16 5602916 4.50 1 SOUTH 1 2016 Similarly, these are the amounts spent on the first 6 purchases. We use the dollar sign to pull out a specific column of the data and focus (only) on that column. head(myDF$SPEND) ## [1] -1.50 -1.50 2.19 0.99 2.50 4.50 These first 6 values in the SPEND column add up to a total sum of 7.18 (you can check by hand if you like!) sum(head(myDF$SPEND)) ## [1] 7.18 The average of the first 6 values in the SPEND column is 1.196667 mean(head(myDF$SPEND)) ## [1] 1.196667 The first 100 values in the SPEND column are: head(myDF$SPEND, n=100) ## [1] -1.50 -1.50 2.19 0.99 2.50 4.50 3.49 2.79 1.00 9.98 1.29 1.79 ## [13] 3.99 1.00 2.00 10.80 3.49 1.00 3.99 1.88 0.49 2.49 1.99 2.50 ## [25] 1.67 1.99 5.50 7.89 6.49 1.00 2.78 3.69 1.19 0.69 3.00 5.99 ## [37] 8.19 3.49 4.29 5.66 0.99 5.99 0.99 8.11 12.82 7.99 4.19 1.49 ## [49] 4.96 3.49 4.49 2.79 2.99 5.49 3.99 12.00 3.79 0.89 4.99 2.29 ## [61] 1.69 5.78 6.99 2.00 3.89 6.77 2.69 4.99 3.20 14.40 6.93 2.50 ## [73] 1.00 5.98 1.75 1.19 4.25 3.00 1.11 0.98 8.17 13.10 17.98 4.38 ## [85] 5.79 3.59 4.99 11.56 3.42 2.99 17.99 1.50 -0.38 3.14 2.49 3.99 ## [97] 3.39 1.49 0.53 1.25 Note that, in the line above, we have an &quot;index&quot; at the far left-hand side of the Console. It shows the position of the first value on each line. The values will change, depending on how wide your screen is. Here is the 1st value in the SPEND column: myDF$SPEND[1] ## [1] -1.5 Here is the 22nd value in the SPEND column: myDF$SPEND[22] ## [1] 2.49 Here is the 25th value in the SPEND column: myDF$SPEND[25] ## [1] 1.67 Here are the last 20 values in the SPEND column. (Notice that we changed head to tail, since tail refers to the end rather than the start.) tail(myDF$SPEND, n=20) ## [1] 1.00 1.39 19.98 2.97 0.89 2.89 5.99 1.79 1.99 1.34 1.34 1.99 ## [13] 6.49 4.00 1.00 8.00 3.79 2.99 3.00 4.99 We can load the help menu for a function in R by using a question mark before the function name. It takes some time to get familiar with the style of the R help menus, but once you get comfortable reading the help pages, they are very helpful indeed! ?head We already took an average of the first 6 entries in the SPEND column. Now we can take an average of the entire SPEND column. mean(myDF$SPEND) ## [1] 3.584366 Again, here are the first six entries in the SPEND column. head(myDF$SPEND) ## [1] -1.50 -1.50 2.19 0.99 2.50 4.50 Suppose that we want to see which entires are bigger than 2 and which ones are smaller than 2. Here are the first six results: head(myDF$SPEND &gt; 2) ## [1] FALSE FALSE TRUE FALSE TRUE TRUE Now we can see what the actual values are. Here are the first 100 such values that are each bigger than 2. head(myDF$SPEND[myDF$SPEND &gt; 2], n=100) ## [1] 2.19 2.50 4.50 3.49 2.79 9.98 3.99 10.80 3.49 3.99 2.49 2.50 ## [13] 5.50 7.89 6.49 2.78 3.69 3.00 5.99 8.19 3.49 4.29 5.66 5.99 ## [25] 8.11 12.82 7.99 4.19 4.96 3.49 4.49 2.79 2.99 5.49 3.99 12.00 ## [37] 3.79 4.99 2.29 5.78 6.99 3.89 6.77 2.69 4.99 3.20 14.40 6.93 ## [49] 2.50 5.98 4.25 3.00 8.17 13.10 17.98 4.38 5.79 3.59 4.99 11.56 ## [61] 3.42 2.99 17.99 3.14 2.49 3.99 3.39 8.99 3.34 14.38 5.49 2.47 ## [73] 3.49 5.98 7.99 5.98 5.77 4.00 5.49 3.79 3.34 3.69 2.39 10.00 ## [85] 2.97 5.00 4.79 3.49 5.99 3.99 4.99 3.49 4.54 2.79 2.68 6.78 ## [97] 7.99 3.47 2.69 3.49 You might want to plot the first 50 values in the SPEND column: plot(head(myDF$SPEND, n=50)) If the result says Error in plot.new() : figure margins too large then you just need to make your plotting window a little bigger, so that R has room to make the plot, and then run the line again. There are 10625553 entries in the SPEND column: length(myDF$SPEND) ## [1] 1000000 This makes sense, because the data frame has 10625553 rows and 9 columns. dim(myDF) ## [1] 1000000 9 There are 6322739 entries larger than 2. length(myDF$SPEND[myDF$SPEND &gt; 2]) ## [1] 593322 There are 451155 entries larger than 10. length(myDF$SPEND[myDF$SPEND &gt; 10]) ## [1] 42202 There are 4197 entries less than -3. length(myDF$SPEND[myDF$SPEND &lt;= -3]) ## [1] 420 We encourage you to play with the data sets, and to learn how to work with the data, by trying things yourself, and by asking questions. We always welcome your questions, and we love for you to post questions on Piazza. This is a great way for the entire community to learn together! Examples using the New York City yellow taxi cab data set. Please see https://piazza.com/class/kdrxb6dxa8c6by?cid=110 for example code, to go along with this video. Click here for video This data set contains the information about the yellow taxi cab rides in New York City in June 2019. myDF &lt;- read.csv(&quot;/class/datamine/data/taxi/yellow/yellow_tripdata_2019-06.csv&quot;) Here is the information about the first 6 taxi cab rides. You need to imagine that your computer monitor is much, much wider than it actually is, so that your data has room to stretch out in 6 rows across your screen. Instead, right now, the data wraps around, a few columns at a time. This is probably obvious when you look at it. Each column has a column header. head(myDF) ## VendorID tpep_pickup_datetime tpep_dropoff_datetime passenger_count ## 1 1 2019-06-01 00:55:13 2019-06-01 00:56:17 1 ## 2 1 2019-06-01 00:06:31 2019-06-01 00:06:52 1 ## 3 1 2019-06-01 00:17:05 2019-06-01 00:36:38 1 ## 4 1 2019-06-01 00:59:02 2019-06-01 00:59:12 0 ## 5 1 2019-06-01 00:03:25 2019-06-01 00:15:42 1 ## 6 1 2019-06-01 00:28:31 2019-06-01 00:39:23 2 ## trip_distance RatecodeID store_and_fwd_flag PULocationID DOLocationID ## 1 0.0 1 N 145 145 ## 2 0.0 1 N 262 263 ## 3 4.4 1 N 74 7 ## 4 0.8 1 N 145 145 ## 5 1.7 1 N 113 148 ## 6 1.6 1 N 79 125 ## payment_type fare_amount extra mta_tax tip_amount tolls_amount ## 1 2 3.0 0.5 0.5 0.00 0 ## 2 2 2.5 3.0 0.5 0.00 0 ## 3 2 17.5 0.5 0.5 0.00 0 ## 4 2 2.5 1.0 0.5 0.00 0 ## 5 1 9.5 3.0 0.5 2.65 0 ## 6 1 9.5 3.0 0.5 1.00 0 ## improvement_surcharge total_amount congestion_surcharge ## 1 0.3 4.30 0.0 ## 2 0.3 6.30 2.5 ## 3 0.3 18.80 0.0 ## 4 0.3 4.30 0.0 ## 5 0.3 15.95 2.5 ## 6 0.3 14.30 2.5 The mean cost (i.e., the average cost) of a taxi cab ride in New York City in June 2019 is 19.74, i.e., almost 20 dollars. mean(myDF$total_amount) ## [1] 19.33511 The mean number of passengers in a taxi cab ride is 1.567322. mean(myDF$passenger_count) ## [1] 1.567329 We can use the table function to tabulate the results of the number of taxi cab rides, according to the passenger_count For instance, in this case, there are 128130 taxi cab rides with 0 passengers, there are 4854651 taxi cab rides with 1 passenger, there are 1061648 taxi cab rides with 2 passengers, etc. table(myDF$passenger_count) ## ## 0 1 2 3 4 5 6 7 8 9 ## 19336 697349 154878 43720 20051 39156 25497 8 3 2 We can look at each passenger_count for which the passenger_count equals 4. Of course, the results are all just the value 4! head(myDF$passenger_count[myDF$passenger_count == 4]) ## [1] 4 4 4 4 4 4 On a more interesting note, we can look at the total cost of a taxi cab ride with 4 passengers. The first 6 rides that (each) have 4 passengers have these 6 costs: head(myDF$total_amount[myDF$passenger_count == 4]) ## [1] 8.30 16.80 14.80 9.95 10.30 37.56 The average cost of a taxi cab ride with 4 passengers is 20.42111, i.e., just a little more than 20 dollars. mean(myDF$total_amount[myDF$passenger_count == 4]) ## [1] 19.73445 Altogether, our data set has 6941024 rows and 18 columns. dim(myDF) ## [1] 1000000 18 For this reason, the total_amount column has 6941024 entries. length(myDF$total_amount) ## [1] 1000000 The amounts of the first 6 taxi cab rides are: head(myDF$total_amount) ## [1] 4.30 6.30 18.80 4.30 15.95 14.30 These are the amounts of the first 6 taxi cab rides that each cost more than 100 dollars. head(myDF$total_amount[myDF$total_amount &gt; 100]) ## [1] 104.30 120.80 158.90 181.30 112.35 116.30 There are 16681 taxi cab rides that (each) cost more than 100 dollars. length(myDF$total_amount[myDF$total_amount &gt; 100]) ## [1] 2180 If we only include the taxi cab rides that (each) cost more than 100 dollars, the average number of passengers is 1.545051. mean(myDF$passenger_count[myDF$total_amount &gt; 100]) ## [1] 1.563303 There are 6941024 taxi cab rides altogether. length(myDF$passenger_count) ## [1] 1000000 If we ask for the length of the taxi cab rides with total_amount &gt; 100, we might expect to get a smaller number, but again we get 6941024. length(myDF$total_amount &gt; 100) ## [1] 1000000 This might be confusing at first, but we can look at the head of those results. This is a vector of 6941024 occurrences of TRUE and FALSE, one per taxi cab ride. head(myDF$total_amount &gt; 100) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE The way to find out that there are only 16681 taxi cab rides that cost more than 100 dollars is (as we did before) to use the TRUE values as an index into another vector, like this: length(myDF$total_amount[myDF$total_amount &gt; 100]) ## [1] 2180 or like this sum(myDF$total_amount &gt; 100) ## [1] 2180 In this latter method, we turn the TRUE values into 1's and the FALSE values into 0's (this happens automatically when we sum them up) and so we have 16681 values of 1's and the rest are 0's so the sum is 16681, just like we saw above. Variables NA NA stands for not available and, in general, represents a missing value or a lack of data. How do I tell if a value is NA? Click here for solution # Test if value is NA. value &lt;- NA is.na(value) ## [1] TRUE # Does is.nan return TRUE for NA? is.nan(value) ## [1] FALSE NaN NaN stands for not a number and, in general, is used for arithmetic purposes, for example, the result of 0/0. How do I tell if a value is NaN? Click here for solution # Test if a value is NaN. value &lt;- NaN is.nan(value) ## [1] TRUE value &lt;- 0/0 is.nan(value) ## [1] TRUE # Does is.na return TRUE for NaN? is.na(value) ## [1] TRUE NULL NULL represents the null object, and is often returned when we have undefined values. How do I tell if a value is NULL? Click here for solution # Test if a value is NaN. value &lt;- NULL is.null(value) ## [1] TRUE class(value) ## [1] &quot;NULL&quot; # Does is.na return TRUE for NULL? is.na(value) ## logical(0) Dates Date is a class which allows you to perform special operations like subtraction, where the number of days between dates are returned. Or addition, where you can add 30 to a Date and a Date is returned where the value is 30 days in the future. You will usually need to specify the format argument based on the format of your date strings. For example, if you had a string 07/05/1990, the format would be: %m/%d/%Y. If your string was 31-12-90, the format would be %d-%m-%y. Replace %d, %m, %Y, and %y according to your date strings. A full list of formats can be found here. How do I convert a string &quot;07/05/1990&quot; to a Date? Click here for solution my_string &lt;- &quot;07/05/1990&quot; my_date &lt;- as.Date(my_string, format=&quot;%m/%d/%Y&quot;) my_date ## [1] &quot;1990-07-05&quot; How do I convert a string &quot;31-12-1990&quot; to a Date? Click here for solution my_string &lt;- &quot;31-12-1990&quot; my_date &lt;- as.Date(my_string, format=&quot;%d-%m-%Y&quot;) my_date ## [1] &quot;1990-12-31&quot; How do I convert a string &quot;12-31-1990&quot; to a Date? Click here for solution my_string &lt;- &quot;12-31-1990&quot; my_date &lt;- as.Date(my_string, format=&quot;%m-%d-%Y&quot;) my_date ## [1] &quot;1990-12-31&quot; How do I convert a string &quot;31121990&quot; to a Date? Click here for solution my_string &lt;- &quot;31121990&quot; my_date &lt;- as.Date(my_string, format=&quot;%d%m%Y&quot;) my_date ## [1] &quot;1990-12-31&quot; Factors A factor is R's way of representing a categorical variable. There are entries in a factor (just like there are entries in a vector), but they are constrained to only be chosen from a specific set of values, called the levels of the factor. They are useful when a vector has only a few different values it could be, like &quot;Male&quot; and &quot;Female&quot; or &quot;A&quot;, &quot;B&quot;, or &quot;C&quot;. How do I test whether or not a vector is a factor? Click here for solution test_factor &lt;- factor(&quot;Male&quot;) is.factor(test_factor) ## [1] TRUE test_factor_vec &lt;- factor(c(&quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;)) is.factor(test_factor_vec) ## [1] TRUE How do I convert a vector of strings to a factor? Click here for solution vec &lt;- c(&quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;) vec &lt;- factor(c(&quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;)) How do I get the unique values a factor could hold, also known as levels? Click here for solution vec &lt;- factor(c(&quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;)) levels(vec) ## [1] &quot;Female&quot; &quot;Male&quot; How can I rename the levels of a factor? Click here for solution vec &lt;- factor(c(&quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;)) levels(vec) ## [1] &quot;Female&quot; &quot;Male&quot; levels(vec) &lt;- c(&quot;F&quot;, &quot;M&quot;) vec ## [1] M F F ## Levels: F M # Be careful! Order matters, this is wrong: vec &lt;- factor(c(&quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;)) levels(vec) ## [1] &quot;Female&quot; &quot;Male&quot; levels(vec) &lt;- c(&quot;M&quot;, &quot;F&quot;) vec ## [1] F M M ## Levels: M F How can I find the number of levels of a factor? Click here for solution vec &lt;- factor(c(&quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;)) nlevels(vec) ## [1] 2 Logical operators Logical operators are symbols that can be used within R to compare values or vectors of values. Operator Description &lt; less than &lt;= less than or equal to &gt; greater than &gt;= greater than or equal to == equal to != not equal to !x negation, not x x|y x OR y x&amp;y x AND y Examples What are the values in a vector, vec that are greater than 5? Click here for solution vec &lt;- 1:10 vec &gt; 5 ## [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE What are the values in a vector, vec that are greater than or equal to 5? Click here for solution vec &lt;- 1:10 vec &gt;= 5 ## [1] FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE What are the values in a vector, vec that are less than 5? Click here for solution vec &lt;- 1:10 vec &lt; 5 ## [1] TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE What are the values in a vector, vec that are less than or equal to 5? Click here for solution vec &lt;- 1:10 vec &lt;= 5 ## [1] TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE What are the values in a vector that are greater than 7 OR less than or equal to 2? Click here for solution vec &lt;- 1:10 vec &gt; 7 | vec &lt;=2 ## [1] TRUE TRUE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE What are the values in a vector that are greater than 3 AND less than 6? Click here for solution vec &lt;- 1:10 vec &gt; 3 &amp; vec &lt; 6 ## [1] FALSE FALSE FALSE TRUE TRUE FALSE FALSE FALSE FALSE FALSE How do I get the values in list1 that are in list2? Click here for solution list1 &lt;- c(&quot;this&quot;, &quot;is&quot;, &quot;a&quot;, &quot;test&quot;) list2 &lt;- c(&quot;this&quot;, &quot;a&quot;, &quot;exam&quot;) list1[list1 %in% list2] ## [1] &quot;this&quot; &quot;a&quot; How do I get the values in list1 that are not in list2? Click here for solution list1 &lt;- c(&quot;this&quot;, &quot;is&quot;, &quot;a&quot;, &quot;test&quot;) list2 &lt;- c(&quot;this&quot;, &quot;a&quot;, &quot;exam&quot;) list1[!(list1 %in% list2)] ## [1] &quot;is&quot; &quot;test&quot; How can I get the number of values in a vector that are greater than 5? Click here for solution vec &lt;- 1:10 sum(vec&gt;5) ## [1] 5 # Note, you do not need to do: length(vec[vec&gt;5]) ## [1] 5 # because TRUE==1 and FALSE==0 in R TRUE==1 ## [1] TRUE FALSE==0 ## [1] TRUE Resources Operators Summary A quick list of the various operators with a few simple examples. Lists &amp; Vectors A vector contains values that are all the same type. The following are some examples of vectors: # A logical vector lvec &lt;- c(F, T, TRUE, FALSE) class(lvec) ## [1] &quot;logical&quot; # A numeric vector nvec &lt;- c(1,2,3,4) class(nvec) ## [1] &quot;numeric&quot; # A character vector cvec &lt;- c(&quot;this&quot;, &quot;is&quot;, &quot;a&quot;, &quot;test&quot;) class(cvec) ## [1] &quot;character&quot; As soon as you try to mix and match types, elements are coerced to the simplest type required to represent all the data. The order of representation is: logical, numeric, character, list For example: class(c(F, 1, 2)) ## [1] &quot;numeric&quot; class(c(F, 1, 2, &quot;ok&quot;)) ## [1] &quot;character&quot; class(c(F, 1, 2, &quot;ok&quot;, list(1, 2, &quot;ok&quot;))) ## [1] &quot;list&quot; Lists are vectors that can contain any class of data. For example: list(TRUE, 1, 2, &quot;OK&quot;, c(1,2,3)) ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] 1 ## ## [[3]] ## [1] 2 ## ## [[4]] ## [1] &quot;OK&quot; ## ## [[5]] ## [1] 1 2 3 With lists, there are 3 ways you can index. my_list &lt;- list(TRUE, 1, 2, &quot;OK&quot;, c(1,2,3), list(&quot;OK&quot;, 1,2, F)) # The first way is with single square brackets []. # This will always return a list, even if the content # only has 1 component. class(my_list[1:2]) ## [1] &quot;list&quot; class(my_list[3]) ## [1] &quot;list&quot; # The second way is with double brackets [[]]. # This will return the content itself. If the # content is something other than a list it will # return the value itself. class(my_list[[1]]) ## [1] &quot;logical&quot; class(my_list[[3]]) ## [1] &quot;numeric&quot; # Of course, if the value is a list itself, it will # remain a list. class(my_list[[6]]) ## [1] &quot;list&quot; # The third way is using $ to extract a single, named variable. # We need to add names first! $ is like the double bracket, # in that it will return the simplest form. my_list &lt;- list(first=TRUE, second=1, third=2, fourth=&quot;OK&quot;, embedded_vector=c(1,2,3), embedded_list=list(&quot;OK&quot;, 1,2, F)) my_list$first ## [1] TRUE my_list$embedded_list ## [[1]] ## [1] &quot;OK&quot; ## ## [[2]] ## [1] 1 ## ## [[3]] ## [1] 2 ## ## [[4]] ## [1] FALSE How do get the type of a vector? Click here for solution my_vector &lt;- c(0, 1, 2) typeof(my_vector) ## [1] &quot;double&quot; How do I convert a character vector to a numeric? Click here for solution my_character_vector &lt;- c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;) as.numeric(my_character_vector) ## [1] 1 2 3 4 How do I convert a numeric vector to a character? Click here for solution my_numeric_vector &lt;- c(1,2,3,4) as.character(my_numeric_vector) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; Indexing Indexing enables us to access a subset of the elements in vectors and lists. There are three types of indexing: positional/numeric, logical, and reference/named. You can create a named vector and a named list easily: my_vec &lt;- 1:5 names(my_vec) &lt;- c(&quot;alpha&quot;,&quot;bravo&quot;,&quot;charlie&quot;,&quot;delta&quot;,&quot;echo&quot;) my_list &lt;- list(1,2,3,4,5) names(my_list) &lt;- c(&quot;alpha&quot;,&quot;bravo&quot;,&quot;charlie&quot;,&quot;delta&quot;,&quot;echo&quot;) my_list2 &lt;- list(&quot;alpha&quot; = 1, &quot;beta&quot; = 2, &quot;charlie&quot; = 3, &quot;delta&quot; = 4, &quot;echo&quot; = 5) # Numeric (positional) indexing: my_vec[1:2] ## alpha bravo ## 1 2 my_vec[c(1,3)] ## alpha charlie ## 1 3 my_list[1:2] ## $alpha ## [1] 1 ## ## $bravo ## [1] 2 my_list[c(1,3)] ## $alpha ## [1] 1 ## ## $charlie ## [1] 3 # Logical indexing: my_vec[c(T, F, T, F, F)] ## alpha charlie ## 1 3 my_list[c(T, F, T, F, F)] ## $alpha ## [1] 1 ## ## $charlie ## [1] 3 # Named (reference) indexing: # if there are named values: my_vec[c(&quot;alpha&quot;, &quot;charlie&quot;)] ## alpha charlie ## 1 3 my_list[c(&quot;alpha&quot;, &quot;charlie&quot;)] ## $alpha ## [1] 1 ## ## $charlie ## [1] 3 Examples How can I get the first 2 values of a vector named my_vec? Click here for solution my_vec &lt;- c(1, 13, 2, 9) names(my_vec) &lt;- c(&#39;cat&#39;, &#39;dog&#39;,&#39;snake&#39;, &#39;otter&#39;) my_vec[1:2] ## cat dog ## 1 13 How can I get the values that are greater than 2? Click here for solution my_vec[my_vec&gt;2] ## dog otter ## 13 9 How can I get the values greater than 5 and smaller than 10? Click here for solution my_vec[my_vec &gt; 5 &amp; my_vec &lt; 10] ## otter ## 9 How can I get the values greater than 10 or smaller than 3? Click here for solution my_vec[my_vec &gt; 10 | my_vec &lt; 3] ## cat dog snake ## 1 13 2 How can I get the values for &quot;otter&quot; and &quot;dog&quot;? Click here for solution my_vec[c(&#39;otter&#39;,&#39;dog&#39;)] ## otter dog ## 9 13 Recycling Often operations in R on two or more vectors require them to be the same length. When R encounters vectors with different lengths, it automatically repeats (recycles) the shorter vector until the length of the vectors is the same. Examples Given two numeric vectors with different lengths, add them element-wise. Click here for solution x &lt;- c(1,2,3) y &lt;- c(0,1) x+y ## Warning in x + y: longer object length is not a multiple of shorter object ## length ## [1] 1 3 3 Basic R functions all all returns a logical value (TRUE or FALSE) if all values in a vector are TRUE. Examples Are all values in x positive? Click here for solution x &lt;- c(1, 2, 3, 4, 8, -1, 7, 3, 4, -2, 1, 3) all(x&gt;0) # FALSE ## [1] FALSE any any returns a logical value (TRUE or FALSE) if any values in a vector are TRUE. Examples Are any values in x positive? Click here for solution x &lt;- c(1, 2, 3, 4, 8, -1, 7, 3, 4, -2, 1, 3) any(x&gt;0) # TRUE ## [1] TRUE all.equal all.equal compares two objects and tests if they are &quot;nearly equal&quot; (up to some provided tolerance). Examples Is \\(\\pi\\) equal to 3.14? Click here for solution all.equal(pi, 3.14) # FALSE ## [1] &quot;Mean relative difference: 0.0005069574&quot; Is \\(\\pi\\) equal to 3.14 if our tolerance is 2 decimal cases? Click here for solution all.equal(pi, 3.14, tol=0.01) # TRUE ## [1] TRUE Are the vectors x and y equal? Click here for solution x &lt;- 1:5 y &lt;- c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;) all.equal(x, y) # difference in type (numeric vs. character) ## [1] &quot;Modes: numeric, character&quot; ## [2] &quot;target is numeric, current is character&quot; all.equal(x, as.numeric(y)) # TRUE ## [1] TRUE %in% Although %in% doesn't look like it, it is a function. Given two vectors, %in% returns a logical vector indicating if the respective values in the left operand have a match in the right operand. You can learn more about %in% by running ?&quot;%in%&quot;. Examples How do I find whether or not a value, 5 is in a given vector? Click here for solution 5 %in% c(1,2,3) ## [1] FALSE 5 %in% c(3,4,5) ## [1] TRUE How can I find which values in one vector are present in another? Click here for solution c(1,2,3) %in% c(1,2) c(1,2,3) %in% c(3,4,5) # order doesn&#39;t matter for the right operand c(1,2,3) %in% c(5,3,4) setdiff Given two vectors, the function setdiff returns the element of the first vector which do not exist in the second vector. Note: The order in which the vectors are listed in relation to the function setdiff matters, as illustrated in the first two examples. Examples Let x = (a, b, b, c) and y = (c, b, d, e, f). How to I find the elements in vector x that are not in vector y? Click here for solution x &lt;- c(&#39;a&#39;,&#39;b&#39;,&#39;b&#39;,&#39;c&#39;) y &lt;- c(&#39;c&#39;,&#39;b&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;) setdiff(x,y) ## [1] &quot;a&quot; setdiff(y,x) ## [1] &quot;d&quot; &quot;e&quot; &quot;f&quot; How to I find the elements in vector y that are not in vector x? Click here for solution x &lt;- c(&#39;a&#39;,&#39;b&#39;,&#39;b&#39;,&#39;c&#39;) y &lt;- c(&#39;c&#39;,&#39;b&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;) setdiff(y,x) ## [1] &quot;d&quot; &quot;e&quot; &quot;f&quot; intersect The intersect function returns the elements that two vectors or data.frames have in common. Note: The order in which the vectors are listed in relation to the function intersect only affects the order of the common elements returned. Examples Let x = (a, b, b, c) and y = (c, b, d, e, f). How to I find the elements shared both by vector x and by vector y? Click here for solution x &lt;- c(&#39;a&#39;,&#39;b&#39;,&#39;b&#39;,&#39;c&#39;) y &lt;- c(&#39;c&#39;,&#39;b&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;) intersect(x,y) ## [1] &quot;b&quot; &quot;c&quot; # as you can see, reversing the order # of the arguments only changes the order # in which the results are in the returned vector intersect(y,x) ## [1] &quot;c&quot; &quot;b&quot; dim dim returns the dimensions of a matrix or data.frame. The first value is the rows, the second is columns. Examples How many dimensions does the data.frame dat have? Click here for solution dat &lt;- data.frame(&quot;col1&quot;=c(1,2,3), &quot;col2&quot;=c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) dim(dat) # 3 rows and 2 columns ## [1] 3 2 length length allows you to get or set the length of an object in R (for which a method has been defined). How do I get how many values are in a vector? Click here for solution # Create a vector of length 5 my_vector &lt;- c(1,2,3,4,5) # Calculate the length of my_vector length(my_vector) ## [1] 5 rep rep is short for replicate. rep accepts some object, x, and up to three additional arguments: times, length.out, and each. times is the number of non-negative times to repeat the whole object x. length.out specifies the end length you want the result to be. rep will repeat the values in x as many times as it takes to reach the provided length.out. each repeats each element in x the number of times specified by each. Examples How do I repeat values in a vector 3 times? Click here for solution vec &lt;- c(1,2,3) rep(vec, 3) ## [1] 1 2 3 1 2 3 1 2 3 # or rep(vec, times=3) ## [1] 1 2 3 1 2 3 1 2 3 How do I repeat the values in a vector enough times to be the same length as another vector? Click here for solution vec &lt;- c(1,2,3) other_vec &lt;- c(1,2,2,2,2,2,2,8) rep(vec, length.out=length(other_vec)) ## [1] 1 2 3 1 2 3 1 2 # Note that if the end goal is to do something # like add the two vectors, this can be done # using recycling. rep(vec, length.out=length(other_vec)) + other_vec ## [1] 2 4 5 3 4 5 3 10 vec + other_vec ## Warning in vec + other_vec: longer object length is not a multiple of shorter ## object length ## [1] 2 4 5 3 4 5 3 10 How can I repeat each value inside a vector a certain amount of times? Click here for solution vec &lt;- c(1,2,3) rep(vec, each=3) ## [1] 1 1 1 2 2 2 3 3 3 How can I repeat the values in one vector based on the values in another vector? Click here for solution vec &lt;- c(1,2,3) rep_by &lt;- c(3,2,1) rep(vec, times=rep_by) ## [1] 1 1 1 2 2 3 rbind and cbind rbind and cbind append objects (vectors, matrices or data.frames) as rows (rbind) or as columns (cbind). Examples How do I combine 3 vectors into a matrix? Click here for solution x &lt;- 1:10 y &lt;- 11:20 z &lt;- 10:1 # combining them as rows rbind(x,y,z) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## x 1 2 3 4 5 6 7 8 9 10 ## y 11 12 13 14 15 16 17 18 19 20 ## z 10 9 8 7 6 5 4 3 2 1 dim(rbind(x,y,z)) ## [1] 3 10 # combining them as columns cbind(x,y,z) ## x y z ## [1,] 1 11 10 ## [2,] 2 12 9 ## [3,] 3 13 8 ## [4,] 4 14 7 ## [5,] 5 15 6 ## [6,] 6 16 5 ## [7,] 7 17 4 ## [8,] 8 18 3 ## [9,] 9 19 2 ## [10,] 10 20 1 dim(cbind(x,y,z)) ## [1] 10 3 How do I add a vector as a column to a matrix? Click here for solution x &lt;- 1:10 my_mat &lt;- matrix(1:20, ncol=2) my_mat &lt;- cbind(my_mat, x) dim(my_mat) ## [1] 10 3 How do I append new rows to a matrix? Click here for solution my_mat1 &lt;- matrix(20:1, ncol=2) my_mat2 &lt;- matrix(1:20, ncol=2) my_mat &lt;- rbind(my_mat1, my_mat2) dim(my_mat) ## [1] 20 2 which, which.max, which.min which enables you to find the position of the elements that are TRUE in a logical vector. which.max and which.min finds the location of the maximum and minimum, respectively, of a numeric (or logical) vector. Examples Given a numeric vector, return the index of the maximum value. Click here for solution x &lt;- c(1,-10, 2,4,-3,9,2,-2,4,8) which.max(x) ## [1] 6 # which.max is just shorthand for: which(x==max(x)) ## [1] 6 Given a vector, return the index of the positive values. Click here for solution x &lt;- c(1,-10, 2,4,-3,9,2,-2,4,8) which(x&gt;0) ## [1] 1 3 4 6 7 9 10 Given a matrix, return the indexes (row and column) of the positive values. Click here for solution x &lt;- matrix(c(1,-10, 2,4,-3,9,2,-2,4,8), ncol=2) which(x&gt;0, arr.ind = TRUE) ## row col ## [1,] 1 1 ## [2,] 3 1 ## [3,] 4 1 ## [4,] 1 2 ## [5,] 2 2 ## [6,] 4 2 ## [7,] 5 2 grep, grepl, etc. grep allows you to use regular expressions to search for a pattern in a string or character vector, and returns the index where there is a match. grepl performs the same operation but rather than returning indices, returns a vector of logical TRUE or FALSE values. Examples Given a character vector, return the index of any words ending in &quot;s&quot;. Click here for solution grep(&quot;.*s$&quot;, c(&quot;waffle&quot;, &quot;waffles&quot;, &quot;pancake&quot;, &quot;pancakes&quot;)) ## [1] 2 4 Given a character vector, return a vector of the same length where each element is TRUE if there was a match for any word ending in &quot;s&quot;, and `FALSE otherwise. Click here for solution grepl(&quot;.*s$&quot;, c(&quot;waffle&quot;, &quot;waffles&quot;, &quot;pancake&quot;, &quot;pancakes&quot;)) ## [1] FALSE TRUE FALSE TRUE Resources ReExCheatsheet An excellent quick reference for regular expressions. Examples using grep in R. sum sum is a function that calculates the sum of a vector of values. Examples How do I get the sum of the values in a vector? Click here for solution sum(c(1,3,2,10,4)) ## [1] 20 How do I get the sum of the values in a vector when some of the values are: NA, NaN? Click here for solution sum(c(1,2,3,NaN), na.rm=T) ## [1] 6 sum(c(1,2,3,NA), na.rm=T) ## [1] 6 sum(c(1,2,NA,NaN,4), na.rm=T) ## [1] 7 mean mean is a function that calculates the average of a vector of values. How do I get the average of a vector of values? Click here for solution mean(c(1,2,3,4)) ## [1] 2.5 How do I get the average of a vector of values when some of the values are: NA, NaN? Click here for solution Many R functions have the na.rm argument available. This argument is &quot;a logical value indicating whether NA values should be stripped before the computation proceeds.&quot; mean(c(1,2,3,NaN), na.rm=T) ## [1] 2 mean(c(1,2,3,NA), na.rm=T) ## [1] 2 mean(c(1,2,NA,NaN,4), na.rm=T) ## [1] 2.333333 var var is a function that calculate the variance of a vector of values. How do I get the variance of a vector of values? Click here for solution var(c(1,2,3,4)) ## [1] 1.666667 How do I get the variance of a vector of values when some of the values are: NA, NaN? Click here for solution var(c(1,2,3,NaN), na.rm=T) ## [1] 1 var(c(1,2,3,NA), na.rm=T) ## [1] 1 var(c(1,2,NA,NaN,4), na.rm=T) ## [1] 2.333333 How do I get the standard deviation of a vector of values? Click here for solution The standard deviation is equal to the square root of the variance. sqrt(var(c(1,2,3,NaN), na.rm=T)) ## [1] 1 sqrt(var(c(1,2,3,NA), na.rm=T)) ## [1] 1 sqrt(var(c(1,2,NA,NaN,4), na.rm=T)) ## [1] 1.527525 colSums and rowSums colSums and rowSums calculates row and column sums for numeric matrices or data.frames. Examples How do I get the sum of the values for every column in a data frame? Click here for solution # First 6 values in mtcars head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 # For every column, sum of all rows: colSums(mtcars) ## mpg cyl disp hp drat wt qsec vs ## 642.900 198.000 7383.100 4694.000 115.090 102.952 571.160 14.000 ## am gear carb ## 13.000 118.000 90.000 How do I get the sum of the values for every row in a data frame? Click here for solution # First 6 values in mtcars head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 # For every row, sum of all columns: rowSums(mtcars) ## Mazda RX4 Mazda RX4 Wag Datsun 710 Hornet 4 Drive ## 328.980 329.795 259.580 426.135 ## Hornet Sportabout Valiant Duster 360 Merc 240D ## 590.310 385.540 656.920 270.980 ## Merc 230 Merc 280 Merc 280C Merc 450SE ## 299.570 350.460 349.660 510.740 ## Merc 450SL Merc 450SLC Cadillac Fleetwood Lincoln Continental ## 511.500 509.850 728.560 726.644 ## Chrysler Imperial Fiat 128 Honda Civic Toyota Corolla ## 725.695 213.850 195.165 206.955 ## Toyota Corona Dodge Challenger AMC Javelin Camaro Z28 ## 273.775 519.650 506.085 646.280 ## Pontiac Firebird Fiat X1-9 Porsche 914-2 Lotus Europa ## 631.175 208.215 272.570 273.683 ## Ford Pantera L Ferrari Dino Maserati Bora Volvo 142E ## 670.690 379.590 694.710 288.890 colMeans and rowMeans colMeans and rowMeans calculates row and column means for numeric matrices or data.frames. Examples Examples How do I get the mean for every column in a data frame? Click here for solution # First 6 values in mtcars head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 # Mean of each column colMeans(mtcars) ## mpg cyl disp hp drat wt qsec ## 20.090625 6.187500 230.721875 146.687500 3.596563 3.217250 17.848750 ## vs am gear carb ## 0.437500 0.406250 3.687500 2.812500 How do I get the mean for every row in a data frame? Click here for solution # First 6 values in mtcars head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 # Mean of each row rowMeans(mtcars) ## Mazda RX4 Mazda RX4 Wag Datsun 710 Hornet 4 Drive ## 29.90727 29.98136 23.59818 38.73955 ## Hornet Sportabout Valiant Duster 360 Merc 240D ## 53.66455 35.04909 59.72000 24.63455 ## Merc 230 Merc 280 Merc 280C Merc 450SE ## 27.23364 31.86000 31.78727 46.43091 ## Merc 450SL Merc 450SLC Cadillac Fleetwood Lincoln Continental ## 46.50000 46.35000 66.23273 66.05855 ## Chrysler Imperial Fiat 128 Honda Civic Toyota Corolla ## 65.97227 19.44091 17.74227 18.81409 ## Toyota Corona Dodge Challenger AMC Javelin Camaro Z28 ## 24.88864 47.24091 46.00773 58.75273 ## Pontiac Firebird Fiat X1-9 Porsche 914-2 Lotus Europa ## 57.37955 18.92864 24.77909 24.88027 ## Ford Pantera L Ferrari Dino Maserati Bora Volvo 142E ## 60.97182 34.50818 63.15545 26.26273 unique unique &quot;returns a vector, data frame, or array like x but with duplicate elements/rows removed. Given a vector of values, how do I return a vector of values with all duplicates removed? Click here for solution vec &lt;- c(1, 2, 3, 3, 3, 4, 5, 5, 6) unique(vec) ## [1] 1 2 3 4 5 6 summary summary shows summary statistics for a vector, or for every column in a data.frame and/or matrix. The summary statistics shown are: mininum value, maximum value, first and third quartiles, mean and median. Examples How do I get summary statistics for a vector? Click here for solution summary(1:30) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.00 8.25 15.50 15.50 22.75 30.00 How do I get summary statistics for every column in a data frame? Click here for solution # First 6 values in mtcars head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 # Mean of each column summary(mtcars) ## mpg cyl disp hp ## Min. :10.40 Min. :4.000 Min. : 71.1 Min. : 52.0 ## 1st Qu.:15.43 1st Qu.:4.000 1st Qu.:120.8 1st Qu.: 96.5 ## Median :19.20 Median :6.000 Median :196.3 Median :123.0 ## Mean :20.09 Mean :6.188 Mean :230.7 Mean :146.7 ## 3rd Qu.:22.80 3rd Qu.:8.000 3rd Qu.:326.0 3rd Qu.:180.0 ## Max. :33.90 Max. :8.000 Max. :472.0 Max. :335.0 ## drat wt qsec vs ## Min. :2.760 Min. :1.513 Min. :14.50 Min. :0.0000 ## 1st Qu.:3.080 1st Qu.:2.581 1st Qu.:16.89 1st Qu.:0.0000 ## Median :3.695 Median :3.325 Median :17.71 Median :0.0000 ## Mean :3.597 Mean :3.217 Mean :17.85 Mean :0.4375 ## 3rd Qu.:3.920 3rd Qu.:3.610 3rd Qu.:18.90 3rd Qu.:1.0000 ## Max. :4.930 Max. :5.424 Max. :22.90 Max. :1.0000 ## am gear carb ## Min. :0.0000 Min. :3.000 Min. :1.000 ## 1st Qu.:0.0000 1st Qu.:3.000 1st Qu.:2.000 ## Median :0.0000 Median :4.000 Median :2.000 ## Mean :0.4062 Mean :3.688 Mean :2.812 ## 3rd Qu.:1.0000 3rd Qu.:4.000 3rd Qu.:4.000 ## Max. :1.0000 Max. :5.000 Max. :8.000 order and sort sort allows you to arrange (or partially arrange) a vector into ascending or descending order. order returns the position of each element of a vector in ascending (or descending order). Examples Given a vector, arrange it in a ascending order. Click here for solution x &lt;- c(1,3,2,10,4) sort(x) ## [1] 1 2 3 4 10 Given a vector, arrange it in a descending order. Click here for solution x &lt;- c(1,3,2,10,4) sort(x, decreasing = TRUE) ## [1] 10 4 3 2 1 Given a character vector, arrange it in ascending order. Click here for solution sort(c(&quot;waffle&quot;, &quot;pancake&quot;, &quot;eggs&quot;, &quot;bacon&quot;)) ## [1] &quot;bacon&quot; &quot;eggs&quot; &quot;pancake&quot; &quot;waffle&quot; Given a matrix, arrange it in ascending order using the first column. Click here for solution my_mat &lt;- matrix(c(1,5,0, 2, 10, 1, 2, 8, 9, 1,0,2), ncol=3) my_mat[order(my_mat[,1]),] ## [,1] [,2] [,3] ## [1,] 0 2 0 ## [2,] 1 10 9 ## [3,] 2 8 2 ## [4,] 5 1 1 paste and paste0 paste is a useful function to &quot;concatenate vectors after converting to character.&quot; paste0 is a shorthand function where the sep argument is &quot;&quot;. How do I concatenate two vectors, element-wise, with a comma in between values from each vector? Click here for solution vector1 &lt;- c(&quot;one&quot;, &quot;three&quot;, &quot;five&quot;) vector2 &lt;- c(&quot;two&quot;, &quot;four&quot;, &quot;six&quot;) paste(vector1, vector2, sep=&quot;,&quot;) ## [1] &quot;one,two&quot; &quot;three,four&quot; &quot;five,six&quot; How do I paste together two strings? Click here for solution paste0(&quot;abra&quot;, &quot;kadabra&quot;) ## [1] &quot;abrakadabra&quot; How do I paste together three strings? Click here for solution paste0(&quot;abra&quot;, &quot;kadabra&quot;, &quot;alakazam&quot;) ## [1] &quot;abrakadabraalakazam&quot; head and tail head returns the first n (default is 6) parts of a vector, matrix, table, data.frame or function. For vectors, head shows the first 6 values, for matrices, tables and data.frame, head shows the first 6 rows, and for functions the first 6 rows of code. tail returns the last n (default is 6) parts of a vector, matrix, table, data.frame or function. Examples How do I get the first 6 rows of a data.frame? Click here for solution head(df) ## ## 1 function (x, df1, df2, ncp, log = FALSE) ## 2 { ## 3 if (missing(ncp)) ## 4 .Call(C_df, x, df1, df2, log) ## 5 else .Call(C_dnf, x, df1, df2, ncp, log) ## 6 } How do I get the first 10 rows of a data.frame? Click here for solution head(df, 10) ## ## 1 function (x, df1, df2, ncp, log = FALSE) ## 2 { ## 3 if (missing(ncp)) ## 4 .Call(C_df, x, df1, df2, log) ## 5 else .Call(C_dnf, x, df1, df2, ncp, log) ## 6 } How do I get the last 6 rows of a data.frame? Click here for solution tail(df) ## ## 1 function (x, df1, df2, ncp, log = FALSE) ## 2 { ## 3 if (missing(ncp)) ## 4 .Call(C_df, x, df1, df2, log) ## 5 else .Call(C_dnf, x, df1, df2, ncp, log) ## 6 } How do I get the last 8 rows of a data.frame? Click here for solution tail(df, 8) ## ## 1 function (x, df1, df2, ncp, log = FALSE) ## 2 { ## 3 if (missing(ncp)) ## 4 .Call(C_df, x, df1, df2, log) ## 5 else .Call(C_dnf, x, df1, df2, ncp, log) ## 6 } str str stands for structure. str gives you a glimpse at the variable of interest. Examples How do I get the number of columns or features in a data.frame? Click here for solution As you can see, there are 9 rows or obs. (short for observations), and 29 variables (which can be referred to as columns or features). str(df) strsplit strsplit accepts a vector of strings, and a vector of strings representing regular expressions. Each string in the first vector is split according to the respective string in the second vector. Examples How do I split a string containing multiple sentences into individual sentences? Click here for solution Note that you need to escape the &quot;.&quot; as &quot;.&quot; means &quot;any character&quot; in regular expressions. In R, you put two &quot;&quot; before it. multiple_sentences &lt;- &quot;This is the first sentence. This is the second sentence. This is the third sentence.&quot; unlist(strsplit(multiple_sentences, &quot;\\\\.&quot;)) ## [1] &quot;This is the first sentence&quot; &quot; This is the second sentence&quot; ## [3] &quot; This is the third sentence&quot; # remove extra whitespace trimws(unlist(strsplit(multiple_sentences, &quot;\\\\.&quot;))) ## [1] &quot;This is the first sentence&quot; &quot;This is the second sentence&quot; ## [3] &quot;This is the third sentence&quot; How do I split one string by a space, and the next string by a &quot;.&quot;? Click here for solution string_vec &lt;- c(&quot;Okay okay you win.&quot;, &quot;This. Is. Not. Okay.&quot;) strsplit(string_vec, c(&quot; &quot;, &quot;\\\\.&quot;)) ## [[1]] ## [1] &quot;Okay&quot; &quot;okay&quot; &quot;you&quot; &quot;win.&quot; ## ## [[2]] ## [1] &quot;This&quot; &quot; Is&quot; &quot; Not&quot; &quot; Okay&quot; names names is a function that returns the names of a an object. This includes the typical data structures: vectors, lists, and data.frames. By default, names will return the column names of a data.frame, not the row names. Examples How do I get the column names of a data.frame? Click here for solution # Get the column names of a data.frame names(df) ## [1] &quot;cat_1&quot; &quot;cat_2&quot; &quot;ok&quot; &quot;other&quot; How do I get the names of a list? Click here for solution # Get the names of a list names(list(col1=c(1,2,3), col2=c(987))) ## [1] &quot;col1&quot; &quot;col2&quot; How do I get the names of a vector? Click here for solution # Get the names of a vector names(c(val1=1, val2=2, val3=3)) ## [1] &quot;val1&quot; &quot;val2&quot; &quot;val3&quot; How do I change the column names of a data.frame? Click here for solution names(df) &lt;- c(&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;, &quot;col4&quot;) df ## col1 col2 col3 col4 ## 1 1 9 TRUE first ## 2 2 8 TRUE second ## 3 3 7 FALSE third colnames &amp; rownames colnames is the same as names but specifies the column names. rownames is the same as names but specifies the row names. table &amp; prop.table table is a function used to build a contingency table of counts of various factors. prop.table is a function that accepts the output of table and rather than returning counts, returns conditional proportions. Examples How do I get a count of the number of students in each year in our grades data.frame? Click here for solution table(grades$year) ## ## freshman junior senior sophomore ## 1 4 2 3 How do I get the precentages of students in each year in our grades data.frame? Click here for solution prop.table(table(grades$year)) ## ## freshman junior senior sophomore ## 0.1 0.4 0.2 0.3 How do I get a count of the number of students in each year by sex in our grades data.frame? Click here for solution table(grades$year, grades$sex) ## ## F M ## freshman 0 1 ## junior 2 2 ## senior 1 1 ## sophomore 1 2 How do I get the precentages of students in each year by sex in our grades data.frame? Click here for solution prop.table(table(grades$year, grades$sex)) ## ## F M ## freshman 0.0 0.1 ## junior 0.2 0.2 ## senior 0.1 0.1 ## sophomore 0.1 0.2 cut cut breaks a vector x into factors specified by the argument breaks. cut is particularly useful to break Date data into categories like &quot;Q1&quot;, &quot;Q2&quot;, or 1998, 1999, 2000, etc. You can find more useful information by running ?cut.POSIXt. Examples How can I create a new column in a data.frame df that is a factor based on the year? Click here for solution df$year &lt;- cut(df$times, breaks=&quot;year&quot;) str(df) ## &#39;data.frame&#39;: 24 obs. of 3 variables: ## $ times: POSIXct, format: &quot;2020-06-01 06:00:00&quot; &quot;2020-07-01 06:00:00&quot; ... ## $ value: int 29 49 21 83 100 20 68 9 69 87 ... ## $ year : Factor w/ 3 levels &quot;2020-01-01&quot;,&quot;2021-01-01&quot;,..: 1 1 1 1 1 1 1 2 2 2 ... How can I create a new column in a data.frame df that is a factor based on the quarter? Click here for solution df$quarter &lt;- cut(df$times, breaks=&quot;quarter&quot;) str(df) ## &#39;data.frame&#39;: 24 obs. of 4 variables: ## $ times : POSIXct, format: &quot;2020-06-01 06:00:00&quot; &quot;2020-07-01 06:00:00&quot; ... ## $ value : int 29 49 21 83 100 20 68 9 69 87 ... ## $ year : Factor w/ 3 levels &quot;2020-01-01&quot;,&quot;2021-01-01&quot;,..: 1 1 1 1 1 1 1 2 2 2 ... ## $ quarter: Factor w/ 9 levels &quot;2020-04-01&quot;,&quot;2020-07-01&quot;,..: 1 2 2 2 3 3 3 4 4 4 ... How can I create a new column in a data.frame df that is a factor based on every 2 weeks? Click here for solution df$biweekly &lt;- cut(df$times, breaks=&quot;2 weeks&quot;) For an example with the 7581 data set: myDF &lt;- read.csv(&quot;/class/datamine/data/fars/7581.csv&quot;) These are the values of the HOUR column: table(myDF$HOUR) We can break these values into 6-hour intervals: table( cut(myDF$HOUR, breaks=c(0,6,12,18,24,99), include.lowest=T) ) and then find the total number of PERSONS who are involved in accidents during each 6-hour interval tapply( myDF$PERSONS, cut(myDF$HOUR, breaks=c(0,6,12,18,24,99), include.lowest=T), sum ) Click here for video subset subset is a function that helps you take subsets of data. By default, subset removes NA rows, so use with care. subset does not perform any operation that can't be accomplished by indexing, but can sometimes be easier to read. Where we would normally write something like: grades[grades$year==&quot;junior&quot; | grades$sex==&quot;M&quot;,]$grade ## [1] 100 75 74 69 88 99 90 92 We can instead do: subset(grades, year==&quot;junior&quot; | sex==&quot;M&quot;, select=grade) ## grade ## 1 100 ## 3 75 ## 4 74 ## 6 69 ## 7 88 ## 8 99 ## 9 90 ## 10 92 But be careful, if we replace a grade with an NA, it will be removed by subset: grades$sex[8] &lt;- NA subset(grades, year==&quot;junior&quot; | sex==&quot;M&quot;, select=grade) ## grade ## 1 100 ## 3 75 ## 4 74 ## 6 69 ## 7 88 ## 9 90 ## 10 92 Whereas indexing will not unless you specify to: grades[grades$year==&quot;junior&quot; | grades$sex==&quot;M&quot;,]$grade ## [1] 100 75 74 69 88 NA 90 92 How can I easily make a subset of the 8451 data, using only 1 line of R, with the subset function? Click here for video In the 84.51 data set: myDF &lt;- read.csv(&quot;/class/datamine/data/8451/The_Complete_Journey_2_Master/5000_transactions.csv&quot;) We recall that these are the variables: head(myDF) and there are 10625553 rows and 9 columns dim(myDF) We can use the subset command to focus on only the purchases from the CENTRAL store region, in the YEAR 2016. We can also pick which variables that we want to have in this new data frame. Please note: We do not need to specify myDF on each variable, because the subset function will keep track of this for us. The subset function knows which data set that we are working with, because we specify it as the first parameter in the subset function. The subset parameter of the subset function describes the rows that we are interested in. (In particular, we specify the conditions that we want the rows to satisfy.) The select parameter of the subset function describes the columns that we are interested in. (We list the columns by their names, and we need to put each such column name in double quotes.) myfocusedDF &lt;- subset(myDF, subset=(STORE_R==&quot;CENTRAL&quot;) &amp; (YEAR==2016), select=c(&quot;PURCHASE_&quot;,&quot;PRODUCT_NUM&quot;,&quot;SPEND&quot;,&quot;UNITS&quot;) ) This new data set has only 1246144 rows, i.e., about 12 percent of the purchases, as expected. It also has only the 4 columns that we specified in the subset function. dim(myfocusedDF) How can I easily make a subset of the election data, using only 1 line of R, with the subset function? Click here for video Here is an example of how to use the subset function with the data from the federal election campaign contributions from 2016: library(data.table) myDF &lt;- fread(&quot;/class/datamine/data/election/itcont2016.txt&quot;, sep=&quot;|&quot;) There were 20557796 donations made in 2016: dim(myDF) We can use the subset command to focus on the donations made from Midwest states, and limit our results to those donations that had positive TRANSACTION_AMT values. We can extract interesting variables, e.g., the NAME, CITY, STATE, and TRANSACTION_AMT. mymidwestDF &lt;- subset(myDF, subset=(STATE %in% c(&quot;IN&quot;,&quot;IL&quot;,&quot;OH&quot;,&quot;MI&quot;,&quot;WI&quot;)) &amp; (TRANSACTION_AMT &gt; 0), select=c(&quot;NAME&quot;,&quot;CITY&quot;,&quot;STATE&quot;,&quot;TRANSACTION_AMT&quot;) ) The resulting data frame has 2435825 rows. dim(mymidwestDF) From the data set, we can sum the TRANSACTION_AMT values, grouped according to the NAME of the donor, and we find that EYCHANER, FRED was the top donor living in the midwest, during the 2016 federal election campaigns. tail(sort(tapply(mymidwestDF$TRANSACTION_AMT, mymidwestDF$NAME, sum))) difftime {r#-difftime} The function difftime computes/creates a time interval between two dates/times and converts the interval to a chosen time unit. Examples How many days,hours and minutes are there between the dates 2015-04-06 and 2015-01-01? Click here for solution # number of days difftime(ymd(&quot;2015-04-06&quot;),ymd(&quot;2015-01-01&quot;), units=&quot;days&quot;) # number of hours difftime(ymd(&quot;2015-04-06&quot;),ymd(&quot;2015-01-01&quot;), units=&quot;hours&quot;) # number of minutes difftime(ymd(&quot;2015-04-06&quot;),ymd(&quot;2015-01-01&quot;), units=&quot;mins&quot;) merge merge is a function that can be used to combine data.frames by row names, or more commonly, by column names. merge can replicate the join operations in SQL. The documentation is quite clear, and a useful resource: ?merge. How can I easily merge the fars data with the state_names data, using only 1 line of R, with the merge function? Click here for video In STAT 19000, Project 6, we used the state_names data frame, to change the codes for the State's names into the State's actual names. We gave you the code to do so (in Question 1 of Project 6). It is easier, however, to use the merge function. dat &lt;- read.csv(&quot;/class/datamine/data/fars/7581.csv&quot;) state_names &lt;- read.csv(&quot;/class/datamine/data/fars/states.csv&quot;) We look at the heads of both data frames. head(dat) head(state_names) The STATE column of the dat data frame corresponds to the code column of the state_names data frame. Now we merge these two data frames, by corresponding values from this column. We call resulting data frame mynewDF mynewDF &lt;- merge(dat,state_names,by.x=&quot;STATE&quot;,by.y=&quot;code&quot;) The new column, called state (not to be confused with STATE) is the rightmost column in this new data frame. head(mynewDF) Now we can solve Project 6, Question 2, using this new data frame. sort(tapply(mynewDF$DRUNK_DR, mynewDF$state, mean)) How can I easily merge the data about flights with the data about the airports themselves, using only 1 line of R, with the merge function? Click here for video Here is the flight data from 1995. Notice that, for instance, the locations of the airports are not given. We only know the airport Origin and Dest codes. myDF &lt;- read.csv(&quot;/class/datamine/data/flights/subset/1995.csv&quot;) Here is a listing of the information about the airports themselves: airportsDF &lt;- read.csv(&quot;/class/datamine/data/flights/subset/airports.csv&quot;) We see that the 3-letter codes about the airports are given in the Origin and Dest columns of myDF. head(myDF) It is harder to tell which column in the airportsDF gives the 3-letter codes, but these are the iata codes head(airportsDF) It is perhaps easier to see this from the tale of airportsDF: tail(airportsDF) Now we merge the two data frames, and we display the information about the Origin airport, by linking the Origin column of myDF with the iata column of airportsDF: mynewDF &lt;- merge(myDF, airportsDF, by.x=&quot;Origin&quot;, by.y=&quot;iata&quot;) The resulting data frame has the same size as myDF: dim(myDF) dim(mynewDF) but now has extra columns, namely, with information about the Origin airport: head(mynewDF) tail(mynewDF) So now we can do things like calculating a sum of all Distances of flights with Origin in each state: sort(tapply( mynewDF$Distance, mynewDF$state, sum )) Here is another merge example: Examples Consider the data.frame's books and authors: books ## id title author_id rating ## 1 1 Harry Potter and the Sorcerer&#39;s Stone 1 4.47 ## 2 2 Harry Potter and the Chamber of Secrets 1 4.43 ## 3 3 Harry Potter and the Prisoner of Azkaban 1 4.57 ## 4 4 Harry Potter and the Goblet of Fire 1 4.56 ## 5 5 Harry Potter and the Order of the Phoenix 1 4.50 ## 6 6 Harry Potter and the Half Blood Prince 1 4.57 ## 7 7 Harry Potter and the Deathly Hallows 1 4.62 ## 8 8 The Way of Kings 2 4.64 ## 9 9 The Book Thief 3 4.37 ## 10 10 The Eye of the World 4 4.18 authors ## id name avg_rating ## 1 1 J.K. Rowling 4.46 ## 2 2 Brandon Sanderson 4.39 ## 3 3 Markus Zusak 4.34 ## 4 4 Robert Jordan 4.18 ## 5 5 Agatha Christie 4.00 ## 6 6 Alex Kava 4.02 ## 7 7 Nassim Nicholas Taleb 3.99 ## 8 8 Neil Gaiman 4.13 ## 9 9 Stieg Larsson 4.16 ## 10 10 Antoine de Saint-Exupéry 4.30 How do I merge the author information from authors based on author_id in books and id in authors, keeping only information from authors and books where there is a match? Click here for solution # In SQL this is referred to as an INNER JOIN. merge(books, authors, by.x=&quot;author_id&quot;, by.y=&quot;id&quot;, all=F) ## author_id id title rating ## 1 1 1 Harry Potter and the Sorcerer&#39;s Stone 4.47 ## 2 1 2 Harry Potter and the Chamber of Secrets 4.43 ## 3 1 3 Harry Potter and the Prisoner of Azkaban 4.57 ## 4 1 4 Harry Potter and the Goblet of Fire 4.56 ## 5 1 5 Harry Potter and the Order of the Phoenix 4.50 ## 6 1 6 Harry Potter and the Half Blood Prince 4.57 ## 7 1 7 Harry Potter and the Deathly Hallows 4.62 ## 8 2 8 The Way of Kings 4.64 ## 9 3 9 The Book Thief 4.37 ## 10 4 10 The Eye of the World 4.18 ## name avg_rating ## 1 J.K. Rowling 4.46 ## 2 J.K. Rowling 4.46 ## 3 J.K. Rowling 4.46 ## 4 J.K. Rowling 4.46 ## 5 J.K. Rowling 4.46 ## 6 J.K. Rowling 4.46 ## 7 J.K. Rowling 4.46 ## 8 Brandon Sanderson 4.39 ## 9 Markus Zusak 4.34 ## 10 Robert Jordan 4.18 How do I merge the author information from authors based on author_id in books and id in authors, keeping all information from authors regardless of whether or not there is match? Click here for solution merge(books, authors, by.x=&quot;author_id&quot;, by.y=&quot;id&quot;, all.y=T) ## author_id id title rating ## 1 1 1 Harry Potter and the Sorcerer&#39;s Stone 4.47 ## 2 1 2 Harry Potter and the Chamber of Secrets 4.43 ## 3 1 3 Harry Potter and the Prisoner of Azkaban 4.57 ## 4 1 4 Harry Potter and the Goblet of Fire 4.56 ## 5 1 5 Harry Potter and the Order of the Phoenix 4.50 ## 6 1 6 Harry Potter and the Half Blood Prince 4.57 ## 7 1 7 Harry Potter and the Deathly Hallows 4.62 ## 8 2 8 The Way of Kings 4.64 ## 9 3 9 The Book Thief 4.37 ## 10 4 10 The Eye of the World 4.18 ## 11 5 NA &lt;NA&gt; NA ## 12 6 NA &lt;NA&gt; NA ## 13 7 NA &lt;NA&gt; NA ## 14 8 NA &lt;NA&gt; NA ## 15 9 NA &lt;NA&gt; NA ## 16 10 NA &lt;NA&gt; NA ## name avg_rating ## 1 J.K. Rowling 4.46 ## 2 J.K. Rowling 4.46 ## 3 J.K. Rowling 4.46 ## 4 J.K. Rowling 4.46 ## 5 J.K. Rowling 4.46 ## 6 J.K. Rowling 4.46 ## 7 J.K. Rowling 4.46 ## 8 Brandon Sanderson 4.39 ## 9 Markus Zusak 4.34 ## 10 Robert Jordan 4.18 ## 11 Agatha Christie 4.00 ## 12 Alex Kava 4.02 ## 13 Nassim Nicholas Taleb 3.99 ## 14 Neil Gaiman 4.13 ## 15 Stieg Larsson 4.16 ## 16 Antoine de Saint-Exupéry 4.30 # or merge(authors, books, by.x=&quot;id&quot;, by.y=&quot;author_id&quot;, all.x=T) ## id name avg_rating id.y ## 1 1 J.K. Rowling 4.46 1 ## 2 1 J.K. Rowling 4.46 2 ## 3 1 J.K. Rowling 4.46 3 ## 4 1 J.K. Rowling 4.46 4 ## 5 1 J.K. Rowling 4.46 5 ## 6 1 J.K. Rowling 4.46 6 ## 7 1 J.K. Rowling 4.46 7 ## 8 2 Brandon Sanderson 4.39 8 ## 9 3 Markus Zusak 4.34 9 ## 10 4 Robert Jordan 4.18 10 ## 11 5 Agatha Christie 4.00 NA ## 12 6 Alex Kava 4.02 NA ## 13 7 Nassim Nicholas Taleb 3.99 NA ## 14 8 Neil Gaiman 4.13 NA ## 15 9 Stieg Larsson 4.16 NA ## 16 10 Antoine de Saint-Exupéry 4.30 NA ## title rating ## 1 Harry Potter and the Sorcerer&#39;s Stone 4.47 ## 2 Harry Potter and the Chamber of Secrets 4.43 ## 3 Harry Potter and the Prisoner of Azkaban 4.57 ## 4 Harry Potter and the Goblet of Fire 4.56 ## 5 Harry Potter and the Order of the Phoenix 4.50 ## 6 Harry Potter and the Half Blood Prince 4.57 ## 7 Harry Potter and the Deathly Hallows 4.62 ## 8 The Way of Kings 4.64 ## 9 The Book Thief 4.37 ## 10 The Eye of the World 4.18 ## 11 &lt;NA&gt; NA ## 12 &lt;NA&gt; NA ## 13 &lt;NA&gt; NA ## 14 &lt;NA&gt; NA ## 15 &lt;NA&gt; NA ## 16 &lt;NA&gt; NA Data.frames Data.frames are one of the primary data structure used very frequently when working in R. Data.frames are tables of same-sized, named columns, where each column has a single type. You can create a data.frame easily: df &lt;- data.frame(cat_1=c(1,2,3), cat_2=c(9,8,7), ok=c(T, T, F), other=c(&quot;first&quot;, &quot;second&quot;, &quot;third&quot;)) head(df) ## cat_1 cat_2 ok other ## 1 1 9 TRUE first ## 2 2 8 TRUE second ## 3 3 7 FALSE third Regular indexing rules apply as well. This is how you index rows. Pay close attention to the trailing comma: # Numeric indexing on rows: df[1:2,] ## cat_1 cat_2 ok other ## 1 1 9 TRUE first ## 2 2 8 TRUE second df[c(1,3),] ## cat_1 cat_2 ok other ## 1 1 9 TRUE first ## 3 3 7 FALSE third # Logical indexing on rows: df[c(T,F,T),] ## cat_1 cat_2 ok other ## 1 1 9 TRUE first ## 3 3 7 FALSE third # Named indexing on rows only works # if there are named rows: row.names(df) &lt;- c(&quot;row1&quot;, &quot;row2&quot;, &quot;row3&quot;) df[c(&quot;row1&quot;, &quot;row3&quot;),] ## cat_1 cat_2 ok other ## row1 1 9 TRUE first ## row3 3 7 FALSE third By default, if you don't include the comma in the square brackets, you are indexing the column: df[c(&quot;cat_1&quot;, &quot;ok&quot;)] ## cat_1 ok ## row1 1 TRUE ## row2 2 TRUE ## row3 3 FALSE To index columns, place expressions after the first comma: # Numeric indexing on columns: df[, 1] ## [1] 1 2 3 df[, c(1,3)] ## cat_1 ok ## row1 1 TRUE ## row2 2 TRUE ## row3 3 FALSE # Logical indexing on columns: df[, c(T, F, F, F)] ## [1] 1 2 3 # Named indexing on columns. # This is the more typical method of # column indexing: df$cat_1 ## [1] 1 2 3 # Another way to do named indexing on columns: df[,c(&quot;cat_1&quot;, &quot;ok&quot;)] ## cat_1 ok ## row1 1 TRUE ## row2 2 TRUE ## row3 3 FALSE Of course, you can index on columns and rows: # Numeric indexing on columns and rows: df[1:2, 1] ## [1] 1 2 df[1:2, c(1,3)] ## cat_1 ok ## row1 1 TRUE ## row2 2 TRUE # Logical indexing on columns and rows: df[c(T,F,T), c(T, F, F, F)] ## [1] 1 3 # Named indexing on columns and rows. # This is the more typical method of # column indexing: df$cat_1[c(T,F,T)] ## [1] 1 3 # Another way to do named indexing on columns and rows: row.names(df) &lt;- c(&quot;row1&quot;, &quot;row2&quot;, &quot;row3&quot;) df[c(&quot;row1&quot;, &quot;row3&quot;),c(&quot;cat_1&quot;, &quot;ok&quot;)] ## cat_1 ok ## row1 1 TRUE ## row3 3 FALSE Examples How can I get the first 2 rows of a data.frame named df? Click here for solution df &lt;- data.frame(cat_1=c(1,2,3), cat_2=c(9,8,7), ok=c(T, T, F), other=c(&quot;first&quot;, &quot;second&quot;, &quot;third&quot;)) df[1:2,] ## cat_1 cat_2 ok other ## 1 1 9 TRUE first ## 2 2 8 TRUE second How can I get the first 2 columns of a data.frame named df? Click here for solution df[,1:2] ## cat_1 cat_2 ## 1 1 9 ## 2 2 8 ## 3 3 7 How can I get the rows where values in the column named cat_1 are greater than 2? Click here for solution df[df$cat_1 &gt; 2,] ## cat_1 cat_2 ok other ## 3 3 7 FALSE third df[df[, c(&quot;cat_1&quot;)] &gt; 2,] ## cat_1 cat_2 ok other ## 3 3 7 FALSE third How can I get the rows where values in the column named cat_1 are greater than 2 and the values in the column named cat_2 are less than 9? Click here for solution df[df$cat_1 &gt; 2 &amp; df$cat_2 &lt; 9,] ## cat_1 cat_2 ok other ## 3 3 7 FALSE third How can I get the rows where values in the column named cat_1 are greater than 2 or the values in the column named cat_2 are less than 9? Click here for solution df[df$cat_1 &gt; 2 | df$cat_2 &lt; 9,] ## cat_1 cat_2 ok other ## 2 2 8 TRUE second ## 3 3 7 FALSE third How do I sample n rows randomly from a data.frame called df? Click here for solution df[sample(nrow(df), n),] Alternatively you could use the sample_n function from the package dplyr: sample_n(df, n) How can I get only columns whose names start with &quot;cat_&quot;? Click here for solution df &lt;- data.frame(cat_1=c(1,2,3), cat_2=c(9,8,7), ok=c(T, T, F), other=c(&quot;first&quot;, &quot;second&quot;, &quot;third&quot;)) df[, grep(&quot;^cat_&quot;, names(df))] ## cat_1 cat_2 ## 1 1 9 ## 2 2 8 ## 3 3 7 Reading &amp; Writing data Examples How do I read a csv file called grades.csv into a data.frame? Click here for solution Note that the &quot;.&quot; means the current working directory. So, if we were in &quot;/home/john/projects&quot;, &quot;./grades.csv&quot; would be the same as &quot;/home/john/projects/grades.csv&quot;. This is called a relative path. Read this for a better understanding. dat &lt;- read.csv(&quot;./grades.csv&quot;) head(dat) ## grade year ## 1 100 junior ## 2 99 sophomore ## 3 75 sophomore ## 4 74 sophomore ## 5 44 senior ## 6 69 junior How do I read a csv file called grades.csv into a data.frame using the function fread? Click here for solution Note: The function fread is part of the data.table package and which reads in dataset faster than read.csv. It is therefore recommended for reading in large datasets in R. ```r library(data.table) dat &lt;- data.frame(fread(&quot;./grades.csv&quot;)) head(dat) ``` ``` ## grade year ## 1 100 junior ## 2 99 sophomore ## 3 75 sophomore ## 4 74 sophomore ## 5 44 senior ## 6 69 junior ``` How do I read a csv file called grades2.csv where instead of being comma-separated, it is semi-colon-separated, into a data.frame? Click here for solution dat &lt;- read.csv(&quot;./grades_semi.csv&quot;, sep=&quot;;&quot;) head(dat) ## grade year ## 1 100 junior ## 2 99 sophomore ## 3 75 sophomore ## 4 74 sophomore ## 5 44 senior ## 6 69 junior How do I prevent R from reading in strings as factors when using a function like read.csv? Click here for solution In R 4.0+, strings are not read in as factors, so you do not need to do anything special. For R &lt; 4.0, use stringsAsFactors. dat &lt;- read.csv(&quot;./grades.csv&quot;, stringsAsFactors=F) head(dat) ## grade year ## 1 100 junior ## 2 99 sophomore ## 3 75 sophomore ## 4 74 sophomore ## 5 44 senior ## 6 69 junior How do I specify the type of 1 or more columns when reading in a csv file? Click here for solution dat &lt;- read.csv(&quot;./grades.csv&quot;, colClasses=c(&quot;grade&quot;=&quot;character&quot;, &quot;year&quot;=&quot;factor&quot;)) str(dat) ## &#39;data.frame&#39;: 10 obs. of 2 variables: ## $ grade: chr &quot;100&quot; &quot;99&quot; &quot;75&quot; &quot;74&quot; ... ## $ year : Factor w/ 4 levels &quot;freshman&quot;,&quot;junior&quot;,..: 2 4 4 4 3 2 2 3 1 2 Given a list of csv files with the same columns, how can I read them in and combine them into a single dataframe? Click here for solution # We want to read in grades.csv, grades2.csv, and grades3.csv # into a single dataframe. list_of_files &lt;- c(&quot;grades.csv&quot;, &quot;grades2.csv&quot;, &quot;grades3.csv&quot;) results &lt;- data.frame() for (file in list_of_files) { dat &lt;- read.csv(file) results &lt;- rbind(results, dat) } dim(results) ## [1] 32 2 How do I create a data.frame with comma-separated data that I've copied onto my clipboard? Click here for solution # For mac dat &lt;- read.delim(pipe(&quot;pbpaste&quot;),header=F,sep=&quot;,&quot;) # For windows dat &lt;- read.table(&quot;clipboard&quot;,header=F,sep=&quot;,&quot;) Control flow If/else statements If, else if, and else statements are methods for controlling whether or not an operation is performed based on the result of some expression. How do I print &quot;Success!&quot; if my expression evaluates to TRUE, and &quot;Failure!&quot; otherwise? Click here for solution # Randomly assign either TRUE or FALSE to t_or_f. t_or_f &lt;- sample(c(TRUE,FALSE),1) if (t_or_f == TRUE) { # If t_or_f is TRUE, print success print(&quot;Success!&quot;) } else { # Otherwise, print failure print(&quot;Failure!&quot;) } ## [1] &quot;Success!&quot; # You don&#39;t need to put the full expression. # This is the same thing because t_or_f # is already TRUE or FALSE. # TRUE == TRUE evaluates to TRUE and # FALSE == TRUE evaluates to FALSE. if (t_or_f) { # If t_or_f is TRUE, print success print(&quot;Success!&quot;) } else { # Otherwise, print failure print(&quot;Failure!&quot;) } ## [1] &quot;Success!&quot; How do I print &quot;Success!&quot; if my expression evaluates to TRUE, &quot;Failure!&quot; if my expression evaluates to FALSE, and &quot;Huh?&quot; otherwise? Click here for solution # Randomly assign either TRUE or FALSE to t_or_f. t_or_f &lt;- sample(c(TRUE,FALSE, &quot;Something else&quot;),1) if (t_or_f == TRUE) { # If t_or_f is TRUE, print success print(&quot;Success!&quot;) } else if (t_or_f == FALSE) { # If t_or_f is FALSE, print failure print(&quot;Failure!&quot;) } else { # Otherwise print huh print(&quot;Huh?&quot;) } ## [1] &quot;Huh?&quot; # In this case you need the full expression because # &quot;Something else&quot; does not evaluate to TRUE or FALSE # which will cause an error as the if and else if # statements expect a result of TRUE or FALSE. if (t_or_f == TRUE) { # If t_or_f is TRUE, print success print(&quot;Success!&quot;) } else if (t_or_f == FALSE) { # If t_or_f is FALSE, print failure print(&quot;Failure!&quot;) } else { # Otherwise print huh print(&quot;Huh?&quot;) } ## [1] &quot;Huh?&quot; For loops For loops allow us to execute similar code over and over again until we've looped through all of the elements. They are useful for performing the same operation to an entire vector of input, for example. Using the suite of apply functions is more common in R. It is often said that the apply suite of function are much faster than for loops in R. While this used to be the case, this is no longer true. Examples How do I loop through every value in a vector and print the value? Click here for solution for (i in 1:10) { # In the first iteration of the loop, # i will be 1. The next, i will be 2. # Etc. print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 How do I break out of a loop before it finishes? Click here for solution for (i in 1:10) { if (i==7) { # When i==7, we will exit the loop. break } print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 How do I loop through a vector of names? Click here for solution friends &lt;- c(&quot;Phoebe&quot;, &quot;Ross&quot;, &quot;Rachel&quot;, &quot;Chandler&quot;, &quot;Joey&quot;, &quot;Monica&quot;) my_string &lt;- &quot;So no one told you life was gonna be this way, &quot; for (friend in friends) { print(paste0(my_string, friend, &quot;!&quot;)) } ## [1] &quot;So no one told you life was gonna be this way, Phoebe!&quot; ## [1] &quot;So no one told you life was gonna be this way, Ross!&quot; ## [1] &quot;So no one told you life was gonna be this way, Rachel!&quot; ## [1] &quot;So no one told you life was gonna be this way, Chandler!&quot; ## [1] &quot;So no one told you life was gonna be this way, Joey!&quot; ## [1] &quot;So no one told you life was gonna be this way, Monica!&quot; How do I skip a loop if some expression evaluates to TRUE? Click here for solution friends &lt;- c(&quot;Phoebe&quot;, &quot;Ross&quot;, &quot;Mike&quot;, &quot;Rachel&quot;, &quot;Chandler&quot;, &quot;Joey&quot;, &quot;Monica&quot;) my_string &lt;- &quot;So no one told you life was gonna be this way, &quot; for (friend in friends) { if (friend == &quot;Mike&quot;) { # next, skips over the rest of the code for this loop # and continues to the next element next } print(paste0(my_string, friend, &quot;!&quot;)) } ## [1] &quot;So no one told you life was gonna be this way, Phoebe!&quot; ## [1] &quot;So no one told you life was gonna be this way, Ross!&quot; ## [1] &quot;So no one told you life was gonna be this way, Rachel!&quot; ## [1] &quot;So no one told you life was gonna be this way, Chandler!&quot; ## [1] &quot;So no one told you life was gonna be this way, Joey!&quot; ## [1] &quot;So no one told you life was gonna be this way, Monica!&quot; Are there examples in which for loops are not appropriate to use? Click here for solution This is usually how we write loops in other languages, e.g., C, C++, Java, Python, etc., if we want to add the first 10 billion integers. mytotal &lt;- 0 for (i in 1:10000000000) { mytotal &lt;- mytotal + i } mytotal ## [1] 5e+19 but this takes a long time to evaluate. It is easier to write, and much faster to evaluate, if we use the sum function, which is vectorized, i.e., which works on an entire vector of data all at once. Here, for instance, we add the first 10 billion integers, and the computation occurs almost immediately. sum(1:10000000000) ## [1] 5e+19 Click here for video Can you show an example of how to do the same thing, with a for loop and without a for loop? Click here for solution Yes, here is an example about how to compute the average cost of a line of the grocery store data. myDF &lt;- read.csv(&quot;/class/datamine/data/8451/The_Complete_Journey_2_Master/5000_transactions.csv&quot;) head(myDF) ## BASKET_NUM HSHD_NUM PURCHASE_ PRODUCT_NUM SPEND UNITS STORE_R WEEK_NUM YEAR ## 1 24 1809 03-JAN-16 5817389 -1.50 -1 SOUTH 1 2016 ## 2 24 1809 03-JAN-16 5829886 -1.50 -1 SOUTH 1 2016 ## 3 34 1253 03-JAN-16 539501 2.19 1 EAST 1 2016 ## 4 60 1595 03-JAN-16 5260099 0.99 1 WEST 1 2016 ## 5 60 1595 03-JAN-16 4535660 2.50 2 WEST 1 2016 ## 6 168 3393 03-JAN-16 5602916 4.50 1 SOUTH 1 2016 This is how we find the average cost per line in other languages, for instance, C/C++, Python, Java, etc. amountspent &lt;- 0 # we initialize a variable to keep track of the entire price of the purchases numberofitems &lt;- 0 # and we initialize a variable to keep track of the number of purchases for (myprice in myDF$SPEND) { amountspent &lt;- amountspent + myprice # we add the price of the current purchase numberofitems &lt;- numberofitems + 1 # and we increment (by 1) the number o purchases processed so far } amountspent # this is the total amount spent on all purchases ## [1] 3584366 numberofitems # this is the total number of purchases ## [1] 1e+06 amountspent/numberofitems # so this is the average ## [1] 3.584366 amountspent/length(myDF$SPEND) # this is an equivalent way to compute the average ## [1] 3.584366 For comparison, this is the much easier way that we can use a vectorized function in R, to accomplish the same purpose. The vector is the column myDF$SPEND. We can just focus our attention on that column from the data frame, and take a mean. mean(myDF$SPEND) ## [1] 3.584366 Click here for video Can you show an example of how to make a new column in a data frame, which classifies things, based on another column? Click here for solution Yes, we can make a new column in the grocery store data set. myDF &lt;- read.csv(&quot;/class/datamine/data/8451/The_Complete_Journey_2_Master/5000_transactions.csv&quot;) head(myDF) ## BASKET_NUM HSHD_NUM PURCHASE_ PRODUCT_NUM SPEND UNITS STORE_R WEEK_NUM YEAR ## 1 24 1809 03-JAN-16 5817389 -1.50 -1 SOUTH 1 2016 ## 2 24 1809 03-JAN-16 5829886 -1.50 -1 SOUTH 1 2016 ## 3 34 1253 03-JAN-16 539501 2.19 1 EAST 1 2016 ## 4 60 1595 03-JAN-16 5260099 0.99 1 WEST 1 2016 ## 5 60 1595 03-JAN-16 4535660 2.50 2 WEST 1 2016 ## 6 168 3393 03-JAN-16 5602916 4.50 1 SOUTH 1 2016 Let's first make a new vector (the same length as a column of the data frame) in which all of the entries are safe. mystatus &lt;- rep(&quot;safe&quot;, times=nrow(myDF)) and then we can change the entries for the elements of mystatus that occurred on 05-JUL-16 or on 06-JUL-16 to be contaminated. mystatus[(myDF$PURCHASE_ == &quot;05-JUL-16&quot;)|(myDF$PURCHASE_ == &quot;06-JUL-16&quot;)] &lt;- &quot;contaminated&quot; and finally change this into a factor, and add it as a new column in the data frame. myDF$safetystatus &lt;- factor(mystatus) Now the head of the data frame looks like this: head(myDF) ## BASKET_NUM HSHD_NUM PURCHASE_ PRODUCT_NUM SPEND UNITS STORE_R WEEK_NUM YEAR ## 1 24 1809 03-JAN-16 5817389 -1.50 -1 SOUTH 1 2016 ## 2 24 1809 03-JAN-16 5829886 -1.50 -1 SOUTH 1 2016 ## 3 34 1253 03-JAN-16 539501 2.19 1 EAST 1 2016 ## 4 60 1595 03-JAN-16 5260099 0.99 1 WEST 1 2016 ## 5 60 1595 03-JAN-16 4535660 2.50 2 WEST 1 2016 ## 6 168 3393 03-JAN-16 5602916 4.50 1 SOUTH 1 2016 ## safetystatus ## 1 safe ## 2 safe ## 3 safe ## 4 safe ## 5 safe ## 6 safe and the number of contaminated rows versus safe rows is this: table(myDF$safetystatus) ## ## contaminated safe ## 2459 997541 Click here for video Apply functions apply lapply The lapply is a function that applies a function FUN to each element in a vector or list, and returns a list. Examples How do I get the mean value of each vector in our list, my_list, in another list? Click here for solution lapply(my_list, mean) ## $pages ## [1] 3 ## ## $words ## [1] 30 ## ## $letters ## [1] 300 How can I find the average of several variables in the flight data, using only 1 line of R, with the lapply function? Click here for video These are the flights from 2003: myDF &lt;- read.csv(&quot;/class/datamine/data/flights/subset/2003.csv&quot;) We can break the flights into categories, depending on the Distance of the flight: less than 100 miles; from 100 to 200 miles; from 200 to 500 miles; from 500 to 1000 miles; from 1000 to 2000 miles; more than 2000 miles my_distance_categories &lt;- cut(myDF$Distance, breaks = c(0,100,200,500,1000,2000,Inf), include.lowest=T) The numbers of flights in each category are: table(my_distance_categories) Here are the average values of 4 variables, in each of these 6 categories: tapply( myDF$DepDelay, my_distance_categories, mean, na.rm=T) # the DepDelay in each category tapply( myDF$ArrDelay, my_distance_categories, mean, na.rm=T) # the ArrDelay in each category tapply( myDF$TaxiOut, my_distance_categories, mean, na.rm=T) # the time to TaxiOut in each category tapply( myDF$TaxiIn, my_distance_categories, mean, na.rm=T) # the time to TaxiIn in each category OR, MUCH EASIER: We can do all of this with just 1 line of R. To make it easier to read, we can make a temporary data frame flights_by_distance with these 4 variables. Then we split the data into 6 data frames, according to the Distance of the flights, and we get the average DepDelay, ArrDelay, TaxiOut, and TaxiIn, in each of these 6 categories, with only 1 line of R. Notice that this agrees exactly with the results of the 4 separate tapply functions, but it only takes us 1 call to the lapply function!! flights_by_distance &lt;- split( data.frame(myDF$DepDelay, myDF$ArrDelay, myDF$TaxiOut, myDF$TaxiIn), my_distance_categories ) lapply( flights_by_distance, colMeans, na.rm=T ) Some closing remarks about this example: We use lapply on a list. It only takes two arguments, namely, a list and a function to run on each piece of our list. In this case, we are taking an average (colMeans) of each column in each piece of our list. The flights_by_distance is a list of 6 data frames You might want to check these out. class( flights_by_distance ) length( flights_by_distance ) class(flights_by_distance[[1]]) class(flights_by_distance[[2]]) class(flights_by_distance[[3]]) class(flights_by_distance[[4]]) class(flights_by_distance[[5]]) class(flights_by_distance[[6]]) head(flights_by_distance[[1]]) head(flights_by_distance[[2]]) head(flights_by_distance[[3]]) head(flights_by_distance[[4]]) head(flights_by_distance[[5]]) head(flights_by_distance[[6]]) You can take the colMeans within each of these data frames, like this: colMeans(flights_by_distance[[1]], na.rm=T) colMeans(flights_by_distance[[2]], na.rm=T) colMeans(flights_by_distance[[3]], na.rm=T) colMeans(flights_by_distance[[4]], na.rm=T) colMeans(flights_by_distance[[5]], na.rm=T) colMeans(flights_by_distance[[6]], na.rm=T) but this is all accomplished by the 1-line lapply that we did earlier, in a much easier way. How can I find the average of several variables in the fars data, using only 1 line of R, with the lapply function? Click here for video This is the fars data set, studied in STAT 19000 Project 6 (only the years 1975 to 1981) dat &lt;- read.csv(&quot;/class/datamine/data/fars/7581.csv&quot;) We will learn a more efficient way to add the state names but for now, we do this in the same way as Project 6. state_names &lt;- read.csv(&quot;/class/datamine/data/fars/states.csv&quot;) v &lt;- state_names$state names(v) &lt;- state_names$code dat$mystates &lt;- v[as.character(dat$STATE)] In Project 6, Question 2, we found the average number of DRUNK_DR, according to the state: tapply( dat$DRUNK_DR, dat$mystates, mean) We might also want to find the average number fatalities (FATALS) per accident, according to the state: tapply( dat$FATALS, dat$mystates, mean) and the average number of people (PERSONS) involved per accident, according to the state: tapply( dat$PERSONS, dat$mystates, mean) OR, MUCH EASIER: We can do all 3 of these calculations with just 1 line of R. To make it easier to read, we can make a temporary data frame accidents_by_state with these 3 variables. Then we split the data into 51 data frames, according to the state where the accident occurred, and we get the average DRUNK_DR, FATALS, and PERSONS in each of these 51 categories, with only 1 line of R. Notice that this agrees exactly with the results of the 3 separate tapply functions, but it only takes us 1 call to the lapply function!! accidents_by_state &lt;- split( data.frame(dat$DRUNK_DR, dat$FATALS, dat$PERSONS), dat$mystates ) lapply( accidents_by_state, colMeans ) Again, some closing remarks: We use lapply on a list. It only takes two arguments, namely, a list and a function to run on each piece of our list. In this case, we are taking an average (colMeans) of each column in each piece of our list. The accidents_by_state is a list of 51 data frames. You might want to check these out. class( accidents_by_state ) length( accidents_by_state ) class(accidents_by_state[[1]]) class(accidents_by_state[[2]]) # etc., etc. class(accidents_by_state[[50]]) class(accidents_by_state[[51]]) head(accidents_by_state[[1]]) head(accidents_by_state[[2]]) # etc., etc. head(accidents_by_state[[50]]) head(accidents_by_state[[51]]) You can also extract the elements of the list according to their names, e.g., head(accidents_by_state$Indiana) colMeans(accidents_by_state$Indiana) head(accidents_by_state$Illinois) colMeans(accidents_by_state$Illinois) head(accidents_by_state$Ohio) colMeans(accidents_by_state$Ohio) head(accidents_by_state$Michigan) colMeans(accidents_by_state$Michigan) but this is all accomplished by the 1-line lapply that we did earlier, in a much easier way. sapply sapply is very similar to lapply, however, where lapply always returns a list, sapply will simplify the output of applying the function FUN to each element. If you recall, when accessing an element in a list using single brackets my_list[1], the result will always return a list. If you access an element with double brackets my_list[[1]], R will attempt to simplify the result. This is analogous to lapply and sapply. Examples How do I get the mean value of each vector in our list, my_list, but rather than the result being a list, put the results in the simplest form? Click here for solution sapply(my_list, mean) ## pages words letters ## 3 30 300 Use the provided function to create a new column in the data.frame example_df named transformed. transformed should contain TRUE if the value in pre_transformed is &quot;t&quot;, FALSE if it is &quot;f&quot;, and NA otherwise. string_to_bool &lt;- function(value) { if (value == &quot;t&quot;) { return(TRUE) } else if (value == &quot;f&quot;) { return(FALSE) } else { return(NA) } } example_df &lt;- data.frame(pre_transformed=c(&quot;f&quot;, &quot;f&quot;, &quot;t&quot;, &quot;f&quot;, &quot;something&quot;, &quot;t&quot;, &quot;else&quot;, &quot;&quot;), other=c(1,2,3,4,5,6,7,8)) example_df ## pre_transformed other ## 1 f 1 ## 2 f 2 ## 3 t 3 ## 4 f 4 ## 5 something 5 ## 6 t 6 ## 7 else 7 ## 8 8 Click here for solution example_df$transformed &lt;- sapply(example_df$pre_transformed, string_to_bool) example_df ## pre_transformed other transformed ## 1 f 1 FALSE ## 2 f 2 FALSE ## 3 t 3 TRUE ## 4 f 4 FALSE ## 5 something 5 NA ## 6 t 6 TRUE ## 7 else 7 NA ## 8 8 NA tapply tapply is described in the documentation as a way to &quot;apply a function to each cell of a ragged array, that is to each (non-empty) group of values given by a unique combination of the levels of certain factors.&quot; This is not a very useful description. An alternative way to think about tapply, is as a function that allows you to calculate or apply function to data1 when data1 is grouped by data2. tapply(data1, data2, function) A concrete example would be getting the mean (function) grade (data1) when grade (data1) is grouped by year (data2): grades ## grade year sex ## 1 100 junior M ## 2 99 sophomore F ## 3 75 sophomore M ## 4 74 sophomore M ## 5 44 senior F ## 6 69 junior M ## 7 88 junior F ## 8 99 senior &lt;NA&gt; ## 9 90 freshman M ## 10 92 junior F tapply(grades$grade, grades$year, mean) ## freshman junior senior sophomore ## 90.00000 87.25000 71.50000 82.66667 If your function (in this case mean), requires extra arguments, you can pass those by name to tapply. This is what the ... argument in tapply is for. For example, if we want our mean function to remove na's prior to calculating a mean we could do the following: tapply(grades$grade, grades$year, mean, na.rm=T) ## freshman junior senior sophomore ## 90.00000 87.25000 71.50000 82.66667 Examples Amazon fine food tapply example Here is an example using the Amazon fine food reviews myDF &lt;- read.csv(&quot;/class/datamine/data/amazon/amazon_fine_food_reviews.csv&quot;) This is the data source: https://www.kaggle.com/snap/amazon-fine-food-reviews/ The people who wrote the most reviews are tail(sort(table(myDF$UserId))) In particular, user A3OXHLG6DIBRW8 wrote the most reviews. The total number of people who read reviews that were written by A3OXHLG6DIBRW8 is: sum(myDF$HelpfulnessDenominator[myDF$UserId == &quot;A3OXHLG6DIBRW8&quot;]) The number of people who found those reviews (written by A3OXHLG6DIBRW8) to be helpful is: sum(myDF$HelpfulnessNumerator[myDF$UserId == &quot;A3OXHLG6DIBRW8&quot;]) So, altogether, when people read the reviews written by user A3OXHLG6DIBRW8, these reviews were rated as helpful 0.9795918 of the time sum(myDF$HelpfulnessNumerator[myDF$UserId == &quot;A3OXHLG6DIBRW8&quot;])/sum(myDF$HelpfulnessDenominator[myDF$UserId == &quot;A3OXHLG6DIBRW8&quot;]) Now we can do this again, for all users. The total number of people who read reviews altogether, grouped by the user who wrote the review, is head( tapply(myDF$HelpfulnessDenominator, myDF$UserId, sum) ) The total number of people who rated reviews as helpful, grouped by the user who wrote the review, is head( tapply(myDF$HelpfulnessNumerator, myDF$UserId, sum) ) The percentages of people who found reviews to be helpful, grouped according to who wrote the review, are head( tapply(myDF$HelpfulnessNumerator, myDF$UserId, sum)/tapply(myDF$HelpfulnessDenominator, myDF$UserId, sum) ) We can double-check our result for user &quot;A3OXHLG6DIBRW8&quot; as follows ( tapply(myDF$HelpfulnessNumerator, myDF$UserId, sum)/tapply(myDF$HelpfulnessDenominator, myDF$UserId, sum) )[&quot;A3OXHLG6DIBRW8&quot;] Click here for video Writing functions In a nutshell, a function is a set of instructions or actions packaged together in a single definition or unit. Typically, function accept 0 or more arguments as input, and returns 0 or more results as output. The following is an example of a function in R: # word_count is a function that accepts a sentence as an argument, # strips punctuation and extra space, and returns the number of # words in the sentence. word_count &lt;- function(sentence) { # strip punctuation and save into an auxiliary variable aux &lt;- gsub(&#39;[[:punct:]]+&#39;,&#39;&#39;, sentence) # split the sentence by space and remove extra spaces result &lt;- sum(unlist(strsplit(aux, &quot; &quot;)) != &quot;&quot;) return(result) } test_sentence &lt;- &quot;this is a sentence, with 7 words.&quot; word_count(test_sentence) ## [1] 7 The function is named word_count. The function has a single parameter named sentence. The function returns a single value, result, which is the number of words in the provided sentence. test_sentence is the argument to word_count. An argument is the actual value passed to the function. We pass values to functions -- this just means we use the values as arguments to the function. The parameter, sentence, is the name shown in the function definition. Functions can have helper functions. A helper function is a function defined and used within another function in order to reduce complexity or make the task at hand more clear. For example, we could have written the previous function differently: # word_count is a function that accepts a sentence as an argument, # strips punctuation and extra space, and returns the number of # words in the sentence. word_count &lt;- function(sentence) { # a helper function that takes care of removing # punctuation and extra spaces. split_and_clean &lt;- function(sentence) { # strip punctuation and save into an auxiliary variable aux &lt;- gsub(&#39;[[:punct:]]+&#39;,&#39;&#39;, sentence) # remove extra spaces aux &lt;- unlist(strsplit(aux, &quot; &quot;)) return(aux[aux!=&quot;&quot;]) } # return the length of the sentence result &lt;- length(split_and_clean(sentence)) return(result) } test_sentence &lt;- &quot;this is a sentence, with 7 words.&quot; word_count(test_sentence) ## [1] 7 Here, our helper function is named split_and_clean. If you try to call split_and_clean outside of word_count, you will get an error. split_and_clean is defined within the scope of word_count and is not available outside that scope. In this example, word_count is the caller, the function that calls the other function, split_and_clean. The other function, split_and_clean, can be referred to as the callee. In R functions can be passed to other functions as arguments. In general, functions that accept another function as an argument or return functions, are called higher order functions. Some examples of higher order functions in R are sapply, lapply, tapply, Map, and Reduce. The function passed as an argument, is often referred to as a callback function, as the caller is expected to call back (execute) the argument at a later point in time. ... The ellipsis ... in R can be used to pass an unknown number of arguments to a function. For example, if you look at the documentation for sapply (?sapply), you will see the following in the usage section: sapply(X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE) In the arguments section, it says the ellipsis are &quot;optional arguments to FUN&quot;. sapply uses the ellipsis as a vehicle to pass an unknown number of arguments to the callback function. In practice, this could look something like: dims &lt;- function(..., sort=F) { args &lt;- list(...) arg_names &lt;- names(args) results &lt;- lapply(args, dim) if (is.null(arg_names) | sort==FALSE) { # arguments not passed with a name return(results) } return(results[order(names(results))]) } dims(grades) ## [[1]] ## [1] 10 3 dims(grades, my_mat) ## [[1]] ## [1] 10 3 ## ## [[2]] ## [1] 4 3 dims(xyz=grades, abc=my_mat) ## $xyz ## [1] 10 3 ## ## $abc ## [1] 4 3 dims(xyz=grades, abc=my_mat, sort=T) ## $abc ## [1] 4 3 ## ## $xyz ## [1] 10 3 Here, dims accepts any number of data.frame-like objects, ..., and a logical value indicating whether or not to sort the list by names. As you can see, if arguments are passed to dims with names, those names can be accessed within dims via names(list(...)). Examples Create a function named should_be_transformed that, given a value, returns TRUE if the value is &quot;t&quot;, and FALSE if the value is &quot;f&quot;, and NA otherwise. example_df &lt;- data.frame(column_to_test=c(&quot;f&quot;, &quot;f&quot;, &quot;t&quot;, &quot;f&quot;, &quot;something&quot;, &quot;t&quot;, &quot;else&quot;, &quot;&quot;), other=c(1,2,3,4,5,6,7,8)) example_df ## column_to_test other ## 1 f 1 ## 2 f 2 ## 3 t 3 ## 4 f 4 ## 5 something 5 ## 6 t 6 ## 7 else 7 ## 8 8 Click here for solution should_be_transformed &lt;- function(value) { if (value == &quot;t&quot;) { return(TRUE) } else if (value == &quot;f&quot;) { return(FALSE) } else { return(NA) } } should_be_transformed(example_df$column_to_test[1]) ## [1] FALSE should_be_transformed(example_df$column_to_test[3]) ## [1] TRUE should_be_transformed(example_df$column_to_test[5]) ## [1] NA Plotting barplot barplot is a function that creates a barplot. Barplots are used to display categorical data. The following is an example of plotting some data from the precip dataset. barplot(precip[1:10]) As you can see, the x-axis labels are bad. What if we turn the labels to be vertical? barplot(precip[1:10], las=2) Much better, however, some of the longer names go off of the plot. Let's fix this: par(oma=c(3,0,0,0)) # oma stands for outer margins. We increase the bottom margin to 3. barplot(precip[1:10], las=2) This is even better, however, it would be nice to have a title and axis label(s). par(oma=c(3,0,0,0)) # oma stands for outer margins. We increase the bottom margin to 3. barplot(precip[1:10], las=2, main=&quot;Average Precipitation&quot;, ylab=&quot;Inches of rain&quot;) We are getting there. Let's add some color. par(oma=c(3,0,0,0)) # oma stands for outer margins. We increase the bottom margin to 3. barplot(precip[1:10], las=2, main=&quot;Average Precipitation&quot;, ylab=&quot;Inches of rain&quot;, col=&quot;blue&quot;) What if we want different colors for the different cities? library(RColorBrewer) par(oma=c(3,0,0,0)) # oma stands for outer margins. We increase the bottom margin to 3. colors &lt;- brewer.pal(10, &quot;Set3&quot;) barplot(precip[1:10], las=2, main=&quot;Average Precipitation&quot;, ylab=&quot;Inches of rain&quot;, col=colors) What if instead of x-axis labels, we want to use a legend? library(RColorBrewer) par(oma=c(0,0,0,0)) # oma stands for outer margins. We increase the bottom margin to 3. colors &lt;- brewer.pal(10, &quot;Set3&quot;) barplot(precip[1:10], las=2, main=&quot;Average Precipitation&quot;, ylab=&quot;Inches of rain&quot;, col=colors, legend=T, names.arg=F) Pretty good, but now we don't need so much space at the bottom, and we need to make space for that legend. We use xlim to increase the x-axis, and args.legend to move the position of the legend along the x and y axes. library(RColorBrewer) colors &lt;- brewer.pal(10, &quot;Set3&quot;) barplot(precip[1:10], las=2, main=&quot;Average Precipitation&quot;, ylab=&quot;Inches of rain&quot;, col=colors, legend=T, names.arg=F, xlim=c(0, 15), args.legend=list(x=16.5, y=46)) It's looking good, let's remove the box around the legend: library(RColorBrewer) colors &lt;- brewer.pal(10, &quot;Set3&quot;) barplot(precip[1:10], las=2, main=&quot;Average Precipitation&quot;, ylab=&quot;Inches of rain&quot;, col=colors, legend=T, names.arg=F, xlim=c(0, 15), args.legend=list(x=16.5, y=46, bty=&quot;n&quot;)) boxplot boxplot is a function that creates a box and whisker plot, given some grouped data. The following is an example using the trees dataset. First, we break our data into groups based on height. dat &lt;- trees dat$size &lt;- cut(trees$Height, breaks=c(0,76,100)) levels(dat$size) &lt;- c(&quot;short&quot;, &quot;tall&quot;) Next, we start with a box plot: boxplot(dat$Girth ~ dat$size) Let's spruce things up with proper labels: boxplot(dat$Girth ~ dat$size, main=&quot;Tree girth&quot;, ylab=&quot;Girth in Inches&quot;, names=c(&quot;Short&quot;, &quot;Tall&quot;), xlab=&quot;&quot;) Let's add color: boxplot(dat$Girth ~ dat$size, main=&quot;Tree girth&quot;, ylab=&quot;Girth in Inches&quot;, names=c(&quot;Short&quot;, &quot;Tall&quot;), xlab=&quot;&quot;, border=&quot;darkgreen&quot;, col=&quot;lightgreen&quot;) pie pie is a function that creates a piechart.pie charts are used to display categorical data. The following is an example using the USPersonalExpenditure dataset. First, let's get the mean expenditure: # Quick look at data: USPersonalExpenditure ## 1940 1945 1950 1955 1960 ## Food and Tobacco 22.200 44.500 59.60 73.2 86.80 ## Household Operation 10.500 15.500 29.00 36.5 46.20 ## Medical and Health 3.530 5.760 9.71 14.0 21.10 ## Personal Care 1.040 1.980 2.45 3.4 5.40 ## Private Education 0.341 0.974 1.80 2.6 3.64 # Mean expenditure expenditure &lt;- rowMeans(USPersonalExpenditure) Now, we can create our pie chart. pie(expenditure) Let's use some different colors! pie(expenditure, col = c(&quot;#8E6F3E&quot;, &quot;#1c5253&quot;,&quot;#23395b&quot;,&quot;#6F727B&quot;, &quot;#F97B64&quot;)) Let's add the percentages next to the names. To do so, we must first get those values: # calculating percentages expenditure_percentage &lt;- 100*expenditure/sum(expenditure) # rounding percentages to 2 decimal places expenditure_percentage &lt;- round(expenditure_percentage, 2) # combining names with percentages expenditure_names &lt;- paste0(names(expenditure), &quot; (&quot;, expenditure_percentage, &quot;%)&quot;) # creating new labels pie(expenditure, labels = expenditure_names, col = c(&quot;#8E6F3E&quot;, &quot;#1c5253&quot;,&quot;#23395b&quot;,&quot;#6F727B&quot;, &quot;#F97B64&quot;)) Let's add a title: pie(expenditure, labels = expenditure_names, col = c(&quot;#8E6F3E&quot;, &quot;#1c5253&quot;,&quot;#23395b&quot;,&quot;#6F727B&quot;, &quot;#F97B64&quot;), main = &quot;Mean US expenditure from 1940 to 1960&quot;) dotchart dotchart draws a Cleveland dot plot. Fun Fact: Dr. Cleveland is a Distinguished Professor in the Statistics department at Purdue University! The following is an example using the built-in HairEyeColor dataset. First, let's consider only individuals with black hair. # Selecting only individuals with black hair black_hair = HairEyeColor[1,,] # Summing both Male and Female. black_hair = rowSums(black_hair) Now we can create our dotchart. dotchart(black_hair) Let's add a title, and labels to the x-axis and the y-axis. dotchart(black_hair, main=&#39;Eye color for individuals with black hair&#39;, xlab=&#39;Count&#39;, ylab=&#39;Eye color&#39;) That's better. Let's arrange the data in an ascending manner. # re-ordering the data black_hair &lt;- sort(black_hair) dotchart(black_hair, main=&#39;Eye color for individuals with black hair&#39;, xlab=&#39;Count&#39;, ylab=&#39;Eye color&#39;) How about some color? dotchart(black_hair, main=&#39;Eye color for individuals with black hair&#39;, xlab=&#39;Count&#39;, ylab=&#39;Eye color&#39;, bg=&#39;orange&#39;) plot plot is a generic plotting function. It creates scatter plots as well as line plots. The argument type allows you to define the type of plot that should be drawn. Most common types are &quot;p&quot; for points (default), &quot;l&quot; for lines, and &quot;b&quot; for both. Scatter plots Below is an example using the built-in Orange dataset. plot(Orange$age, Orange$circumference) The labels for x-axis and y-axis can be improved! plot(Orange$age, Orange$circumference, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;) We can also add a title. plot(Orange$age, Orange$circumference, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;, main=&#39;Growth of orange trees&#39;) The argument pch specifies what symbol to use when plotting. pch set at &quot;21&quot; enables us to have colored circles. We can specify both the border and fill colors. Let's give it a try. plot(Orange$age, Orange$circumference, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;, main=&#39;Growth of orange trees&#39;, pch=21, bg=&#39;lightblue&#39;, col=&#39;tomato&#39;) How about coloring the points based on the tree? plot(Orange$age, Orange$circumference, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;, main=&#39;Growth of orange trees&#39;, pch=21, bg=Orange$Tree) Line plots Below is an example using the built-in Orange dataset. plot(Orange$age, Orange$circumference, type=&#39;l&#39;) Let's fix the title and axes labels. plot(Orange$age, Orange$circumference, type=&#39;l&#39;, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;, main=&#39;Growth of orange trees&#39;) lty is an argument that allows us to change the linetype. This is the equivalent version of pch for lines. There 7 options: &quot;blank&quot;, &quot;solid&quot;, &quot;dashed&quot;, &quot;dotted&quot;, &quot;dotdash&quot;, &quot;longdash&quot;, and &quot;twodash&quot;. plot(Orange$age, Orange$circumference, type=&#39;l&#39;, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;, main=&#39;Growth of orange trees&#39;, lty=&#39;longdash&#39;) We can also modify the thickness of the lines using the argument lwd. Below is an example. plot(Orange$age, Orange$circumference, type=&#39;l&#39;, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;, main=&#39;Growth of orange trees&#39;, lty=&#39;longdash&#39;, lwd=1.5) lines lines draws additional lines to an existing graphic. For example, let's add lines to our orange scatter plot. # Original chart plot(Orange$age, Orange$circumference, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;, main=&#39;Growth of orange trees&#39;, pch=21, bg=Orange$Tree) # Adding lines lines(Orange$age, Orange$circumference) The lines are too strong. It will probably be nicer to have them in a different type, such as &quot;dotted&quot;. # Original chart plot(Orange$age, Orange$circumference, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;, main=&#39;Growth of orange trees&#39;, pch=21, bg=Orange$Tree) # Adding lines lines(Orange$age, Orange$circumference, lty=&#39;dotted&#39;) Note that we could continue to add lines. For example, suppose we now want to add the average orange growth line. # Original chart plot(Orange$age, Orange$circumference, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;, main=&#39;Growth of orange trees&#39;, pch=21, bg=Orange$Tree) # Adding lines lines(Orange$age, Orange$circumference, lty=&#39;dotted&#39;) # Getting average growth avg_growth &lt;- tapply(Orange$circumference, Orange$age, mean) # Adding the average growth line lines(unique(Orange$age), avg_growth, col=&#39;tomato&#39;, lwd=2.5) We can add lines to any plot. Here is an example adding lines to a barplot. # Original chart par(oma=c(3,0,0,0)) barplot(precip[1:10], las=2) # Adding a dot-dash vertical line lines(0:12, rep(20,13), lty=&#39;longdash&#39;) points points draws points on an existing graphic. For example, let's add the points to the line plot we did earlier. # Original chart plot(Orange$age, Orange$circumference, type=&#39;l&#39;, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;, main=&#39;Growth of orange trees&#39;) # Adding points points(Orange$age, Orange$circumference) It's hard to see the points. It would help to have the lines be dark grey, and have the points be colored. # Original chart with grey lines plot(Orange$age, Orange$circumference, type=&#39;l&#39;, xlab=&#39;Tree age&#39;, ylab=&#39;Tree circumference&#39;, main=&#39;Growth of orange trees&#39;, col=&#39;grey&#39;) # Adding points points(Orange$age, Orange$circumference, pch=20, col=&#39;tomato&#39;) Much better! Similar to lines, we can add points to any plot. Here is an example adding lines to a barplot. # Original chart par(oma=c(3,0,0,0)) barplot(precip[1:10], las=2) # Adding a dot-dash vertical line x_values &lt;- seq(1,10, length=10) + seq(-.3,1.5,length=10) # adjusting x positions points(x_values, precip[1:10], pch=21, bg=&#39;steelblue&#39;) abline abline is similar to the lines function. Below are some examples. Let's add a Y=X line (with intercept=0 and slope=1). # Original chart plot(cars$speed, cars$dist, xlab=&quot;Speed (mph)&quot;, ylab=&quot;Stopping distance (ft)&quot;) # Adding Y=X line abline(a=0, b=1) # a = intercept, b=slope Let's add a horizontal line at 60. # Original chart plot(cars$speed, cars$dist, xlab=&quot;Speed (mph)&quot;, ylab=&quot;Stopping distance (ft)&quot;) # Adding a dotted horizontal line abline(h=60, lty=&#39;dotted&#39;) Let's add a vertical line at 15. # Original chart plot(cars$speed, cars$dist, xlab=&quot;Speed (mph)&quot;, ylab=&quot;Stopping distance (ft)&quot;) # Adding a dot-dash vertical line abline(v=15, lty=&#39;dotdash&#39;) As with lines and points, we can continue to add ablines. # Original chart plot(cars$speed, cars$dist, xlab=&quot;Speed (mph)&quot;, ylab=&quot;Stopping distance (ft)&quot;) # Adding Y=X line abline(a=0, b=1) # a = intercept, b=slope # Adding a dotted horizontal line abline(h=60, lty=&#39;dotted&#39;) # Adding a dot-dash vertical line abline(v=15, lty=&#39;dotdash&#39;) As lines and points we can add ablines to any plot. Here is an example adding lines to a dotchart. # Original chart dotchart(black_hair, main=&#39;Eye color for individuals with black hair&#39;, xlab=&#39;Count&#39;, ylab=&#39;Eye color&#39;, bg=&#39;orange&#39;) # Adding a dot-dash vertical line abline(v=15, lty=&#39;dotdash&#39;) text text enables us to add texts to our plots. Similarly to points,lines, and abline we can add text to any plot. For the example below, we will focus on scatter plots and the built-in dataset mtcars. # Original chart plot(mtcars$mpg, mtcars$disp, xlab=&#39;Miles/(US) gallon&#39;, ylab=&#39;Displacement (cu.in.)&#39;, pch=21, bg=&#39;orange&#39;) # Text with some additional comments # x and y enables us to select a location text(x=29,y=460,&#39;Note a downward trend&#39;) How about making it italicized? We can change the font using the font argument. It takes 4 values: 1 or plain, 2 or bold, 3 or italic, 4 and bold-italic. # Original chart plot(mtcars$mpg, mtcars$disp, xlab=&#39;Miles/(US) gallon&#39;, ylab=&#39;Displacement (cu.in.)&#39;, pch=21, bg=&#39;orange&#39;) # Text with some additional comments text(x=29,y=460,&#39;Note a downward trend&#39;, font=3) How about we add labels that show what cars are some (or all) of these points? We can do this using the argument labels. # Original chart plot(mtcars$mpg, mtcars$disp, xlab=&#39;Miles/(US) gallon&#39;, ylab=&#39;Displacement (cu.in.)&#39;, pch=21, bg=&#39;orange&#39;) # Text with some additional comments text(x=29,y=460,&#39;Note a downward trend&#39;, font=3) # Selecting some cars subset_mtcars &lt;- subset(mtcars, ((mpg&gt;18&amp;mpg&lt;20)&amp;disp&gt;300)) # Label to some cars text(x=subset_mtcars$mpg,y=subset_mtcars$disp,labels=row.names(subset_mtcars)) We can definitely improve the location of these labels. Let's add some offset to the x-axis. We can do this two ways: Literally add an offset to x, or Use the adj argument. Below is the example for option (1). # Original chart plot(mtcars$mpg, mtcars$disp, xlab=&#39;Miles/(US) gallon&#39;, ylab=&#39;Displacement (cu.in.)&#39;, pch=21, bg=&#39;orange&#39;) # Text with some additional comments text(x=29,y=460,&#39;Note a downward trend&#39;, font=3) # Label to some cars with an offset to x-axis text(x=subset_mtcars$mpg+4.5,y=subset_mtcars$disp,labels=row.names(subset_mtcars)) Below is the example for option (2). # Original chart plot(mtcars$mpg, mtcars$disp, xlab=&#39;Miles/(US) gallon&#39;, ylab=&#39;Displacement (cu.in.)&#39;, pch=21, bg=&#39;orange&#39;) # Text with some additional comments text(x=29,y=460,&#39;Note a downward trend&#39;, font=3) # Label to some cars text(x=subset_mtcars$mpg,y=subset_mtcars$disp,labels=row.names(subset_mtcars), adj=-0.1) Could we decrease the size of the labels? # Original chart plot(mtcars$mpg, mtcars$disp, xlab=&#39;Miles/(US) gallon&#39;, ylab=&#39;Displacement (cu.in.)&#39;, pch=21, bg=&#39;orange&#39;) # Text with some additional comments text(x=29,y=460,&#39;Note a downward trend&#39;, font=3) # Label to some cars text(x=subset_mtcars$mpg,y=subset_mtcars$disp,labels=row.names(subset_mtcars), adj=-0.1, cex=.8) mtext mtext is similar to the text function. However, it enables you to write in one of the four margins of the plot. Below is an example using the built-in mtcars dataset. # Original chart plot(mtcars$mpg, mtcars$disp, xlab=&#39;Miles/(US) gallon&#39;, ylab=&#39;Displacement (cu.in.)&#39;, pch=21, bg=&#39;orange&#39;, main=&#39;Motor trend car results&#39;) # Adding text to the top margin: mtext(&quot;Data from 1974 Motor Trend US magazine&quot;, font=3, cex=.7) # Recall that `cex` controls the font size. legend The legend function enables us to add legends to plots. The example below uses the built-in dataset iris. The scatter plot below colors the data based on the flower's species. # Original chart, colors are based on species plot(iris$Sepal.Length, iris$Sepal.Width, xlab=&#39;Sepal length&#39;, ylab=&#39;Sepal width&#39;, pch=21, bg=iris$Species) Let's create a legend for this plot to make it clear what the colors represent. # Original chart, colors are based on species plot(iris$Sepal.Length, iris$Sepal.Width, xlab=&#39;Sepal length&#39;, ylab=&#39;Sepal width&#39;, pch=21, bg=iris$Species) # Adding a legend: legend(&quot;topright&quot;, legend=unique(iris$Species), col=1:3, pc=20) We can improve the look of the legend by making the points bigger, and removing the box. # Original chart, colors are based on species plot(iris$Sepal.Length, iris$Sepal.Width, xlab=&#39;Sepal length&#39;, ylab=&#39;Sepal width&#39;, pch=21, bg=iris$Species) # Adding a legend: legend(&quot;topright&quot;, legend=unique(iris$Species), col=1:3, pc=20, pt.cex = 1.5, # changing just the point size bty=&#39;n&#39;) # removing box What if we made the legend's text smaller and italicized? # Original chart, colors are based on species plot(iris$Sepal.Length, iris$Sepal.Width, xlab=&#39;Sepal length&#39;, ylab=&#39;Sepal width&#39;, pch=21, bg=iris$Species) # Adding a legend: legend(&quot;topright&quot;, legend=unique(iris$Species), col=1:3, pc=20, cex = .9, # text size text.font=3, # italic text pt.cex = 1.5, # changing just the point size bty=&#39;n&#39;) # removing box par par allows us to set several graphical parameters. Among the many parameters that can be set, some of the most commonly used ones are mfrow, mfcol, mar, and oma. mfrow and mfcol enables us to create a layout for plots, so that we can include several graphs side by side. mar and oma set margins using the following form c(bottom, left, top, right). oma looks at outer margins. Note that you can set several parameters all at once. mfrow, mfcol The example below uses the built-in data mtcars. mfrow and mfcol takes vector of the form c(nr, nc), where nr represents the number of rows and nc the number of columns. par(mfrow=c(2,3)) # two rows, three columns # Plot #1 plot(mtcars$mpg, mtcars$disp, xlab=&#39;Miles/(US) gallon&#39;, ylab=&#39;Displacement (cu.in.)&#39;, pch=21, bg=&#39;orange&#39;, main=&#39;Plot 1&#39;) # Plot #2 boxplot(mtcars$wt, xlab=&#39;Weight (1000 lbs)&#39;, col=&#39;steelblue&#39;,main=&#39;Plot 2&#39;) # Plot #3 barplot(table(mtcars$vs), col=c(&#39;tomato&#39;,&quot;#23395b&quot;), xlab=&#39;Engine&#39;, names.arg = c(&#39;V-shaped&#39;, &#39;Straight&#39;), main=&#39;Plot 3&#39;) # Plot #4 dotchart(mtcars$mpg, pch=21, bg=&quot;#43418A&quot;, xlim=c(10, 42), xlab=&#39;Miles/(US) gallon&#39;, main=&#39;Plot 4&#39;) text(mtcars$mpg[c(1:2, 31:32)], c(1:2, 31:32), labels=row.names(mtcars)[c(1:2, 31:32)], adj = -.2, cex = .75, font=4) # Plot #5 pie(table(mtcars$am), labels=c(&#39;Automatic&#39;, &#39;Manual&#39;), main=&#39;Plot 5&#39;) # Plot #6 boxplot(mtcars$hp ~mtcars$am, names=c(&quot;Automatic&quot;, &quot;Manual&quot;), xlab=&#39;Transmission&#39;, ylab=&#39;Horsepower&#39;, col=c(&quot;#ceb888&quot;,&quot;#03A696&quot;), main=&#39;Plot 6&#39;) mar, oma The example below uses the built-in data iris. # Original plot plot(iris$Sepal.Length, iris$Sepal.Width, xlab=&#39;Sepal length&#39;, ylab=&#39;Sepal width&#39;, pch=21, bg=iris$Species) # Adding a legend: legend(&quot;topright&quot;, legend=unique(iris$Species), col=1:3, pc=20, cex = .9, # text size text.font=3, # italic text pt.cex = 1.5, # changing just the point size bty=&#39;n&#39;) # removing box Remove all margins. par(mar=c(0,0,0,0)) # Original plot plot(iris$Sepal.Length, iris$Sepal.Width, xlab=&#39;Sepal length&#39;, ylab=&#39;Sepal width&#39;, pch=21, bg=iris$Species) # Adding a legend: legend(&quot;topright&quot;, legend=unique(iris$Species), col=1:3, pc=20, cex = .9, # text size text.font=3, # italic text pt.cex = 1.5, # changing just the point size bty=&#39;n&#39;) # removing box Add larger margins on the bottom and left side. par(mar=c(4,6,2,2)) # Original plot plot(iris$Sepal.Length, iris$Sepal.Width, xlab=&#39;Sepal length&#39;, ylab=&#39;Sepal width&#39;, pch=21, bg=iris$Species) # Adding a legend: legend(&quot;topright&quot;, legend=unique(iris$Species), col=1:3, pc=20, cex = .9, # text size text.font=3, # italic text pt.cex = 1.5, # changing just the point size bty=&#39;n&#39;) # removing box How do these margins look set on two plots side by side? par(mar=c(4,6,2,2), mfrow=c(1,2)) # First plot plot(iris$Sepal.Length, iris$Sepal.Width, xlab=&#39;Sepal length&#39;, ylab=&#39;Sepal width&#39;, pch=21, bg=iris$Species) # Adding a legend: legend(&quot;topright&quot;, legend=unique(iris$Species), col=1:3, pc=20, cex = .9, # text size text.font=3, # italic text pt.cex = 1.5, # changing just the point size bty=&#39;n&#39;) # removing box # Second plot plot(iris$Petal.Length, iris$Petal.Width, xlab=&#39;Petal length&#39;, ylab=&#39;Peta width&#39;, pch=21, bg=iris$Species) # Adding a legend: legend(&quot;bottomright&quot;, legend=unique(iris$Species), col=1:3, pc=20, cex = .9, # text size text.font=3, # italic text pt.cex = 1.5, # changing just the point size bty=&#39;n&#39;) # removing box Doesn't look very good. Let's try setting smaller margins. Note that the default values for mar are mar=c(5.1, 4.1, 4.1, 2.1). par(mar=c(4, 4, 2, 1), mfrow=c(1,2)) # First plot plot(iris$Sepal.Length, iris$Sepal.Width, xlab=&#39;Sepal length&#39;, ylab=&#39;Sepal width&#39;, pch=21, bg=iris$Species) # Adding a legend: legend(&quot;topright&quot;, legend=unique(iris$Species), col=1:3, pc=20, cex = .9, # text size text.font=3, # italic text pt.cex = 1.5, # changing just the point size bty=&#39;n&#39;) # removing box # Second plot plot(iris$Petal.Length, iris$Petal.Width, xlab=&#39;Petal length&#39;, ylab=&#39;Peta width&#39;, pch=21, bg=iris$Species) # Adding a legend: legend(&quot;bottomright&quot;, legend=unique(iris$Species), col=1:3, pc=20, cex = .9, # text size text.font=3, # italic text pt.cex = 1.5, # changing just the point size bty=&#39;n&#39;) # removing box Perhaps we don't need two legends. How about we increase the margins (outer and usual) for top and bottom to include legend at the bottom, and a join title at the top? par(mar=c(6, 4, 1, 1), mfrow=c(1,2), oma=c(2,0,3,0)) # First plot plot(iris$Sepal.Length, iris$Sepal.Width, xlab=&#39;Sepal length&#39;, ylab=&#39;Sepal width&#39;, pch=21, bg=iris$Species) # Adding a legend legend(&quot;bottom&quot;,legend=unique(iris$Species), col=1:3, pc=20, cex = .8, # text size text.font=3, # italic text pt.cex = 1.5, # changing just the point size bty=&#39;n&#39;,# removing box xpd = TRUE, horiz = TRUE, # make legend horizontal inset=c(2,-0.50)) # changes to x and y positions # Second plot plot(iris$Petal.Length, iris$Petal.Width, xlab=&#39;Petal length&#39;, ylab=&#39;Peta width&#39;, pch=21, bg=iris$Species) # Joint title mtext(&quot;Results for 3 species of iris flowers&quot;, outer=TRUE, font=2) plot_usmap usmap is a package dedicated to get maps of the US by varying region types. Includes the plot_usmap function which allows you do easily plot state or region level data on top of a map. First, load up the package: library(usmap) You can generate the default map pretty easily. plot_usmap(&quot;states&quot;, labels=T) The first argument, regions can be &quot;states&quot;, &quot;state&quot;, &quot;counties&quot;, or &quot;county&quot;. You can switch the borders by changing this argument. plot_usmap(&quot;counties&quot;, labels=T) As you can see, adding the labels in this case, obfuscates our map. plot_usmap(&quot;counties&quot;, labels=F) If we wanted to zoom in on a state, this is easy to do. plot_usmap(&quot;counties&quot;, include=c(&quot;IN&quot;)) Of course, you can still just zoom in on a group of states, you don't have to show the county lines. plot_usmap(&quot;states&quot;, labels=T, include=c(&quot;IL&quot;, &quot;MI&quot;, &quot;IN&quot;, &quot;OH&quot;)) Pretty incredible. You can change the label colors using the label_color argument. plot_usmap(&quot;states&quot;, labels=T, include=c(&quot;IL&quot;, &quot;MI&quot;, &quot;IN&quot;, &quot;OH&quot;), label_color=&quot;gold&quot;) You can even have different colors for each of the states. plot_usmap(&quot;states&quot;, labels=T, include=c(&quot;IL&quot;, &quot;MI&quot;, &quot;IN&quot;, &quot;OH&quot;), label_color=c(&quot;blue&quot;, &quot;green&quot;, &quot;gold&quot;, &quot;tomato&quot;)) Similarly, you can control the fill color using the fill argument. plot_usmap(&quot;states&quot;, labels=T, include=c(&quot;IL&quot;, &quot;MI&quot;, &quot;IN&quot;, &quot;OH&quot;), label_color=c(&quot;blue&quot;, &quot;green&quot;, &quot;gold&quot;, &quot;tomato&quot;), fill=&quot;grey&quot;) You can control the border color using the color argument. plot_usmap(&quot;states&quot;, labels=T, include=c(&quot;IL&quot;, &quot;MI&quot;, &quot;IN&quot;, &quot;OH&quot;), label_color=c(&quot;blue&quot;, &quot;green&quot;, &quot;gold&quot;, &quot;tomato&quot;), fill=&quot;grey&quot;, color=&quot;white&quot;) We can control the border width with the size argument as well. plot_usmap(&quot;states&quot;, labels=T, include=c(&quot;IL&quot;, &quot;MI&quot;, &quot;IN&quot;, &quot;OH&quot;), label_color=c(&quot;blue&quot;, &quot;green&quot;, &quot;gold&quot;, &quot;tomato&quot;), fill=&quot;grey&quot;, color=&quot;white&quot;, size=2) Of course, it is important to be able to utilize a dataset with plot_usmap. To do so you must use the data and values arguments. The data argument expects a data.frame with at least two columns. One column to indicate which state or county, and another to indicate the associated values (whatever they may be). The column indicating the state or value must be named either fips or state. The other column can be anything as long as you use the values argument to specify the name. myDF &lt;- data.frame(state=state.abb, val=datasets::state.area) head(myDF) ## state val ## 1 AL 51609 ## 2 AK 589757 ## 3 AZ 113909 ## 4 AR 53104 ## 5 CA 158693 ## 6 CO 104247 plot_usmap(data=myDF, values=&quot;val&quot;, labels=T, include=c(&quot;IL&quot;, &quot;MI&quot;, &quot;IN&quot;, &quot;OH&quot;)) To move the legend out of the way, you can use theme from ggplot2. library(ggplot2) plot_usmap(data=myDF, values=&quot;val&quot;, labels=T, include=c(&quot;IL&quot;, &quot;MI&quot;, &quot;IN&quot;, &quot;OH&quot;)) + theme(legend.position = &quot;right&quot;) If we wanted to change the colors and way the shading works, we can use scale_fill_continous from ggplot2. library(ggplot2) plot_usmap(data=myDF, values=&quot;val&quot;, labels=T, include=c(&quot;IL&quot;, &quot;MI&quot;, &quot;IN&quot;, &quot;OH&quot;)) + theme(legend.position = &quot;right&quot;) + scale_fill_continuous(low=&quot;white&quot;, high=&quot;navy&quot;) It would probably look better if we had more than 4 points. Let's try with the entire US. library(ggplot2) plot_usmap(data=myDF, values=&quot;val&quot;, labels=T) + theme(legend.position = &quot;right&quot;) + scale_fill_continuous(low=&quot;white&quot;, high=&quot;navy&quot;) It really puts AK's area into perspective! How about if we remove AK using the exclude argument? library(ggplot2) plot_usmap(data=myDF, values=&quot;val&quot;, labels=T, exclude=c(&quot;AK&quot;)) + theme(legend.position = &quot;right&quot;) + scale_fill_continuous(low=&quot;white&quot;, high=&quot;navy&quot;) Note that if the regions argument is &quot;state&quot; or &quot;states&quot;, either the state name, abbreviation, or fips code would work to identify the state. The full 5-digit fips code is required to identify counties, however. To get a fips code for a certain county, you can do the following. usmap::fips(state = &quot;IN&quot;, county=&quot;Tippecanoe&quot;) ## [1] &quot;18157&quot; Note that the first 2 digits of the 5 digit fips code is the state fips code. usmap::fips(state = &quot;IN&quot;) ## [1] &quot;18&quot; What if we wanted to show area by the percentage of area that the state represents? First we would need to calculate it. myDF$percent_area &lt;- myDF$val/sum(myDF$val) library(ggplot2) plot_usmap(data=myDF, values=&quot;percent_area&quot;, labels=T) + theme(legend.position = &quot;right&quot;) + scale_fill_continuous(low=&quot;white&quot;, high=&quot;navy&quot;) After that, we can use the scales packages to fix the legend up. library(ggplot2) plot_usmap(data=myDF, values=&quot;percent_area&quot;, labels=T) + theme(legend.position = &quot;right&quot;) + scale_fill_continuous(low=&quot;white&quot;, high=&quot;navy&quot;, name=&quot;Percent of US area&quot;, label=scales::percent) If you were working with data that would be better represented by dollars instead of percentages, you could simply change the label argument to scales::dollars. Resources Simple examples A page with some code examples and output using usmap. More examples using usmap A page with some code examples and output using usmap. A little bit more in depth. ggplot ggmap ggmap is an excellent package that provides a suite of functions that, among other things, allows you to map spatial data on top of static maps. Important note: You must set up billing in order to use Google's APIs. Getting started To install ggmap, simply run install.packages(&quot;ggmap&quot;). To load the library, run library(ggmap). When first using this package, you may notice you need an API key to get access to certain functionality. Follow the directions here to get an API key. It should looks somethings like: mQkzTpiaLYjPqXQBotesgif3EfGL2dbrNVOrogg. Once you've acquired the API key, you have two options: Register ggmap with Google for the current session: library(ggmap) register_google(key=&quot;mQkzTpiaLYjPqXQBotesgif3EfGL2dbrNVOrogg&quot;) Register ggmap with Google, persistently through sessions: library(ggmap) register_google(key=&quot;mQkzTpiaLYjPqXQBotesgif3EfGL2dbrNVOrogg&quot;, write=TRUE) Note that if you choose option (2), your API key will be saved within your ~/.Renviron. Examples How do I get a map of West Lafayette? Click here for solution map &lt;- get_map(location=&quot;West Lafayette&quot;) ggmap(map) How do I zoom in and out on a map of West Lafayette? Click here for solution # zoom way out map &lt;- get_map(location=&quot;West Lafayette&quot;, zoom=1) ggmap(map) # zoom in map &lt;- get_map(location=&quot;West Lafayette&quot;, zoom=12) ggmap(map) How do I add Latitude and Longitude points to a map of Purdue University? Click here for solution points_to_add &lt;- data.frame(latitude=c(40.433663, 40.432104, 40.428486), longitude=c(-86.916584, -86.919610, -86.920866)) map &lt;- get_map(location=&quot;Purdue University&quot;, zoom=14) ggmap(map) + geom_point(data = points_to_add, aes(x = longitude, y = latitude)) leaflet leaflet is a popular JavaScript library to create interactive maps. The leaflet R package makes it easy to create incredible interactive maps. Examples How do I plot some longitude and latitude points on an interactive map? Click here for solution library(leaflet) points_to_plot &lt;- data.frame(latitude=c(40.433663, 40.432104, 40.428486), longitude=c(-86.916584, -86.919610, -86.920866)) map &lt;- leaflet() map &lt;- addTiles(map) map &lt;- addCircles(map, lng=points_to_plot$longitude, lat=points_to_plot$latitude) map # or another way with magrittr library(magrittr) leaflet(points_to_plot) %&gt;% addTiles() %&gt;% addCircles(lng=~longitude, lat=~latitude) magrittr is a package that adds the %&gt;% and `%&lt;% operators which allow you to pipe the output of R code to more R code, much like piping in bash. You can read more about it here. RMarkdown To install RMarkdown simply run the following: install.packages(&quot;rmarkdown&quot;) Projects in The Data Mine are all written in RMarkdown. You can download the RMarkdown file by clicking on the link at the top of each project page. Each file should end in the &quot;.Rmd&quot; which is the file extension commonly associated with RMarkdown files. You can find an exemplary RMarkdown file here: https://raw.githubusercontent.com/TheDataMine/the-examples-book/master/files/rmarkdown.Rmd If you open this file in RStudio, and click on the &quot;Knit&quot; button in the upper left hand corner of IDE, you will get the resulting HTML file. Open this file in the web browser of your choice and compare and contrast the syntax in the rmarkdown.Rmd file and resulting output. Play around with the file, make modifications, and re-knit to gain a better understanding of the syntax. Note that similar input/output examples are shown in the RMarkdown Cheatsheet. Click here for video Code chunks Code chunks are sections within an RMarkdown file where you can write, display, and optionally evaluate code from a variety of languages: ## [1] &quot;awk&quot; &quot;bash&quot; &quot;coffee&quot; &quot;gawk&quot; &quot;groovy&quot; ## [6] &quot;haskell&quot; &quot;lein&quot; &quot;mysql&quot; &quot;node&quot; &quot;octave&quot; ## [11] &quot;perl&quot; &quot;psql&quot; &quot;Rscript&quot; &quot;ruby&quot; &quot;sas&quot; ## [16] &quot;scala&quot; &quot;sed&quot; &quot;sh&quot; &quot;stata&quot; &quot;zsh&quot; ## [21] &quot;highlight&quot; &quot;Rcpp&quot; &quot;tikz&quot; &quot;dot&quot; &quot;c&quot; ## [26] &quot;cc&quot; &quot;fortran&quot; &quot;fortran95&quot; &quot;asy&quot; &quot;cat&quot; ## [31] &quot;asis&quot; &quot;stan&quot; &quot;block&quot; &quot;block2&quot; &quot;js&quot; ## [36] &quot;css&quot; &quot;sql&quot; &quot;go&quot; &quot;python&quot; &quot;julia&quot; ## [41] &quot;sass&quot; &quot;scss&quot; &quot;theorem&quot; &quot;lemma&quot; &quot;corollary&quot; ## [46] &quot;proposition&quot; &quot;conjecture&quot; &quot;definition&quot; &quot;example&quot; &quot;exercise&quot; ## [51] &quot;proof&quot; &quot;remark&quot; &quot;solution&quot; The syntax is simple: ```{language, options...} code here... ``` For example: ```{r, echo=TRUE} my_variable &lt;- c(1,2,3) my_variable ``` Which will render like: my_variable &lt;- c(1,2,3) my_variable ## [1] 1 2 3 You can find a list of chunk options here. How do I run a code chunk but not display the code above the results? Click here for solution ```{r, echo=FALSE} my_variable &lt;- c(1,2,3) my_variable ``` How do I include a code chunk without evaluating the code itself? Click here for solution ```{r, eval=FALSE} my_variable &lt;- c(1,2,3) my_variable ``` How do I prevent warning messages from being displayed? Click here for solution ```{r, warning=FALSE} my_variable &lt;- c(1,2,3) my_variable ``` How do I prevent error messages from being displayed? Click here for solution ```{r, error=FALSE} my_variable &lt;- c(1,2,3) my_variable ``` How do I run a code chunk, but not include the chunk in the final output? Click here for solution ```{r, include=FALSE} my_variable &lt;- c(1,2,3) my_variable ``` How do I render a figure from a chunk? Click here for solution ```{r} my_variable &lt;- c(1,2,3) plot(my_variable) ``` How do I create a set of slides using RMarkdown? Click here for solution Please see the example Rmarkdown file here. You can change the slide format by changing the yaml header to any of: ioslides_presentation, slidy_presentation, or beamer_presentation. By default all first and second level headers (# and ##, respectively) will create a new slide. To manually create a new slide, you can use ***. Resources RMarkdown Cheatsheet An excellent quick reference for RMarkdown syntax. RMarkdown Reference A thorough reference manual showing markdown input and expected output. Gives descriptions of the various chunk options, as well as output options. RStudio RMarkdown Lessons A set of lessons detailing the ins and outs of RMarkdown. Markdown Tutorial RMarkdown uses Markdown syntax for its text. This is a good, interactive tutorial to learn the basics of Markdown. This tutorial is available in multiple languages. RMarkdown Gallery This gallery highlights a variety of reproducible and interactive RMarkdown documents. An excellent resource to see the power of RMarkdown. RMarkdown Chapter This is a chapter from Hadley Wickham's excellent R for Data Science book that details important parts of RMarkdown. RMarkdown in RStudio This is a nice article that introduces RMarkdown, and guides the user through creating their own interactive document using RMarkdown in RStudio. Reproducible Research This is another good resource that introduces RMarkdown. Plenty of helpful pictures and screenshots. Tidyverse piping glimpse filter arrange mutate group_by str_extract and str_extract_all str_extract and str_extract_all are useful functions from the stringr package. You can install the package by running: install.packages(&quot;stringr&quot;) str_extract extracts the text which matches the provided regular expression or pattern. Note that this differs from grep in a major way. grep simply returns the index in which a pattern match was found. str_extract returns the actual matching text. Note that grep typically returns the entire line where a match was found. str_extract returns only the part of the line or text that matches the pattern. For example: text &lt;- c(&quot;cat&quot;, &quot;mat&quot;, &quot;spat&quot;, &quot;spatula&quot;, &quot;gnat&quot;) # All 5 &quot;lines&quot; of text were a match. grep(&quot;.*at&quot;, text) ## [1] 1 2 3 4 5 text &lt;- c(&quot;cat&quot;, &quot;mat&quot;, &quot;spat&quot;, &quot;spatula&quot;, &quot;gnat&quot;) stringr::str_extract(text, &quot;.*at&quot;) ## [1] &quot;cat&quot; &quot;mat&quot; &quot;spat&quot; &quot;spat&quot; &quot;gnat&quot; As you can see, although all 5 words match our pattern and would be returned by grep, str_extract only returns the actual text that matches the pattern. In this case &quot;spatula&quot; is not a &quot;full&quot; match -- the pattern &quot;.*at&quot; only captures the &quot;spat&quot; part of &quot;spatula&quot;. In order to capture the rest of the word you would need to add something like &quot;.*&quot; to the end of the pattern: text &lt;- c(&quot;cat&quot;, &quot;mat&quot;, &quot;spat&quot;, &quot;spatula&quot;, &quot;gnat&quot;) stringr::str_extract(text, &quot;.*at.*&quot;) ## [1] &quot;cat&quot; &quot;mat&quot; &quot;spat&quot; &quot;spatula&quot; &quot;gnat&quot; One final note is that you must double-escape certain characters in patterns because R treats backslashes as escape values for character constants (stackoverflow). For example, to write \\( we must first escape the \\, so we write \\\\(. This is true for many character which would normally only be preceded by a single \\. Examples How can I extract the text between parenthesis in a vector of texts? Click here for solution text &lt;- c(&quot;this is easy for (you)&quot;, &quot;there (are) challenging ones&quot;, &quot;text is (really awesome) (ok?)&quot;) # Search for a literal &quot;(&quot;, followed by any amount of any text other than more parenthesis ([^()]*), followed by a literal &quot;)&quot;. stringr::str_extract(text, &quot;\\\\([^()]*\\\\)&quot;) ## [1] &quot;(you)&quot; &quot;(are)&quot; &quot;(really awesome)&quot; To get all matches, not just the first match: text &lt;- c(&quot;this is easy for (you)&quot;, &quot;there (are) challenging ones&quot;, &quot;text is (really awesome) more text (ok?)&quot;) # Search for a literal &quot;(&quot;, followed by any amount of any text (.*), followed by a literal &quot;)&quot;. stringr::str_extract_all(text, &quot;\\\\([^()]*\\\\)&quot;) ## [[1]] ## [1] &quot;(you)&quot; ## ## [[2]] ## [1] &quot;(are)&quot; ## ## [[3]] ## [1] &quot;(really awesome)&quot; &quot;(ok?)&quot; lubridate lubridate is a fantastic package that makes the typical tasks one would perform on dates, that much easier. How do I convert a string &quot;07/05/1990&quot; to a Date? Click here for solution library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:data.table&#39;: ## ## hour, isoweek, mday, minute, month, quarter, second, wday, week, ## yday, year ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union dat &lt;- &quot;07/05/1990&quot; dat &lt;- mdy(dat) class(dat) ## [1] &quot;Date&quot; How do I convert a string &quot;31-12-1990&quot; to a Date? Click here for solution my_string &lt;- &quot;31-12-1990&quot; dat &lt;- dmy(my_string) dat ## [1] &quot;1990-12-31&quot; class(dat) ## [1] &quot;Date&quot; How do I convert a string &quot;31121990&quot; to a Date? Click here for solution my_string &lt;- &quot;31121990&quot; my_date &lt;- dmy(my_string) my_date ## [1] &quot;1990-12-31&quot; class(my_date) ## [1] &quot;Date&quot; How do I extract the day, week, month, quarter, and year from a Date? Click here for solution my_date &lt;- dmy(&quot;31121990&quot;) day(my_date) ## [1] 31 week(my_date) ## [1] 53 month(my_date) ## [1] 12 quarter(my_date) ## [1] 4 year(my_date) ## [1] 1990 strrep strrep is a function that allows you to repeat the characters a given number of times. Examples How to repeat the string of characters ABC three times? Click here for solution strrep(&quot;ABC&quot;, 3) ## [1] &quot;ABCABCABC&quot; How to get a vector in which A is repeated twice B three times and C four times? Click here for solution strrep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), c(2,3,4)) ## [1] &quot;AA&quot; &quot;BBB&quot; &quot;CCCC&quot; nchar nchar is a function which counts the number of characters and symbols in a word or a string. Punctuation and blank spaces are counted as well. Examples How to to find the number of characters and or symbols the word &quot;Protozoa&quot;? Click here for solution nchar(&quot;Protozoa&quot;) ## [1] 8 How to to find the number of characters and or symbols forthe following strings all at once &quot;pneumonoultramicroscopicsilicovolcanoconiosis&quot;, &quot;password: DatamineRocks#stat1900@&quot;? Fun fact: &quot;pneumonoultramicroscopicsilicovolcanoconiosis&quot; is the longest word in the English dictionary. Click here for solution string_vector &lt;- c(&quot;pneumonoultramicroscopicsilicovolcanoconiosis&quot;, &quot;password: DatamineRocks#stat1900@&quot;) nchar(string_vector) ## [1] 45 33 Resources Lubridate Cheatsheet A comprehensive cheatsheet on lubridate. Excellent resource to immediately begin using lubridate. data.table SQL in R Scraping shiny Rendering images "],
["python.html", "Python Getting started Variables Printing Logical operators Lists &amp; Tuples Dicts Sets Control flow Writing functions Reading &amp; Writing data pathlib numpy scipy pandas Jupyter notebooks Writing scripts Scraping XML Plotting Classes tensorflow pytorch", " Python Getting started Python on Scholar Each year we provide students with a working Python kernel that students are able to select and use from within https://notebook.scholar.rcac.purdue.edu/ as well as within an Rmarkdown document in https://rstudio.scholar.rcac.purdue.edu/. We ask that students use this kernel when completing all Python-related questions for the course. This ensures version consistency for Python and all packages that students will use during the academic year. In addition, this enables staff to quickly modify the Python environment for all students should the need arise. Let's configure this so every time you access https://notebook.scholar.rcac.purdue.edu/ or https://rstudio.scholar.rcac.purdue.edu/, you will have access to the proper kernel, and the default version of python is correct. Navigate to https://rstudio.scholar.rcac.purdue.edu/, and login using your Purdue credentials. In the menu, click Tools &gt; Shell.... You should be presented with a shell towards the bottom left. Click within the shell, and type the following followed by pressing Enter or Return: /class/datamine/apps/runme After executing the script, in the menu, click Session &gt; Restart R. In order to run Python within https://rstudio.scholar.rcac.purdue.edu/, log in to https://rstudio.scholar.rcac.purdue.edu/ and run the following in the Console or in an R code chunk: datamine_py() install.packages(&quot;reticulate&quot;) The function datamine_py &quot;activates&quot; the Python environment we have setup for the course. Any time you want to use our environment, simply run the R function at the beginning of any R Session, prior to running anything Python code chunks. To test if the Python environment is working within https://rstudio.scholar.rcac.purdue.edu/, run the following in a Python code chunk: import sys print(sys.executable) The python executable should be located in the appropriate folder in the following path: /class/datamine/apps/python/. The runme script also adds a kernel to the list of kernels shown in https://notebook.scholar.rcac.purdue.edu/. To test if the kernel is available and working, navigate to https://notebook.scholar.rcac.purdue.edu/, login, click on New, and select the kernel matching the current year. For example, you would select f2020-s2021 for the 2020-2021 academic year. Once the notebook has launched, you can confirm the version of Python by running the following in a code cell: import sys print(sys.executable) The python executable should be located in the appropriate folder in the following path: /class/datamine/apps/python/. If you already have a a Jupyter notebook running at https://notebook.scholar.rcac.purdue.edu/, you may need to refresh in order for the kernel to appear as an option in Kernel &gt; Change Kernel. If you would like to use the Python environment that is put together for this class, from within a terminal on Scholar, run the following: source /class/datamine/apps/python.sh This will load the environment and python will launch our environment's interpreter. Variables Variables are declared just like in R, but rather than using &lt;- and -&gt;, Python uses a single = as is customary for most languages. You can declared variables like this: my_var = 4 Here, we declared a variable with a value of 4. Important note: Actually this is technically not true. Numbers between -5 and 256 (inclusive) are already pre-declared and exist within Python's memory before you assigned the value to my_var. The = operator simply forces my_var to point to that value that already exists! That is right, my_var is technically a pointer. One extremely important distinction between declaring variables in Python vs. in R is what is actually happening under the hood. Take the following code: my_var = 4 new_var = my_var my_var = my_var + 1 print(f&quot;my_var: {my_var}\\nnew_var: {new_var}&quot;) ## my_var: 5 ## new_var: 4 my_var = [4,] new_var = my_var my_var[0] = my_var[0] + 1 print(f&quot;my_var: {my_var}\\nnew_var: {new_var}&quot;) ## my_var: [5] ## new_var: [5] Here, the first chunk of code behaves as expected because ints are immutable, meaning the values cannot be changed. As a result, when we assign my_var = my_var + 1, my_var's value isn't changing, my_var is just being pointed to a different value of 5, which is not where new_var points. new_var still points to the value of 4. The second chunk however is dealing with a mutable list. We first assign the first value of our list to a value of 4. Then we assign my_var to new_var. This does not copy the values of my_var to new_var, but rather new_var now points to the same exact object. Then, when we increment the first value in my_var, that same change is reflected when we print the value in new_var, because new_var and my_var are the same object, i.e. new_var is my_var. An excellent article that goes into more detail can be found here. None None is a keyword used to define a null value. This would be the Python equivalent to R's NULL. If used in an if statement, None represents False. This does not mean None == False, in fact: print(None == False) ## False As you can see, although None can represent False in an if statement, they are not equivalent. bool A bool has two possible values: True and False. It is important to understand that technically: print(True == 1) ## True print(False == 0) ## True With that being said, True is not equal to numbers greater than 1: print(True == 2) ## False print(True == 3) ## False With that being said, numbers not equal to 0 evaluate to True when used in an if statement: if 3: print(&quot;3 evaluates to True&quot;) ## 3 evaluates to True if 4: print(&quot;4 evaluates to True&quot;) ## 4 evaluates to True if -1: print(&quot;-1 evaluates to True&quot;) ## -1 evaluates to True str str are strings in Python. Strings are &quot;immutable sequences of Unicode code points&quot;. Strings can be surrounded in single quotes, double quotes, or triple quoted (with either single or double quotes): print(f&quot;Single quoted text is type: {type(&#39;test&#39;)}&quot;) ## Single quoted text is type: &lt;class &#39;str&#39;&gt; print(f&#39;Double quoted text is type: {type(&quot;test&quot;)}&#39;) ## Double quoted text is type: &lt;class &#39;str&#39;&gt; print(f&quot;Triple quoted with single quotes: {type(&#39;&#39;&#39;This is some text&#39;&#39;&#39;)}&quot;) ## Triple quoted with single quotes: &lt;class &#39;str&#39;&gt; print(f&#39;Triple quoted with double quotes: {type(&quot;&quot;&quot;This is some text&quot;&quot;&quot;)}&#39;) ## Triple quoted with double quotes: &lt;class &#39;str&#39;&gt; Triple quoted strings can span multiple lines. All associated whitespace will be incorporated in the string: my_string = &quot;&quot;&quot;This text spans multiple lines.&quot;&quot;&quot; print(my_string) ## This text ## spans multiple ## lines. But, this would cause an error: my_string = &quot;This text, will throw an error&quot; print(my_string) But, you could make it span multiple lines by adding a \\, but newlines won't be maintained: my_string = &quot;This text, \\ will throw an error&quot; print(my_string) ## This text, will throw an error int int's are whole numbers. For instance: my_var = 5 print(type(my_var)) ## &lt;class &#39;int&#39;&gt; int's can be added, subtracted, and multiplied without changing types. With that being said, division of 2 int's results in a float regardless of whether or not the result of the division is a whole number or not: print(type(6+2)) ## &lt;class &#39;int&#39;&gt; print(type(6-2)) ## &lt;class &#39;int&#39;&gt; print(type(6*2)) ## &lt;class &#39;int&#39;&gt; print(type(6/2)) ## &lt;class &#39;float&#39;&gt; Similarly, any calculation between an int and float results in a float: print(type(6+2.0)) ## &lt;class &#39;float&#39;&gt; print(type(6-2.0)) ## &lt;class &#39;float&#39;&gt; print(type(6*2.0)) ## &lt;class &#39;float&#39;&gt; print(type(6/2.0)) ## &lt;class &#39;float&#39;&gt; float float's are floating point numbers, or numbers with decimals. my_var = 5.0 print(type(my_var)) ## &lt;class &#39;float&#39;&gt; float's can be converted back to int's using the int function. This coercion causes the float to be truncated, regardless of how close to the &quot;next&quot; number the float is: print(int(5.5)) ## 5 print(int(5.49)) ## 5 print(int(5.51)) ## 5 print(int(5.99999)) ## 5 complex complex's represent complex numbers. j can be used to represent an imaginary number. j must be preceded by a number, like 1j. my_var = 1j print(my_var) ## 1j print(type(my_var)) ## &lt;class &#39;complex&#39;&gt; Arithmetic with a complex always results in a complex: print(type(1j*2)) ## &lt;class &#39;complex&#39;&gt; print(type(1j*2.0)) ## &lt;class &#39;complex&#39;&gt; print(type(1j*1j)) ## &lt;class &#39;complex&#39;&gt; You cannot convert to an int or float: print(int(1j*1j)) print(float(1j*1j)) Resources Pointers in Python An excellent article explaining what happens under the hood when declaring variables in Python. Printing print is a function in Python that allows you to... well... print. Printing values and information about a program while the program is running is still to this day one of the best methods to debug your code. This is just one good reason to learn about and feel comfortable with printing. You can print simple string literals: print(&quot;This is a simple string literal being printed...&quot;) ## This is a simple string literal being printed... You can print all types of variables, not just strings: print(int(4)) ## 4 print(float(4.4)) ## 4.4 print(False) ## False You can even mix and match what you print: print(&quot;This is a string and an int:&quot;, int(4)) # notice there is a space added between the arguments to print ## This is a string and an int: 4 print(&quot;This is a string and an int and a float:&quot;, int(4), float(4.4)) ## This is a string and an int and a float: 4 4.4 print(int(4), &quot;&lt;- is an integer&quot;) ## 4 &lt;- is an integer You can even do arithmetic inside the print function: print(&quot;4 + 4 =&quot;, 4+4) ## 4 + 4 = 8 There are a series of special characters called escape characters that need to be escaped with a \\, but that represent a different symbol when processed. For example, a newline character is \\n, but when you print \\n it results in a new line: print(&quot;This is line 1.\\nThis is line 2.&quot;) ## This is line 1. ## This is line 2. Here are a couple more escape characters: print(&quot;This is a carriage return\\rAs you can see it is not a visible character.&quot;) ## This is a carriage return As you can see it is not a visible character. print(&quot;This is a .\\tAnd another.\\tAnd now two tabs.\\t\\tNice.&quot;) ## This is a . And another. And now two tabs. Nice. You may now be wondering, well what if I want to literally print \\t or \\n? There are a couple of options: print(&quot;You can escape a forward slash with another forward slash: \\\\&quot;) ## You can escape a forward slash with another forward slash: \\ print(&quot;This would then look like: \\\\t \\\\n&quot;) ## This would then look like: \\t \\n print(r&quot;You could also add an &#39;r&#39; before your string. The &#39;r&#39; represents raw and will render the text literally: \\t \\n&quot;) ## You could also add an &#39;r&#39; before your string. The &#39;r&#39; represents raw and will render the text literally: \\t \\n Similarly, if you want to use double or single quotes within double or single quotes you can escape them as well: print(&quot;This sentence has \\&quot;double quotes\\&quot;.&quot;) ## This sentence has &quot;double quotes&quot;. print(&#39;This sentence has \\&#39;single quotes\\&#39;.&#39;) ## This sentence has &#39;single quotes&#39;. Of course, you can mix and match quotes to avoid needing to escape: print(&#39;Now it is easy to print &quot;double quotes&quot;.&#39;) ## Now it is easy to print &quot;double quotes&quot;. print(&quot;Now it is easy to print &#39;single quotes&#39;.&quot;) ## Now it is easy to print &#39;single quotes&#39;. f-strings f-strings are extremely straightforward, useful, and fast. I would highly recommend using f-strings when the need arrives to print something more than simple text. f-string stands for &quot;format string&quot;. An f-string is a string literal that starts with an f or an F: print(f&#39;This is an f-string.&#39;) ## This is an f-string. print(F&#39;This is an f-string.&#39;) ## This is an f-string. Of course, you can use double or single quotes, like normal: print(f&quot;This still works.&quot;) ## This still works. print(F&quot;So does this.&quot;) ## So does this. What do f-strings do? They allow you to print expressions inline: print(f&quot;4+4={4+4}&quot;) ## 4+4=8 They allow you to call functions: def sum(a, b): return(a+b) print(f&quot;4+4={sum(4,4)}&quot;) ## 4+4=8 Overall, they are just a really nice feature that makes printing a pleasure. You can even write multi-line f-strings: first = &#39;First&#39; second = &#39;Second&#39; multiline_string = f&quot;First line {first}.&quot; \\ &quot;Second line {second}.&quot; print(multiline_string) ## First line First.Second line {second}. But make sure you put an f before each line. first = &#39;First&#39; second = &#39;Second&#39; multiline_string = f&quot;First line {first}.&quot; \\ f&quot;Second line {second}.&quot; print(multiline_string) ## First line First.Second line Second. Better yet, use triple quotes with the f-string to handle multiline f-strings: multiline_string = f&quot;&quot;&quot;First line {first}. Second line {second}.&quot;&quot;&quot; print(multiline_string) ## First line First. ## Second line Second. Of course, this is not all f-strings are capable of. The &quot;format&quot; comes from somewhere. We can format our dates and times: import datetime dt = datetime.datetime.now() print(f&#39;This is the datetime: {dt: %Y/%m/%d %H:%M}&#39;) ## This is the datetime: 2021/01/14 22:19 As you can see, the content following the : is used to specify the format. For numbers, you can specify the number of decimals: my_float = 444.44444445 print(f&#39;My float: {my_float:.3f}&#39;) ## My float: 444.444 print(f&#39;My float: {my_float:.5f}&#39;) ## My float: 444.44444 Or if you desire leading zeros: my_float = 444.44444445 print(f&#39;My float: {my_float:010.3f}&#39;) ## My float: 000444.444 print(f&#39;My float: {my_float:010.5f}&#39;) ## My float: 0444.44444 print(f&#39;My float: {my_float:10.5f}&#39;) ## My float: 444.44444 Note that the first 0 means &quot;zero pad&quot;, and the following 10 represents the total width of the result. In this case it means zero pad until the full number takes up 10 characters (including the decimal place). You could remove the intial 0 if you want to make numbers line up neatly: my_float = 444.44444445 print(f&#39;My float: {555.55}&#39;) ## My float: 555.55 print(f&#39;My float: {22}&#39;) ## My float: 22 print(f&#39;My float: {1234.5}&#39;) # vs ## My float: 1234.5 print(&quot;\\nvs.\\n&quot;) ## ## vs. print(f&#39;My float: {555.55:7.02f}&#39;) ## My float: 555.55 print(f&#39;My float: {22:7.02f}&#39;) ## My float: 22.00 print(f&#39;My float: {1234.5:7.02f}&#39;) ## My float: 1234.50 Resources RealPython f-strings A good walkthrough on f-strings. Logical operators Logical operators are symbols that can be used within Python to make comparisons. Operator Description &lt; less than &lt;= less than or equal to &gt; greater than &gt;= greater than or equal to == equal to != not equal to not x negation, not x x or y x OR y x and y x AND y x is y x and y both point to the same objects in memory x == y x and y have the same values It may be important to give a quick example of the difference between == and is: x = -5 y = -5 print(x==y) # True ## True print(x is y) # True ## True x = 256 y = 256 print(x==y) # True ## True print(x is y) # True ## True x = 257 y = 257 print(x==y) # True ## True print(x is y) # False ## False This may be a surprising result for some of you. What is going on here? Well, Python makes an optimization where numbers between -5 and 256 (inclusive) are already declared internally. When you assign one of those pre-declared values to a variable, the variable points to the already declared object, rather than re-declaring the object. This is why the is operator is True for the first two numbers, and False for 257 -- x and y literally point to the same object when is results in True and does not when is results in False. x = -5 y = -5 print(x==y) # True ## True print(x is y) # True ## True print(id(x)) ## 140164841474160 print(id(y)) ## 140164841474160 x = 256 y = 256 print(x==y) # True ## True print(x is y) # True ## True print(id(x)) ## 140164841671056 print(id(y)) ## 140164841671056 x = 257 y = 257 print(x==y) # True ## True print(x is y) # False ## False print(id(x)) ## 140164333132720 print(id(y)) ## 140164333129936 There are a variety of interesting behaviors highlighted in this excellent article. It would be well worthwhile to read it. Lists &amp; Tuples Lists and tuples are two of the primary data types in Python. Indexing List methods The following is a table of list methods from w3schools.com. Method Description append() Adds an element at the end of the list clear() Removes all the elements from the list copy() Returns a copy of the list count() Returns the number of elements with the specified value extend() Add the elements of a list (or any iterable), to the end of the current list index() Returns the index of the first element with the specified value insert() Adds an element at the specified position pop() Removes the element at the specified position remove() Removes the item with the specified value reverse() Reverses the order of the list sort() Sorts the list Tuple methods The following is a table of tuple methods from w3schools.com. Method Description count() Returns the number of times a specified value occurs in a tuple index() Searches the tuple for a specified value and returns the position of where it was found Dicts Dictionaries, commonly referred to as dicts, are used to store key:value pairs. Under the hood, dicts are hash tables (or hash maps). Even with extremely large sets of data, dicts are able to very quickly add, remove, and search for data on average. Dicts are able to accomplish this at the expense of space. There are two ways to declare a dict, you can either use an empty or populated set of curly braces {}, or the dict keyword. # Declaring dicts my_dict_01 = {} print(type(my_dict_01)) ## &lt;class &#39;dict&#39;&gt; my_dict_02 = dict() print(type(my_dict_02)) ## &lt;class &#39;dict&#39;&gt; my_dict_03 = {&quot;first_names&quot;: [&quot;John&quot;, &quot;Jill&quot;,], &quot;last_names&quot;: [&quot;Smith&quot;, &quot;Johnson&quot;, &quot;Chen&quot;]} print(type(my_dict_03)) ## &lt;class &#39;dict&#39;&gt; my_dict_04 = dict(first_names=[&quot;John&quot;, &quot;Jill&quot;,], last_names=[&quot;Smith&quot;, &quot;Johnson&quot;, &quot;Chen&quot;]) print(type(my_dict_04)) ## &lt;class &#39;dict&#39;&gt; Be careful! Dicts are not the only data type that utilizes the curly braces. The following is not a dict, but rather a set. not_a_dict = {&quot;John&quot;, &quot;Jill&quot;, &quot;Ellen&quot;,} print(type(not_a_dict)) ## &lt;class &#39;set&#39;&gt; There are two primary ways to &quot;get&quot; information from a dict. One is to use the get method, the other is to use square brackets and strings. my_dict = {&quot;fruits&quot;: [&quot;apple&quot;, &quot;orange&quot;, &quot;pear&quot;], &quot;person&quot;: &quot;John&quot;, &quot;vegetables&quot;: [&quot;carrots&quot;, &quot;peas&quot;]} # If &quot;person&quot; is indeed a key, they will function the same way my_dict[&quot;person&quot;] my_dict.get(&quot;person&quot;) # If the key does not exist, like below, they will not # function the same way. my_dict.get(&quot;height&quot;) # Returns None when key doesn&#39;t exist my_dict[&quot;height&quot;] # Throws a KeyError exception because the key, &quot;height&quot; doesn&#39;t exist The following is a table of dict methods from w3schools.com. Method Description clear() Removes all the elements from the dictionary copy() Returns a copy of the dictionary fromkeys() Returns a dictionary with the specified keys and value get() Returns the value of the specified key, or None if the key doesn't exist items() Returns a list containing a tuple for each key value pair keys() Returns a list containing the dictionary's keys pop() Removes and returns the element with the specified key popitem() Removes the last inserted key-value pair setdefault() Returns the value of the specified key. If the key does not exist: insert the key, with the specified value update() Updates the dictionary with the specified key-value pairs values() Returns a list of all the values in the dictionary Sets The following is a table of set methods from w3schools.com. Method Description add() Adds an element to the set clear() Removes all the elements from the set copy() Returns a copy of the set difference() Returns a set containing the difference between two or more sets difference_update() Removes the items in this set that are also included in another, specified set discard() Remove the specified item intersection() Returns a set, that is the intersection of two other sets intersection_update() Removes the items in this set that are not present in other, specified set(s) isdisjoint() Returns whether two sets have an intersection or not issubset() Returns whether another set contains this set or not issuperset() Returns whether this set contains another set or not pop() Removes an element from the set remove() Removes the specified element symmetric_difference() Returns a set with the symmetric differences of two sets symmetric_difference_update() Inserts the symmetric differences from this set and another union() Return a set containing the union of sets update() Update the set with the union of this set and others Control flow If/else statements For loops enumerate break break is a keyword in Python that stops execution and immediately jumps out of the loop, continuing execution of code immediately following the end of the loop. my_list = list(range(1, 11)) # this will only print &quot;1&quot; as # the loop is immediately escaped when # break is executed for i in my_list: print(i) break ## 1 In the following example, we exit the loop once we get to number &quot;5&quot;. my_list = list(range(1, 11)) for i in my_list: print(i) if i == 5: break ## 1 ## 2 ## 3 ## 4 ## 5 continue List comprehensions Writing functions Reading &amp; Writing data read_csv Please see here. csv csv is a Python module that is useful for reading and writing tabular data. Much like the read.csv function in R, the csv module is useful for data that is like csv but not necessarily comma-separated. To use the csv module, simply import it: import csv Examples How do you print each row of a csv flights_sample.csv? Click here for solution # my_csv_file is the variable holding the file with open(&#39;flights_sample.csv&#39;) as my_csv_file: my_reader = csv.reader(my_csv_file) # each &quot;row&quot; here is a list where each # value in the list is an element in the row for row in my_reader: print(row) # you can change the word &quot;row&quot; to anything you # would like, just make sure to change it everywhere! # first, we need to &quot;reset&quot; the file so it starts at the beginning my_csv_file.seek(0) for my_row in my_reader: print(my_row) ## [&#39;Year&#39;, &#39;Month&#39;, &#39;DayofMonth&#39;, &#39;DayOfWeek&#39;, &#39;DepTime&#39;, &#39;CRSDepTime&#39;, &#39;ArrTime&#39;, &#39;CRSArrTime&#39;, &#39;UniqueCarrier&#39;, &#39;FlightNum&#39;, &#39;TailNum&#39;, &#39;ActualElapsedTime&#39;, &#39;CRSElapsedTime&#39;, &#39;AirTime&#39;, &#39;ArrDelay&#39;, &#39;DepDelay&#39;, &#39;Origin&#39;, &#39;Dest&#39;, &#39;Distance&#39;, &#39;TaxiIn&#39;, &#39;TaxiOut&#39;, &#39;Cancelled&#39;, &#39;CancellationCode&#39;, &#39;Diverted&#39;, &#39;CarrierDelay&#39;, &#39;WeatherDelay&#39;, &#39;NASDelay&#39;, &#39;SecurityDelay&#39;, &#39;LateAircraftDelay&#39;] ## [&#39;1987&#39;, &#39;10&#39;, &#39;14&#39;, &#39;3&#39;, &#39;741&#39;, &#39;730&#39;, &#39;912&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;91&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;23&#39;, &#39;11&#39;, &#39;SAN&#39;, &#39;SFO&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1990&#39;, &#39;10&#39;, &#39;15&#39;, &#39;4&#39;, &#39;729&#39;, &#39;730&#39;, &#39;903&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;94&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;14&#39;, &#39;-1&#39;, &#39;SAN&#39;, &#39;SFO&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1990&#39;, &#39;10&#39;, &#39;17&#39;, &#39;6&#39;, &#39;741&#39;, &#39;730&#39;, &#39;918&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;97&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;29&#39;, &#39;11&#39;, &#39;SAN&#39;, &#39;SFO&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1990&#39;, &#39;10&#39;, &#39;18&#39;, &#39;7&#39;, &#39;729&#39;, &#39;730&#39;, &#39;847&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;78&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;-2&#39;, &#39;-1&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1991&#39;, &#39;10&#39;, &#39;19&#39;, &#39;1&#39;, &#39;749&#39;, &#39;730&#39;, &#39;922&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;93&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;33&#39;, &#39;19&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1991&#39;, &#39;10&#39;, &#39;21&#39;, &#39;3&#39;, &#39;728&#39;, &#39;730&#39;, &#39;848&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;80&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;-1&#39;, &#39;-2&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1991&#39;, &#39;10&#39;, &#39;22&#39;, &#39;4&#39;, &#39;728&#39;, &#39;730&#39;, &#39;852&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;84&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;3&#39;, &#39;-2&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1991&#39;, &#39;10&#39;, &#39;23&#39;, &#39;5&#39;, &#39;731&#39;, &#39;730&#39;, &#39;902&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;91&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;13&#39;, &#39;1&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1991&#39;, &#39;10&#39;, &#39;24&#39;, &#39;6&#39;, &#39;744&#39;, &#39;730&#39;, &#39;908&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;84&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;19&#39;, &#39;14&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## 0 ## [&#39;Year&#39;, &#39;Month&#39;, &#39;DayofMonth&#39;, &#39;DayOfWeek&#39;, &#39;DepTime&#39;, &#39;CRSDepTime&#39;, &#39;ArrTime&#39;, &#39;CRSArrTime&#39;, &#39;UniqueCarrier&#39;, &#39;FlightNum&#39;, &#39;TailNum&#39;, &#39;ActualElapsedTime&#39;, &#39;CRSElapsedTime&#39;, &#39;AirTime&#39;, &#39;ArrDelay&#39;, &#39;DepDelay&#39;, &#39;Origin&#39;, &#39;Dest&#39;, &#39;Distance&#39;, &#39;TaxiIn&#39;, &#39;TaxiOut&#39;, &#39;Cancelled&#39;, &#39;CancellationCode&#39;, &#39;Diverted&#39;, &#39;CarrierDelay&#39;, &#39;WeatherDelay&#39;, &#39;NASDelay&#39;, &#39;SecurityDelay&#39;, &#39;LateAircraftDelay&#39;] ## [&#39;1987&#39;, &#39;10&#39;, &#39;14&#39;, &#39;3&#39;, &#39;741&#39;, &#39;730&#39;, &#39;912&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;91&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;23&#39;, &#39;11&#39;, &#39;SAN&#39;, &#39;SFO&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1990&#39;, &#39;10&#39;, &#39;15&#39;, &#39;4&#39;, &#39;729&#39;, &#39;730&#39;, &#39;903&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;94&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;14&#39;, &#39;-1&#39;, &#39;SAN&#39;, &#39;SFO&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1990&#39;, &#39;10&#39;, &#39;17&#39;, &#39;6&#39;, &#39;741&#39;, &#39;730&#39;, &#39;918&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;97&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;29&#39;, &#39;11&#39;, &#39;SAN&#39;, &#39;SFO&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1990&#39;, &#39;10&#39;, &#39;18&#39;, &#39;7&#39;, &#39;729&#39;, &#39;730&#39;, &#39;847&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;78&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;-2&#39;, &#39;-1&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1991&#39;, &#39;10&#39;, &#39;19&#39;, &#39;1&#39;, &#39;749&#39;, &#39;730&#39;, &#39;922&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;93&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;33&#39;, &#39;19&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1991&#39;, &#39;10&#39;, &#39;21&#39;, &#39;3&#39;, &#39;728&#39;, &#39;730&#39;, &#39;848&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;80&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;-1&#39;, &#39;-2&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1991&#39;, &#39;10&#39;, &#39;22&#39;, &#39;4&#39;, &#39;728&#39;, &#39;730&#39;, &#39;852&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;84&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;3&#39;, &#39;-2&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1991&#39;, &#39;10&#39;, &#39;23&#39;, &#39;5&#39;, &#39;731&#39;, &#39;730&#39;, &#39;902&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;91&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;13&#39;, &#39;1&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] ## [&#39;1991&#39;, &#39;10&#39;, &#39;24&#39;, &#39;6&#39;, &#39;744&#39;, &#39;730&#39;, &#39;908&#39;, &#39;849&#39;, &#39;PS&#39;, &#39;1451&#39;, &#39;NA&#39;, &#39;84&#39;, &#39;79&#39;, &#39;NA&#39;, &#39;19&#39;, &#39;14&#39;, &#39;SAN&#39;, &#39;ABC&#39;, &#39;447&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;0&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;, &#39;NA&#39;] # my_csv_file is the variable holding the file with open(&#39;flights_sample.csv&#39;) as my_csv_file: my_reader = csv.reader(my_csv_file) # instead of printing a list, you can use the &quot;join&quot; # string method to neatly format the output for this_row in my_reader: print(&#39;, &#39;.join(this_row)) ## Year, Month, DayofMonth, DayOfWeek, DepTime, CRSDepTime, ArrTime, CRSArrTime, UniqueCarrier, FlightNum, TailNum, ActualElapsedTime, CRSElapsedTime, AirTime, ArrDelay, DepDelay, Origin, Dest, Distance, TaxiIn, TaxiOut, Cancelled, CancellationCode, Diverted, CarrierDelay, WeatherDelay, NASDelay, SecurityDelay, LateAircraftDelay ## 1987, 10, 14, 3, 741, 730, 912, 849, PS, 1451, NA, 91, 79, NA, 23, 11, SAN, SFO, 447, NA, NA, 0, NA, 0, NA, NA, NA, NA, NA ## 1990, 10, 15, 4, 729, 730, 903, 849, PS, 1451, NA, 94, 79, NA, 14, -1, SAN, SFO, 447, NA, NA, 0, NA, 0, NA, NA, NA, NA, NA ## 1990, 10, 17, 6, 741, 730, 918, 849, PS, 1451, NA, 97, 79, NA, 29, 11, SAN, SFO, 447, NA, NA, 0, NA, 0, NA, NA, NA, NA, NA ## 1990, 10, 18, 7, 729, 730, 847, 849, PS, 1451, NA, 78, 79, NA, -2, -1, SAN, ABC, 447, NA, NA, 0, NA, 0, NA, NA, NA, NA, NA ## 1991, 10, 19, 1, 749, 730, 922, 849, PS, 1451, NA, 93, 79, NA, 33, 19, SAN, ABC, 447, NA, NA, 0, NA, 0, NA, NA, NA, NA, NA ## 1991, 10, 21, 3, 728, 730, 848, 849, PS, 1451, NA, 80, 79, NA, -1, -2, SAN, ABC, 447, NA, NA, 0, NA, 0, NA, NA, NA, NA, NA ## 1991, 10, 22, 4, 728, 730, 852, 849, PS, 1451, NA, 84, 79, NA, 3, -2, SAN, ABC, 447, NA, NA, 0, NA, 0, NA, NA, NA, NA, NA ## 1991, 10, 23, 5, 731, 730, 902, 849, PS, 1451, NA, 91, 79, NA, 13, 1, SAN, ABC, 447, NA, NA, 0, NA, 0, NA, NA, NA, NA, NA ## 1991, 10, 24, 6, 744, 730, 908, 849, PS, 1451, NA, 84, 79, NA, 19, 14, SAN, ABC, 447, NA, NA, 0, NA, 0, NA, NA, NA, NA, NA How do you print each row of a csv grades_semi.csv, where instead of being comma-separated, values are semi-colon-separated? Click here for solution with open(&#39;grades_semi.csv&#39;) as my_csv_file: my_reader = csv.reader(my_csv_file, delimiter=&#39;;&#39;) for row in my_reader: print(row) ## [&#39;grade&#39;, &#39;year&#39;] ## [&#39;100&#39;, &#39;junior&#39;] ## [&#39;99&#39;, &#39;sophomore&#39;] ## [&#39;75&#39;, &#39;sophomore&#39;] ## [&#39;74&#39;, &#39;sophomore&#39;] ## [&#39;44&#39;, &#39;senior&#39;] ## [&#39;69&#39;, &#39;junior&#39;] ## [&#39;88&#39;, &#39;junior&#39;] ## [&#39;99&#39;, &#39;senior&#39;] ## [&#39;90&#39;, &#39;freshman&#39;] ## [&#39;92&#39;, &#39;junior&#39;] pathlib Path Examples How do I get the size of a file in bytes? Megabytes? Gigabytes? from pathlib import Path p = Path(&quot;./5000_products.csv&quot;) size_in_bytes = p.stat().st_size print(f&#39;Size in bytes: {size_in_bytes}&#39;) ## Size in bytes: 15416485 print(f&#39;Size in megabytes: {size_in_bytes/1000}&#39;) ## Size in megabytes: 15416.485 print(f&#39;Size in gigabytes: {size_in_bytes/1_000_000}&#39;) ## Size in gigabytes: 15.416485 numpy scipy pandas read_csv read_csv is a function from the pandas library that allows you to read tabular data into a pandas DataFrame. Examples How do I read a csv file called grades.csv into a DataFrame? Click here for solution Note that the &quot;.&quot; means the current working directory. So, if we were in &quot;/home/john/projects&quot;, &quot;./grades.csv&quot; would be the same as &quot;/home/john/projects/grades.csv&quot;. This is called a relative path. Read this for a better understanding. import pandas as pd myDF = pd.read_csv(&quot;./grades.csv&quot;) myDF.head() ## grade year ## 0 100 junior ## 1 99 sophomore ## 2 75 sophomore ## 3 74 sophomore ## 4 44 senior How do I read a csv file called grades_semi.csv where instead of being comma-separated, it is semi-colon-separated, into a DataFrame? Click here for solution import pandas as pd myDF = pd.read_csv(&quot;./grades_semi.csv&quot;, sep=&quot;;&quot;) myDF.head() ## grade year ## 0 100 junior ## 1 99 sophomore ## 2 75 sophomore ## 3 74 sophomore ## 4 44 senior How do I specify the type of 1 or more columns when reading in a csv file? Click here for solution import pandas as pd myDF = pd.read_csv(&quot;./grades.csv&quot;) myDF.dtypes # as you can see, year is of dtype &quot;object&quot; # object dtype can hold any Python object # we know that this column should hold strings # so let&#39;s specify this as we read in the data ## grade int64 ## year object ## dtype: object myDF = pd.read_csv(&quot;./grades.csv&quot;, dtype={&quot;year&quot;: &quot;string&quot;}) myDF.dtypes # if we wanted to specify that the &quot;grade&quot; # column should be float64 instead of int64 # we could do that too ## grade int64 ## year string ## dtype: object myDF = pd.read_csv(&quot;./grades.csv&quot;, dtype={&quot;year&quot;: &quot;string&quot;, &quot;grade&quot;: &quot;float64&quot;}) myDF.dtypes # and you can see that they are indeed floats now ## grade float64 ## year string ## dtype: object myDF.head() ## grade year ## 0 100.0 junior ## 1 99.0 sophomore ## 2 75.0 sophomore ## 3 74.0 sophomore ## 4 44.0 senior Given a list of csv files with the same columns, how can I read them in and combine them into a single dataframe? Click here for solution my_csv_files = [&quot;./grades.csv&quot;, &quot;./grades2.csv&quot;] data = [] for file in my_csv_files: myDF = pd.read_csv(file) data.append(myDF) final_result = pd.concat(data, axis=0) final_result ## grade year ## 0 100 junior ## 1 99 sophomore ## 2 75 sophomore ## 3 74 sophomore ## 4 44 senior ## 5 69 junior ## 6 88 junior ## 7 99 senior ## 8 90 freshman ## 9 92 junior ## 0 100 junior ## 1 99 sophomore ## 2 75 sophomore ## 3 74 sophomore ## 4 44 senior ## 5 69 junior ## 6 88 junior ## 7 99 senior ## 8 90 freshman ## 9 92 junior ## 10 45 senior DataFrame The DataFrame is one of the primary classes used from the pandas package. Much like data.frames in R, DataFrames in pandas store tabular, two-dimensional datasets. Most operations involve reading a dataset into a DataFrame, accessing the DataFrame's attributes, and using the DataFrame's methods to perform operations on the underlying data or with other DataFrames. Examples How do I get the number of rows and columns of a DataFrame, myDF? Click here for solution import pandas as pd myDF = pd.read_csv(&quot;./flights_sample.csv&quot;) # returns a tuple where the first value is the number of rows # and the second value is the number of columns myDF.shape # number of rows ## (9, 29) myDF.shape[0] # number of columns ## 9 myDF.shape[1] ## 29 How do I get the column names of a DataFrame, myDF? Click here for solution import pandas as pd myDF = pd.read_csv(&quot;./flights_sample.csv&quot;) myDF.columns ## Index([&#39;Year&#39;, &#39;Month&#39;, &#39;DayofMonth&#39;, &#39;DayOfWeek&#39;, &#39;DepTime&#39;, &#39;CRSDepTime&#39;, ## &#39;ArrTime&#39;, &#39;CRSArrTime&#39;, &#39;UniqueCarrier&#39;, &#39;FlightNum&#39;, &#39;TailNum&#39;, ## &#39;ActualElapsedTime&#39;, &#39;CRSElapsedTime&#39;, &#39;AirTime&#39;, &#39;ArrDelay&#39;, ## &#39;DepDelay&#39;, &#39;Origin&#39;, &#39;Dest&#39;, &#39;Distance&#39;, &#39;TaxiIn&#39;, &#39;TaxiOut&#39;, ## &#39;Cancelled&#39;, &#39;CancellationCode&#39;, &#39;Diverted&#39;, &#39;CarrierDelay&#39;, ## &#39;WeatherDelay&#39;, &#39;NASDelay&#39;, &#39;SecurityDelay&#39;, &#39;LateAircraftDelay&#39;], ## dtype=&#39;object&#39;) How do I change the name of a column &quot;Year&quot; to &quot;year&quot;? Click here for solution import pandas as pd myDF = pd.read_csv(&quot;./flights_sample.csv&quot;) # You must set myDF equal to the result # otherwise, myDF will remain unchanged myDF = myDF.rename(columns={&quot;Year&quot;: &quot;year&quot;}) # Alternatively, you can use the inplace # argument to make the change directly # to myDF myDF.rename(columns={&quot;year&quot;: &quot;YEAR&quot;}, inplace=True) # As you can see, since we used inplace=True # the change has been made to myDF without # setting myDF equal to the result of our # operation myDF.columns ## Index([&#39;YEAR&#39;, &#39;Month&#39;, &#39;DayofMonth&#39;, &#39;DayOfWeek&#39;, &#39;DepTime&#39;, &#39;CRSDepTime&#39;, ## &#39;ArrTime&#39;, &#39;CRSArrTime&#39;, &#39;UniqueCarrier&#39;, &#39;FlightNum&#39;, &#39;TailNum&#39;, ## &#39;ActualElapsedTime&#39;, &#39;CRSElapsedTime&#39;, &#39;AirTime&#39;, &#39;ArrDelay&#39;, ## &#39;DepDelay&#39;, &#39;Origin&#39;, &#39;Dest&#39;, &#39;Distance&#39;, &#39;TaxiIn&#39;, &#39;TaxiOut&#39;, ## &#39;Cancelled&#39;, &#39;CancellationCode&#39;, &#39;Diverted&#39;, &#39;CarrierDelay&#39;, ## &#39;WeatherDelay&#39;, &#39;NASDelay&#39;, &#39;SecurityDelay&#39;, &#39;LateAircraftDelay&#39;], ## dtype=&#39;object&#39;) How do I display the first n rows of a DataFrame? Click here for solution import pandas as pd myDF = pd.read_csv(&quot;./flights_sample.csv&quot;) # By default, this returns 5 rows myDF.head() # Use the &quot;n&quot; parameter to return a different number of rows myDF.head(n=10) How can I convert a list of dicts to a DataFrame? Click here for solution list_of_dicts = [] list_of_dicts.append({&#39;columnA&#39;: 1, &#39;columnB&#39;: 2}) list_of_dicts.append({&#39;columnB&#39;: 4, &#39;columnA&#39;: 1}) myDF = pd.DataFrame(list_of_dicts) myDF.head() ## columnA columnB ## 0 1 2 ## 1 1 4 Resources DataFrame Reference A list of DataFrame attributes and methods, with links to detailed docs. Series Resources 10 minute intro to pandas A great introduction to pandas. Very quick. Jupyter notebooks Writing scripts argparse Scraping XML XML stands for Extensible Markup Language. To read more about XML see here. lxml lxml is a package used for processing XML in Python. To get started, simply import the package: from lxml import etree To load XML from a string, do the following: my_string = f&quot;&quot;&quot;&lt;html&gt; &lt;head&gt; &lt;title&gt;My Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt; &lt;div class=&quot;abc123 sktoe-sldjkt dkjfg3-dlgsk&quot;&gt; &lt;div class=&quot;glkjr-slkd dkgj-0 dklfgj-00&quot;&gt; &lt;a class=&quot;slkdg43lk dlks&quot; href=&quot;https://example.com/123456&quot;&gt; &lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div class=&quot;ldskfg4&quot;&gt; &lt;span class=&quot;slktjoe&quot; aria-label=&quot;123 comments, 43 Retweets, 4000 likes&quot;&gt;Love it.&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;div data-amount=&quot;12&quot;&gt;13&lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div class=&quot;abc123 sktoe-sls dkjfg-dlgsk&quot;&gt; &lt;div class=&quot;glkj-slkd dkgj-0 dklfj-00&quot;&gt; &lt;a class=&quot;slkd3lk dls&quot; href=&quot;https://example.com/123456&quot;&gt; &lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div class=&quot;ldg4&quot;&gt; &lt;span class=&quot;sktjoe&quot; aria-label=&quot;1000 comments, 455 Retweets, 40000 likes&quot;&gt;Love it.&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;div data-amount=&quot;122&quot;&gt;133&lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;&quot;&quot;&quot; tree = etree.fromstring(my_string) Or, to load an XML file called example.xml do the following: tree = etree.parse(&quot;example.xml&quot;) From there, you can use xpath expressions to parse the dataset. Examples How do I get the name of the root node from my lxml tree called tree? Click here for solution # remember &quot;/&quot; gets the node starting at the root node and &quot;*&quot; is a # wildcard that means &quot;anything&quot; tree.xpath(&quot;/*&quot;)[0].tag ## &#39;html&#39; If the root node is named &quot;html&quot;, how do I get the name of all nested tags? Click here for solution list_of_tags = [x.tag for x in tree.xpath(&quot;/html/*&quot;)] print(list_of_tags) # remember, this odd syntax is just a &quot;list comprehension&quot;. It is # essentially a nice short-hand way of writing a loop in Python. # It is the exact same as: ## [&#39;head&#39;, &#39;body&#39;] for element in tree.xpath(&quot;/html/*&quot;): print(element.tag) ## head ## body How do I get the attributes of an element? Click here for solution import pandas as pd # as you can see, this prints the attributes in a dict-like object for each div element # in the node. for element in tree.xpath(&quot;//div&quot;): print(element.attrib) # Note, if you ever want to convert a list of dicts to a pandas dataframe # you will need to convert to a dict. ## {} ## {&#39;class&#39;: &#39;abc123 sktoe-sldjkt dkjfg3-dlgsk&#39;} ## {&#39;class&#39;: &#39;glkjr-slkd dkgj-0 dklfgj-00&#39;} ## {} ## {&#39;class&#39;: &#39;ldskfg4&#39;} ## {&#39;data-amount&#39;: &#39;12&#39;} ## {} ## {&#39;class&#39;: &#39;abc123 sktoe-sls dkjfg-dlgsk&#39;} ## {&#39;class&#39;: &#39;glkj-slkd dkgj-0 dklfj-00&#39;} ## {} ## {&#39;class&#39;: &#39;ldg4&#39;} ## {&#39;data-amount&#39;: &#39;122&#39;} list_of_dicts = [] for element in tree.xpath(&quot;//div&quot;): list_of_dicts.append(element.attrib) myDF = pd.DataFrame(list_of_dicts) myDF.head() # unexpected ## 0 ## 0 None ## 1 class ## 2 class ## 3 None ## 4 class list_of_dicts = [] for element in tree.xpath(&quot;//div&quot;): list_of_dicts.append(dict(element.attrib)) myDF = pd.DataFrame(list_of_dicts) myDF.head() # fixed ## class data-amount ## 0 NaN NaN ## 1 abc123 sktoe-sldjkt dkjfg3-dlgsk NaN ## 2 glkjr-slkd dkgj-0 dklfgj-00 NaN ## 3 NaN NaN ## 4 ldskfg4 NaN How do I get the div elements with attribute &quot;data-amount&quot;? Click here for solution for element in tree.xpath(&quot;//div[@data-amount]&quot;): print(element.attrib) ## {&#39;data-amount&#39;: &#39;12&#39;} ## {&#39;data-amount&#39;: &#39;122&#39;} How do I get the div elements where data-amount is greater than 50? Click here for solution for element in tree.xpath(&quot;//div[@data-amount &gt; 50]&quot;): print(element.attrib) ## {&#39;data-amount&#39;: &#39;122&#39;} How do I get the values of the span tags? Click here for solution for element in tree.xpath(&quot;//span&quot;): print(element.text) ## Love it. ## Love it. Plotting matplotlib Resources plotly plotnine pygal seaborn bokeh Classes Attributes Methods tensorflow pytorch "],
["tools.html", "Tools Docker Tableau GitHub VPNs", " Tools Docker Tableau GitHub Overview GitHub is a git repository hosting service. There are other, less well known repository hosting services such as: GitLab, Bitbucket, and Gitea. git itself is a free and open source version-control system for tracking changes in source code during software development.1 git Install Follow the instructions here to install git onto your machine. Configure git Run the following commands: git config --global user.name &quot;You name here&quot; git config --global user.email &quot;your_email@example.com&quot; Next, you need to authenticate with GitHub. Create a public/private keypair: ssh-keygen -t rsa -C &quot;your_email@example.com&quot; This creates two files: ~/.ssh/id_rsa --your private key and ~/.ssh/id_rsa.pub --your public key Copy your public key to your clipboard. Navigate and sign in to https://github.com. Go here, and click &quot;New SSH key&quot;. Name the key whatever you'd like in the &quot;Title&quot; field. Usually, I put the name of the computer I'm using. Paste the key in the &quot;Key&quot; field, and click &quot;Add SSH key&quot;. At this point in time you should be good to go. Verify by running the following in your terminal: ssh -T git@github.com You should receive a message like: Hi username! You&#39;ve successfully authenticated, but Github does not provide shell access. Clone a repository If you've followed the directions here to configure git with SSH: Open a terminal and navigate into the folder in which you'd like to clone the repository. For example, let's say I would like to clone this book's repository into my ~/projects folder: cd ~/projects Next, run the following command: git clone git@github.com:TheDataMine/the-examples-book.git At this point in time, you should have a new folder called the-examples-book inside your ~/projects folder. Commit changes to a repository Creating a commit is simple: Navigate into your project repository folder. For example, let's assume our repository lives: ~/projects/the-examples-book. cd ~/projects/the-examples-book Modify the repository files as you would like, saving the changes. Create your commit, with an accompanying message: git commit -m &quot;Fixed minor spelling error.&quot; Fetch remote changes Navigate to the local repository. For example, let's assume our repository lives: ~/projects/the-examples-book. cd ~/projects/the-examples-book Fetch and pull the changes: git fetch git pull Push local commits to the remote origin First fetch any remote changes. Then run the following commands: git push Create a new branch To create a new branch based off of the master branch do the following. Checkout the master branch: git checkout master Create a new branch named fix-spelling-errors-01 based off of the master branch and check the new fix-spelling-errors-01 branch out: git checkout -b fix-spelling-errors-01 Publish your branch to GitHub If your current local branch is not present on its remote origin, git push will publish the branch to GitHub. Create a pull request After publishing a local branch to GitHub, in order to create a pull request, simply navigate to the following link: https://github.com/my_organization/my_repo/pull/new/my_branch_name Replace my_organization with the username or organization name. For example: thedatamine. Replace my_repo with the name of the repository. For example: the-examples-book. Replace my_branch_name with the name of the branch you would like to have merged into the master branch. For example: fix-spelling-errors-01. So at the end, using our examples, you would navigate to: https://github.com/TheDataMine/the-examples-book/pull/new/fix-spelling-errors-01 Fill out the information, and click &quot;Create pull request&quot;. GitHub Desktop Install Follow the excellent directions here to install GitHub Desktop. Upon the launch of the application, you should be presented with a screen similar to this: 3. Click on &quot;Sign in to GitHub.com. 4. Enter your GitHub credentials in the following screen: 5. Continue the sign in process. You will eventually be presented with a screen to select a repository. Congratulations! You've succesfully installed GitHub Desktop. Commit changes to a repository First, make a change to to a file within the repository. In this example, I added a contributor named John Smith: 2. In the lower left-hand corner of the GUI, add a Commit title and description. Concise and detailed titles and descriptions are best. Click &quot;Commit to name-of-branch&quot; in this case, our branch name is fix-spelling-errors-01. 3. At this point in time the Commit is only local (on your machine). In order to update the remote respository (on GitHub), you'll need to publish your branch. If your branch is already published (present on github.com), you'll need to push your local commits to the remote origin (which is the remote fix-spelling-errors-01 branch in this case) by clicking on the &quot;Push origin&quot; button: Push local commits to the remote origin If you have commits that are ready to be pushed to the remote origin (github.com), you'll be presented with a screen similar to this: Simply click on the &quot;Push origin&quot; button in order to push your local commits to the remote origin (which is in this case, a remote branch called fix-spelling-errors-01): You can verify that the changes have been made by navigating to the branch on github.com, and checking the commit history. Create a new branch In GitHub Desktop, click on the &quot;Current Branch&quot; dropdown: 2. Click on the &quot;New Branch&quot; button: 3. When presented with the following screen, ensure that your new branch will be based on the master branch: 4. Type whatever name you'd like to give the new branch. In this case, we are calling it fix-spelling-errors-01. Click &quot;Create Branch&quot;. 5. Your current branch should now be fix-spelling-errors-01 or whatever name you entered in step (4). You can see this in the dropdown: Publish your branch to GitHub If the branch you created is not already present remotely, you'll have a button available to you that says &quot;Publish Branch&quot;. Clicking this button will push the branch to the remote repository (on github.com): 2. You can confirm that the branch has been successfully pushed to github.com by navigating to the repository on github, and clicking on the &quot;branches&quot; tab: Create a pull request If the branch you are working on is already published remotely, and the remote repository and local repository are both up to date, you will be presented with a screen similar to this: Note that if your local repository is ahead of the remote repository, you will instead be presented with a screen similar to this: You will first need to push your local commits to the origin (which is the remote fix-spelling-errors-01 branch in this case) by clicking on the &quot;Push origin&quot; button. Click the &quot;Create Pull Request&quot; button. This will open up a tab in your browser: Leave a detailed comment about what you've modified or added to the book. You can click on &quot;Preview&quot; to see what your comment will look like. GitHub's markdown applies here. Once satisfied, click &quot;Create pull request&quot;. Resources GitHub glossary: An excellent resource to understand git and GitHub specific terminology. Learn git branching: An interactive game that teaches you about git branching. VPNs https://en.wikipedia.org/wiki/Git↩ "],
["faqs.html", "FAQs Cannot open the connection. No such file or directory. How do I connect to Scholar from off-campus? In Scholar, on RStudio, my font size looks weird or my cursor is offset. I'm unable to type into the terminal in RStudio. I'm unable to connect to RStudio Server. RStudio is taking a long time to open. How do I delete a file from my RStudio directory? (asked by Karthik Uppuluri) How do I rename a file from my RStudio directory? How can you run a line of R code in RStudio without clicking the &quot;Run&quot; button? My R session freezes. Scholar is slow. How to transfer files between your computer and Scholar. My password will not work. Jupyter Notebook download error with IE. Jupyter Notebook kernel dying. Python kernel not working, Jupyter Notebook won't save. Installing my_package for Python. Displaying multiple images after a single Jupyter Notebook Python code cell. RMarkdown “Error: option error has NULL value” when knitting&quot;. How do you create an RMarkdown file? Problems building an RMarkdown document on Scholar. How can I use SQL in RMarkdown? Copy/paste from terminal (not a console) inside RStudio to RMarkdown. How do I render an image in a shiny app? The package my_package is not found. Problems installing ggmap. Error: object_name is not found. Zoom in on ggmap. Find the latitude and longitude of a location. Problems saving work as a PDF in R on Scholar. What is a good resource to better understand HTML? Is there a style guide for R code? Is there a guide for best practices using R? Tips for using Jupyter notebooks. What is my username on Scholar? How and why would I need to &quot;escape a character&quot;? How can I fix the error &quot;Illegal byte sequence&quot; when using a UNIX utility like cut? Unicode character error when Knitting an RMarkdown file to PDF. My tab key will not auto-complete anymore in RStudio. How can I fix this?", " FAQs Cannot open the connection. No such file or directory. Copy/paste from terminal (not a console) inside RStudio to RMarkdown. Displaying multiple images after a single Jupyter Notebook Python code cell. Error: object_name is not found. Find the latitude and longitude of a location. How and why would I need to &quot;escape a character&quot;? How can I fix the error &quot;Illegal byte sequence&quot; when using a UNIX utility like cut? How can I use SQL in RMarkdown? How can you run a line of R code in RStudio without clicking the &quot;Run&quot; button? How do I connect to Scholar from off-campus? How do I delete a file from my RStudio directory? How do I rename a file from my RStudio directory? How do I render an image in a shiny app? How do you create an RMarkdown file? How to transfer files between your computer and Scholar. I'm unable to connect to RStudio Server. I'm unable to type into the terminal in RStudio. In Scholar, on RStudio, my font size looks weird or my cursor is offset. Installing my_package for Python. Is there a guide for best practices using R? Is there a style guide for R code? Jupyter Notebook download error with IE. Jupyter Notebook kernel dying. My password will note work. My R session freezes. Problems building an RMarkdown document on Scholar. Problems installing ggmap. Problems saving work as a PDF in R on Scholar. Python kernel not working, Jupyter Notebook won't save. RMarkdown “Error: option error has NULL value” when knitting&quot;. RStudio is taking a long time to open. Scholar is slow. The package my_package is not found. Tips for using Jupyter notebooks. Unicode character error when Knitting an RMarkdown file to PDF. What is a good resource to better understand HTML? What is my username on Scholar? Zoom in on ggmap. Cannot open the connection. No such file or directory. If you receive an error similar to: Error in file(file, &quot;rt&quot;) : cannot open the connection In addition: Warning message: In file(file, &quot;rt&quot;) : cannot open file &#39;/class/datamine/data/goodreads_books.csv&#39;: No such file or directory This error means that the path to the dataset does not exist. In this case, the path should be /class/datamine/data/csv/goodreads_books.csv. When you receive an error like this, usually during a call to read.csv, you should double check that the path to your dataset is actually correct. How do I connect to Scholar from off-campus? There are a variety of ways to connect to Scholar from off-campus. If you just want to use Jupyter notebooks (e.g., for Python), you can use JupyterHub. If you just want to use RStudio, you can use RStudio Server. In Scholar, on RStudio, my font size looks weird or my cursor is offset. In scholar, navigate to Tools &gt; Global Options &gt; Appearance. You can change your font, including the size and the color scheme. The default font in RStudio Server Pro is Modern (font size 10), and the default Editor theme is Textmate. Make your desired changes, and then click the Apply button. I'm unable to type into the terminal in RStudio. Try opening a new terminal, try clearing the terminal buffer, or interrupting the current terminal. All these options come from a menu that will pop up when you hit the small down arrow next to the words &quot;Terminal 1&quot; (it might be another number depending on how many terminals are open) which is on the left side right above the terminal in RStudio. I'm unable to connect to RStudio Server. Try closing your browser, clearing your cookies, and using the original link: https://rstudio.scholar.rcac.purdue.edu/ for RStudio Server Pro. RStudio is taking a long time to open. Click here for video In general, you do NOT want to save your .RData file when you close RStudio. These files will make RStudio take a long time to open, next time you use RStudio. It is possible that you (previously) saved a large .RData file the last time that you closed RStudio. If you did save your .RData file, and your RStudio is very slow to open, then you might want to remove the .RData file now. You can do the following: Inside RStudio, select the Terminal (located near the Console; do not use the Console itself). Inside the Terminal, type: cd (and hit Enter/Return) so that you will be working in your home directory. You can double-check this by typing: pwd and it should show you that you are working in /home/mdw (but of course mdw will be whatever your username is). Type: rm .RData (be sure to put a space between rm and .RData) and then hit Enter/Return. Now your R workspace should be fresh when you log out of RStudio (by clicking the little orange &quot;log out&quot; button, in the upper-right-hand corner of RStudio). In other words, next time, you will not have old variables hanging around, from a previous session. Now your RStudio should load more quickly at the start. How do I delete a file from my RStudio directory? (asked by Karthik Uppuluri) In the lower-right-hand corner of your RStudio, you have a panel with 5 tabs: Files, Plots, Packages, Help, Viewer Choose the Files tab. That will give you a listing of files in your home directory. You can click on any of them (i.e., put a checkbox beside the name of the file) and hit the Delete button. Screenshot provided by Hilda Somnooma Marie Bernadette Ibriga: How do I rename a file from my RStudio directory? In the lower-right-hand corner of your RStudio, you have a panel with 5 tabs: Files, Plots, Packages, Help, Viewer Choose the Files tab. That will give you a listing of files in your home directory. You can click on any of them (i.e., put a checkbox beside the name of the file) and hit the Rename button. How can you run a line of R code in RStudio without clicking the &quot;Run&quot; button? Click anywhere on the line (you do not need to highlight the line, and you do not need to click at the start or end of the line; anywhere on the line is ok). Type the &quot;Control&quot; and the &quot;Return (or Enter)&quot; keys together, at the same time, to run that line. This will save you a great deal of time, in the long run. My R session freezes. Log out of RStudio Server Pro, using either the &quot;Sign Out&quot; under the File Menu, or using the little orange &quot;log out&quot; button, in the upper-right-hand corner of RStudio. If neither option works, you can try closing your browser window manually. Scholar is slow. Possibility one: Some of the files we use in this class require a few minutes to load, if we use the read.csv() function in R. Here is a method that can save you some time in data import: Read only the first, say, 10000 rows of data (see instructions below), and complete your code using the smaller dataset. The code works for the subset of data should also work for the complete data. This output is not your final answer! Once you complete the code, read in the entire dataset, and run the code to RStudio. You may even close the ThinLinc after submitting the code as long as you do not close your RStudio window. Closing RStudio will stop your code from running. It is also highly recommended to save your code prior to running it. Some time (e.g., a few hours) later, you can come back and check your output. Scholar is a computing facility that is always on, and thus you can leave it do the work. How do you read the first 10000 rows then? For example, we usually use the following line of code to read all of the election data: myDF &lt;- read.csv(&#39;/class/datamine/data/election/itcont2020.txt&#39;) Now, with an additional parameter nrows, you can decide how many rows to read: myDF_short &lt;- read.csv(&#39;/class/datamine/data/election/itcont2020.txt&#39;, nrows = 10000) Possibility two: You could be close to using 100% of your quota on scholar. Use the Terminal (not the Console), and run the following command: myquota. If your quota is near 100% in your /home directory (25 GB), you will need to delete some files. How to transfer files between your computer and Scholar. Solution 1: use a file transfer client There are many specialized file transfer clients. On Windows, we recommend WinSCP: https://winscp.net/eng/download.php (There are frequently advertisements on this page, but look for the green button that says something like DOWNLOAD WINSCP 5.17.7 (10.6 MB)) On a Mac, we recommand Fetch: https://fetchsoftworks.com/ (Education users can apply for a free license: https://fetchsoftworks.com/fetch/free) The server hostname that you want to connect to is: scholar.rcac.purdue.edu FileZilla is another good client, which works on all platforms. Download and install the FileZilla Client onto your personal computer. FileZilla uses sftp ([S]SH [F]ile [T]ransfer [P]rotocol) to transfer files to and from Scholar. To connect to Scholar from FileZilla, enter the following information and click &quot;Quickconnect&quot;: Host: scholar.rcac.purdue.edu Username: &lt;your_scholar_username&gt; (For example, Dr. Ward's would be mdw. See here.) Password: &lt;your_scholar_password&gt; Port: 22 After clicking &quot;Quickconnect&quot; you may be asked something similar to the following: Select &quot;OK&quot; and establish the connection. The files on the left-hand side are your local computer's files. The files on the right-hand side are the files in Scholar. To download files from Scholar, right click the file(s) on the Scholar side (right-hand side) and click &quot;Download&quot;. To upload files to Scholar, right click the file(s) on your local machine (left-hand side) and click &quot;Upload&quot;. Solution 2: use SFTP On windows: Open your start menu and click on cmd. Type: sftp username@scholar.rcac.purdue.edu (replace &quot;username&quot; with your username). Once connected, follow the documentation from RCAC to transfer files. On mac: Open a terminal. Type: sftp username@scholar.rcac.purdue.edu (replace &quot;username&quot; with your username). Once connected, follow the documentation from RCAC to transfer files. My password will not work. Remember that you need to use your BoilerKey to log into most resources on Scholar this year: https://www.purdue.edu/boilerkey You typically type your 4-digit PIN, then a comma, and then your randomly generated BoilerKey code. There is still one Scholar tool that uses the Career password: Jupyter Notebooks, located at https://notebook.scholar.rcac.purdue.edu/ If your Career password has expired and you need to log onto Jupyter Notebooks, you can use these steps to reset your password: Go to Secure Purdue. Click on the option &quot;Change your password&quot;. After logging in, search for the link &quot;Change Password&quot; that &quot;Allows you to change your Purdue Career Account password&quot;. Jupyter Notebook download error with IE. Please note that Internet Explorer is not a recommended browser. If still want to use Explorer, make sure you download the notebook as &quot;All Files&quot; (or something similar). That is, we need to allow the browser to save in its natural format, and not to convert the notebook when it downloads the file. Jupyter Notebook kernel dying. Make sure you are using the R 3.6 (Scholar) kernel. Make sure you are using https://notebook.scholar.rcac.purdue.edu and not https://notebook.brown.rcac.purdue.edu. (Use Scholar instead of Brown.) Try clicking Kernel &gt; Shutdown, and then reconnect the kernel. If one particular Jupyter Notebook template gives you this error, then create a new R 3.6 (Scholar) file. Try re-running the code from an earlier project that you had set up and working using Jupyter Notebooks. One student needed to re-run the setup command one time in the terminal: /class/datamine/apps/runme.sh You could be close to using 100% of your quota on scholar. Use the Terminal (not the Console), and run the following command: myquota. If your quota is near 100% in your /home directory (25 GB), you will need to delete some files. Python kernel not working, Jupyter Notebook won't save. You probably have a package conflict. Navigate to Jupyter Notebook: https://notebook.scholar.rcac.purdue.edu/, and login. Click on the &quot;Running&quot; tab and shutdown all running kernels. Then navigate to RStudio: https://rstudio.scholar.rcac.purdue.edu/, and login. Open a terminal, and run the following commands: pip uninstall mypackagenamehere /class/datamine/apps/runme.sh Go back to https://notebook.scholar.rcac.purdue.edu/, click on &quot;Control Panel&quot; in the upper right hand corner. Click the &quot;Stop My Server&quot; button, followed by the green &quot;My Server&quot; button. Installing my_package for Python. Do not install packages in Scholar using: pip install my_package or pip install my_package --user We've tried to provide you with a ready-made kernel with every package you would want or need. If you need a newer version of some package, or need a package not available in the kernel, please send us a message indicating what you need. Depending on the situation we may point you to create your own kernel. Displaying multiple images after a single Jupyter Notebook Python code cell. Sometimes it may be convenient to have several images displayed after a single Jupyter cell. For example, if you want to have side-by-side images or graphs for comparison. The following code allows you to place figures side-by-side or in a grid. Note you will need the included import statement at the very top of the notebook. import matplotlib.pyplot as plt number_of_plots = 2 fig, axs = plt.subplots(number_of_plots) fig.suptitle(&#39;Vertically stacked subplots&#39;, fontsize=12) axs[0].plot(x, y) axs[1].imshow(img) plt.show() number_of_plots = 3 fig, axs = plt.subplots(1,number_of_plots) fig.suptitle(&#39;Horizontally stacked subplots&#39;, fontsize=12) axs[0].plot(x, y) axs[1].imshow(img) axs[2].imshow(img2) plt.show() number_of_plots_vertical = 2 number_of_plots_horizontal = 2 # 2 x 2 = 4 total plots fig, axs = plt.subplots(number_of_plots_vertical,number_of_plots_horizontal) fig.suptitle(&#39;Grid of subplots&#39;, fontsize=12) axs[0][0].plot(x, y) # top left axs[0][1].imshow(img) # top right axs[1][0].imshow(img2) # bottom left axs[1][1].plot(a, b) # bottom right plt.show() RMarkdown “Error: option error has NULL value” when knitting&quot;. This error message occurs when running a code chunk in RMarkdown by clicking the green &quot;play&quot; button (Run Current Chunk). Do not click on the green triangle &quot;play&quot; button. Instead, knit the entire document, using the &quot;knit&quot; button that looks like a ball of yarn with a knitting needle on it. How do you create an RMarkdown file? Any text file with the .Rmd file extension can be opened and knitted into a PDF (or other format). If you'd like to create an RMarkdown file in RStudio, you can do so. Open an RStudio session. Click on File &gt; New File &gt; RMarkdown.... You may put R code into the R blocks (the grey sections of the document), and put any comments into the white sections in between. This is an excellent guide to RMarkdown, and this is a cheatsheet to get you up and running quickly. Problems building an RMarkdown document on Scholar. If you are having problems building an RMarkdown document on Scholar, try the following: Remove your R directory: Open up a terminal (not a console) in RStudio. Run the following commands: cd ~ rm -rf R This will force the removal of your R directory. It will remove your old R libraries. They will reload the newest versions if you install them again, and as you use them. This is recommended, especially at the start of the academic year. If your R is taking a long time to open, see here. How can I use SQL in RMarkdown? When you use SQL in RMarkdown you can highlight the code in code chunks just like R by writing &quot;sql&quot; instead of &quot;r&quot; in the brackets: SELECT * FROM table; You will notice that all the SQL code chunks provided in the template have the option eval=F. The option eval=F or eval=FALSE means that the SQL statements would be shown in your knitted document, but without being executed. To actually run SQL inside RMarkdown see here. You can read about the different languages that can be displayed in RMarkdown here: https://bookdown.org/yihui/rmarkdown/language-engines.html. Copy/paste from terminal (not a console) inside RStudio to RMarkdown. If you're using the terminal inside the Scholar RStudio at https://rstudio.scholar.rcac.purdue.edu, then right clicking won't work. A trick that does work (and often works in other situations as well) is the keyboard shortcut ctrl-insert for copy and shift-insert for paste. Alternatively, use the Edit/Copy from the menu in the terminal. How do I render an image in a shiny app? There are a variety of ways to render an image in an RShiny app. See here. The package my_package is not found. The package might not be installed. Try running: install.packages(&quot;ggmap&quot;) Note that if you have already run this on ThinLinc, there is no need to do it again. Another possibility is that the library is not loaded, try running: library(ggmap) Problems installing ggmap. Two possible fixes: Open a terminal (not the console) in RStudio and run: rm -rf ~/R After that, re-open RStudio and re-install ggmap: install.packages(&quot;ggmap&quot;) # Don&#39;t forget to load the package as well library(ggmap) Open a terminal (not the console) and run: module load gcc/5.2.0 After that, restart all RStudio processes. Error: object_name is not found. In R if you try to reference an object that does not yet exist, you will receive this error. For example: my_list &lt;- c(1, 2, 3) mylist In this example you will receive the error Error: object 'mylist' not found. The reason is mylist doesn't exist, we only created my_list. Zoom in on ggmap. Run the following code in R: ?get_googlemap Under the arguments section you will see the argument zoom and can read about what values it can accept. For the zoom level , a map with zoom=9 would not even show the entire state of California. Try different integers. Larger integers &quot;zoom in&quot; and smaller integers &quot;zoom out&quot;. Find the latitude and longitude of a location. Install the ggmap package. Run the following lines of code to retrieve latitude and longitude of a location: as.numeric(geocode(&quot;London&quot;)) Replace &quot;London&quot; with the name of your chosen location. Problems saving work as a PDF in R on Scholar. Make sure you are saving to your own working directory: getwd() This should result in something like: /home/&lt;username&gt;/... where &lt;username&gt; is your username. Read this to find your username. If you don't see your username anywhere the the resulting path, instead try: Specifying a different directory: dev.print(pdf, &quot;/home/&lt;username&gt;/project4map.pdf&quot;) Make sure you replace &lt;username&gt; with your username. Try setting your working directory before saving: setwd(&quot;/home/&lt;username&gt;&quot;) Make sure you replace &lt;username&gt; with your username. What is a good resource to better understand HTML? https://www.geeksforgeeks.org/html-course-structure-of-an-html-document/ Is there a style guide for R code? https://style.tidyverse.org/ Is there a guide for best practices using R? https://www.r-bloggers.com/r-code-best-practices/ Comment what you are going to do. Code -- what did you do? Comment on the output -- what did you get? Tips for using Jupyter notebooks. See here. What is my username on Scholar? To find your username on Scholar: Open a terminal (not the console). Execute the following code: echo $USER How and why would I need to &quot;escape a character&quot;? You would need to escape a character any time when you have a command or piece of code where you would like to represent a character literally, but that character has been reserved for some other use. For example, if I wanted to use grep to search for the $ character, literally, I would need to escape that character as its purpose has been reserved as an indicator or anchor for the end of the line. grep -i &quot;\\$50.00&quot; some_file.txt Without the \\ this code would not work as intended. In this case, if you chose to use single quotes instead, this would work, because single quotes are taken literally by the shell and aren't expanded like with double quotes: grep -i &#39;$50.00&#39; some_file.txt Another example would be searching for &quot;a&quot; or &quot;b&quot;, notice we need to escape (, ), and |: grep -i &#39;\\(a\\|b\\)&#39; some_file.txt Alternatively, we could use the -E option which uses extended regular expressions and doesn't need to be escaped as much: grep -Ei &#39;(a|b)&#39; some_file.txt Another example would be if you wanted to write out 10*10*10 = 1000 in markdown. If you don't escape the asterisks, the result may be rendered as 101010 = 1000, which is clearly not what was intended. For this reason, we would type out: 10\\*10\\*10 = 1000 Which would then have its intended effect. Resources Basic matches Last paragraph here How can I fix the error &quot;Illegal byte sequence&quot; when using a UNIX utility like cut? Often times this is due to your input having illegal, non-utf-8 values. You can find all lines with illegal values by running: grep -axv &#39;.*&#39; file To fix this issue, you can remove the illegal values by running: iconv -c -t UTF-8 &lt; old_file &gt; new_file Unicode character error when Knitting an RMarkdown file to PDF. If you get the following error when trying to Knit an RMarkdown file to PDF: ! Package inputenc Error: Unicode character &lt;somecharacter&gt; (U+0195) (inputenc) not set up for use with LaTeX. You are probably trying to print a unicode character. If you don't think you are trying to print a unicode character, it could be that part of some dataset which you are printing is. To fix this error, print a different slice of the dataset. Alternatively, try using xelatex to compile your PDF, by modifying your YAML header to look something like: --- title: &quot;Title&quot; output: pdf_document: latex_engine: xelatex --- Important note: Make sure you verify that the PDF contents are what you expect if testing xelatex. My tab key will not auto-complete anymore in RStudio. How can I fix this? In the Terminal (not the Console) in RStudio, type: cd ~/.config mv rstudio rstudio.old mv RStudio RStudio.old and then log out of RStudio using the little orange button, and log back in. "],
["projects.html", "Projects Templates Submissions STAT 19000 STAT 29000 STAT 39000", " Projects Templates Our course project template can be found here, or on Scholar: /class/datamine/apps/templates/project_template.Rmd Important note: We've updated the template to allow a code chunk option that prevents content from running off the page. Simply add linewidth=80 to any code chunk that creates output that runs off the page. This video demonstrates: opening a browser (emphasizing Firefox as the best choice), opening RStudio Server Pro (https://rstudio.scholar.rcac.purdue.edu), introducing (basics) about what RStudio looks like, checking to see that the students are using R 4.0, running the initial (one-time) setup script, opening the project template, knitting the template into a PDF file, and finally handling the popup blocker, which can potentially block the PDF. Click here for video Students in STAT 19000, 29000, and 39000 are to use this as a template for all project submissions. The template includes a code chunk that &quot;activates&quot; our Python environment, and adjusts some default settings. In addition, it provides examples on how to include solutions for Python, R, Bash, and SQL. Every question should be clearly marked with a third-level header (using 3 #s) followed by Question 1, Question 2, etc. Sections for solutions should be added or removed, based on the number of questions in the given project. All code chunks are to be run and solutions displayed for the compiled PDF submission. Any format or template related questions should be asked in Piazza. Submissions Unless otherwise specified, all projects will need 2-4 submitted files: A compiled PDF file (built using the template), with all code and output. The .Rmd file (based off of the template), used to Knit the final PDF. If it is a project containing R code, a .R file containing all of the R code with comments explaining what the code does. Note: This is not an .Rmd file. If it is a project containing Python code, a .py file containing all of the Python code. STAT 19000 Project 1 Motivation: In this course we require the majority of project submissions to include a compiled PDF, a .Rmd file based off of our template, and a code file (a .R file if the project is in R, a .py file if the project is in Python). Although RStudio makes it easy to work with both Python and R, there are occasions where working out a Python problem in a Jupyter Notebook could be convenient. For that reason, we will introduce Jupyter Notebook in this project. Context: This is the first in a series of projects that will introduce Python and its tooling to students. Scope: jupyter notebooks, rstudio, python Learning objectives: Use Jupyter Notebook to run Python code and create Markdown text. Use RStudio to run Python code and compile your final PDF. Gain exposure to Python control flow and reading external data. Make sure to read about, and use the template found here, and the important information about projects submissions here. Dataset The following questions will use the dataset found in Scholar: /class/datamine/data/open_food_facts/openfoodfacts.tsv Questions 1. Navigate to https://notebook.scholar.rcac.purdue.edu/ and sign in with your Purdue credentials (without BoilerKey). This is an instance of Jupyter Notebook. The main screen will show a series of files and folders that are in your $HOME directory. Create a new notebook by clicking on New &gt; f2020-s2021. Change the name of your notebook to &quot;LASTNAME_FIRSTNAME_project01&quot; where &quot;LASTNAME&quot; is your family name, and &quot;FIRSTNAME&quot; is your given name. Try to export your notebook, what format options (for example, .txt) are available to you? Important note: f2020-s2021 is the name of our course notebook kernel. A notebook kernel is an engine that runs code in a notebook. ipython kernels run Python code. f2020-s2021 is an ipython kernel that we've created for our course Python environment, which contains a variety of compatible, pre-installed packages for you to use. When you select f2020-s2021 as your kernel, all of the packages in our course environment are automatically made available to you. Item(s) to submit: A list of export format options. 2. Each &quot;box&quot; in a Jupyter Notebook is called a cell. There are two primary types of cells: code, and markdown. By default, a cell will be a code cell. Place the following Python code inside the first cell, and run the cell. What is the output? from thedatamine import hello_datamine hello_datamine() Hint: You can run the code in the currently selected cell by using the GUI (the buttons), as well as by pressing Ctrl+Return/Enter. Item(s) to submit: Output from running the provided code. 3. Jupyter Notebooks allow you to easily pull up documentation, similar to ?function in R. To do so, use the help function, like this: help(my_function). What is the output from running the help function on hello_datamine? Can you modify the code from question (2) to print a customized message? Create a new markdown cell and explain what you did to the code from question (2) to make the message customized. Important note: Some Jupyter-only methods to do this are: Click on the function of interest and type Shift+Tab or Shift+Tab+Tab. Run function?, for example, print?. Important note: You can also see the source code of a function in a Jupyter Notebook by typing function??, for example, print??. Item(s) to submit: Output from running the help function on hello_datamine. Modified code from question (2) that prints a customized message. 4. At this point in time, you've now got the basics of running Python code in Jupyter Notebooks. There is really not a whole lot more to it. For this class, however, we will continue to create RMarkdown documents in addition to the compiled PDFs. You are welcome to use Jupyter Notebooks for personal projects or for testing things out, however, we will still require an RMarkdown file (.Rmd), PDF (generated from the RMarkdown file), and .py file (containing your python code). Let's learn how to run Python code chunks in RMarkdown. Sign in to https://rstudio.scholar.rcac.purdue.edu (with BoilerKey). Projects in The Data Mine should all be submitted using our template found here or on Scholar (/class/datamine/apps/templates/project_template.Rmd). Open the project template and save it into your home directory, in a new RMarkdown file named project01.Rmd. Prior to running any Python code, run datamine_py() in the R console, just like you did at the beginning of every project from the first semester. Code chunks are parts of the RMarkdown file that contains code. You can identify what type of code a code chunk contains by looking at the engine in the curly braces &quot;{&quot; and &quot;}&quot;. As you can see, it is possible to mix and match different languages just by changing the engine. Move the solutions for questions 1-3 to your project01.Rmd. Make sure to place all Python code in python code chunks. Run the python code chunks to ensure you get the same results as you got when running the Python code in a Jupyter Notebook. Important note: Make sure to run datamine_py() in the R console prior to attempting to run any Python code. Hint: The end result of the project01.Rmd should look similar to this. Item(s) to submit: project01.Rmd with the solutions from questions 1-3 (including any Python code in python code chunks). 5. It is not a Data Mine project without data! Here are some examples of reading in data line by line using the csv package. How many columns are in the following dataset: /class/datamine/data/open_food_facts/openfoodfacts.tsv? Print the first row, the number of columns, and then exit the loop after the first iteration using the break keyword. Hint: You can get the number of elements in a list by using the len method. For example: len(my_list). Hint: You can use the break keyword to exit a loop. As soon as break is executed, the loop is exited and the code immediately following the loop is run. for my_row in my_csv_reader: print(my_row) break print(&quot;Exited loop as soon as &#39;break&#39; was run.&quot;) Hint: '\\t' represents a tab in Python. Relevant topics: for loops, break, print Item(s) to submit: project01.Rmd with the solutions from questions 1-3 (including any Python code in python code chunks). 6 (optional). Unlike in R, where many of the tools you need are built-in (read.csv, data.frames, etc.), in Python, you will need to rely on packages like numpy and pandas to do the bulk of your data science work. In R it would be really easy to find the mean of the 151st column, caffeine_100g: myDF &lt;- read.csv(&quot;/class/datamine/data/open_food_facts/openfoodfacts.tsv&quot;, sep=&quot;\\t&quot;, quote=&quot;&quot;) mean(myDF$caffeine_100g, na.rm=T) # 2.075503 If you were to try to modify our loop from question (5) to do the same thing, you will run into a myriad of issues, just to try and get the mean of a column. Luckily, it is easy to do using pandas: import pandas as pd myDF = pd.read_csv(&quot;/class/datamine/data/open_food_facts/openfoodfacts.tsv&quot;, sep=&quot;\\t&quot;) myDF[&quot;caffeine_100g&quot;].mean() # 2.0755028571428573 Take a look at some of the methods you can perform using pandas here. Perform an interesting calculation in R, and replicate your work using pandas. Which did you prefer, Python or R? Item(s) to submit: R code used to solve the problem. Python code used to solve the problem. Project 2 Motivation: In Python it is very important to understand some of the data types in a little bit more depth than you would in R. Many of the data types in Python will seem very familiar. A character in R is similar to a str in Python. An integer in R is an int in Python. A numeric in R is similar to a float in Python. A logical in R is similar to a bool in Python. In addition to all of that, there are some very popular classes that packages like numpy and pandas introduces. On the other hand, there are some data types in Python like tuples, lists, sets, and dicts that diverge from R a little bit more. It is integral to understand some basic concepts before jumping too far into everything. Context: This is the second project introducing some basic data types, and demonstrating some familiar control flow concepts, all while digging right into a dataset. Scope: tuples, lists, if statements, opening files Learning objectives: List the differences between lists &amp; tuples and when to use each. Gain familiarity with string methods, list methods, and tuple methods. Demonstrate the ability to read and write data of various formats using various packages. Make sure to read about, and use the template found here, and the important information about projects submissions here. Dataset The following questions will use the dataset found in Scholar: /class/datamine/data/craigslist/vehicles.csv Questions 1. Read in the dataset /class/datamine/data/craigslist/vehicles.csv into a pandas DataFrame called myDF. pandas is an integral tool for various data science tasks in Python. You can read a quick intro here. We will be slowly introducing bits and pieces of this package throughout the semester. Similarly, we will try to introduce byte-sized (ha!) portions of plotting packages to slowly build up your skills. How big is the dataset (in Mb or Gb)? Hint: Remember to check out a question's relevant topics. We try very hard to link you to content and examples that will get you up and running as quickly as possible. Relevant topics: pandas read_csv, get filesize in Python Item(s) to submit: Python code used to solve the problem. 2. In question (1) we read in our data into a pandas DataFrame. Use one of the pandas DataFrame attributes to get the number of columns and rows of our dataset. How many columns and rows are there? Use f-strings to print a message, for example: There are 123 columns in the DataFrame! There are 321 rows in the DataFrame! In project 1, we learned how to read a csv file in, line-by-line, and print values. Use the csv package to print just the first row, which should contain the names of the columns. Repeat this process, but instead of using the csv package, use one of the attributes from myDF (to print the column names). Relevant topics: csv read csv, pandas DataFrame, f-strings, break Item(s) to submit: The output from printing the f-strings. Python code used to solve the problem. 3. Use the csv package to get a list called our_columns that contains the column names. Add a string, &quot;extra&quot;, to the end of our_columns. Print the second value in the list. Without using a loop, print the 1st, 3rd, 5th, etc. values in the list. &quot;state&quot;, &quot;lat&quot;, &quot;long&quot;, and now &quot;extra&quot; should be the last values in the list. Print them out by accessing their negative index. &quot;extra&quot; doesn't belong in our list, you can easily remove this value from our list by doing the following: our_columns.pop(25) # or even this, as pop removes the last value by default our_columns.pop() The problem with this solution is you must know the index of the value you'd like to remove. This isn't always ideal. Instead, use a list method to remove &quot;extra&quot; by value rather than by index. Relevant topics: csv read csv, break, append, indexing Item(s) to submit: Python code used to solve the problem. The output from running your code. 4. matplotlib is one of the primary plotting packages in Python. You are provided with the following code: my_values = tuple(myDF.loc[:, &#39;odometer&#39;].dropna().to_list()) The result is a tuple containing the odometer readings from all of the vehicles in our dataset. Create a lineplot of the odometer readings. Well, that plot doesn't seem too informative. Let's first sort the values in our tuple: my_values.sort() What happened? A tuple is immutable. What this means is that once the contents of a tuple are declared they cannot be modified. For example: # This will fail because tuples are immutable my_values[0] = 100 You can read a good article about this here. In addition, here is a great post that gives you an idea when using a tuple might be a good idea. Okay, so let's go back to our problem. We know that lists are mutable (and therefore sortable), so convert my_values to a list and then sort, and re-plot. It looks like there are some (potential) outliers that are making our plot look a little wonky. For the sake of seeing how the plot would look, use negative indexing to plot the sorted values minus the last 50 values (the 50 highest values). Hint: To prevent plotting values on the same plot, close your plot with the close method, for example: import matplotlib.pyplot as plt my_values = [1,2,3,4,5] plt.plot(my_values) plt.show() plt.close() Relevant topics: list methods, indexing, matplotlib Item(s) to submit: Python code used to solve the problem. The output from running your code. 5. We've covered a lot in this project! Use what you've learned so far to do one (or more) of the following tasks: - Create a cool graphic using matplotlib, that summarizes some data from our dataset. - Use pandas and your investigative skills to sift through the dataset and glean an interesting factoid. - Create some commented coding examples that highlight the differences between lists and tuples. Include at least 3 examples. Relevant topics: pandas, indexing, matplotlib Item(s) to submit: Python code used to solve the problem. The output from running your code. Project 3 Motivation: dicts or dictionaries, are one of the most useful data structures in Python. You can think about them as a data structure containing key: value pairs. Under the hood, dicts are essentially a data structure called a hash table. Hash tables are a data structure with a useful set of properties. Searching, inserting, or removing a piece of data is usually constant, meaning that no matter how big your hash table grows to be, inserting, searching, or deleting a piece of data will usually take about the same amount of time, and in the worse case, increase linearly in time. dicts are used a lot, so it is worthwhile to understand them. Although not used quite as often, another important data type called sets, is also worthwhile learning about. Context: This is the third project introducing some basic data types, and demonstrating some familiar control flow concepts, all while digging right into a dataset. Throughout the course we will slowly introduce concepts from pandas, and popular plotting packages. Scope: dicts, sets, if/else statements, opening files, tuples, lists Learning objectives: Explain what is a dict is and why it is useful. Understand how a set works and when it could be useful. List the differences between lists &amp; tuples and when to use each. Gain familiarity with string methods, list methods, and tuple methods. Gain familiarity with dict methods. Make sure to read about, and use the template found here, and the important information about projects submissions here. Dataset The following questions will use the dataset found in Scholar: /class/datamine/data/craigslist/vehicles.csv Questions 1. In project 2 we learned how to read in data using pandas. Read in the (/class/datamine/data/craigslist/vehicles.csv) dataset into a DataFrame called myDF using pandas. In R we can get a sneak peek at the data by doing something like: head(myDF) # where myDF is a data.frame There is a very similar (and aptly named method) that allows us to do the exact same thing with a pandas DataFrame. Get the head of myDF, and take a moment to consider how much time it would take to get this information if we didn't have this nice method. Relevant topics: pandas read_csv Item(s) to submit: Python code used to solve the problem. The head of the dataset. 2. Dictionaries, often referred to as dicts, are really powerful. There are two primary ways to &quot;get&quot; information from a dict. One is to use the get method, the other is to use square brackets and strings. Test out the following to understand the differences between the two: my_dict = {&quot;fruits&quot;: [&quot;apple&quot;, &quot;orange&quot;, &quot;pear&quot;], &quot;person&quot;: &quot;John&quot;, &quot;vegetables&quot;: [&quot;carrots&quot;, &quot;peas&quot;]} # If &quot;person&quot; is indeed a key, they will function the same way my_dict[&quot;person&quot;] my_dict.get(&quot;person&quot;) # If the key does not exist, like below, they will not # function the same way. my_dict.get(&quot;height&quot;) # Returns None when key doesn&#39;t exist my_dict[&quot;height&quot;] # Throws a KeyError exception because the key, &quot;height&quot; doesn&#39;t exist Look at the dataset. Let's say that we want to prepare a subset of this data to create a graphic. Specifically, let's say we want to create a barplot that shows the number of vehicles on craigslist by year of make. Create a dict called my_dict that contains key:value pairs where the keys are years, and the values are a single int representing the number of vehicles from that year on craigslist. Use the year column, a loop, and a dict to accomplish this. Print the dictionary. You can use the following code to extract the year column as a list. In the next project we will learn how to loop over pandas DataFrames. years = myDF[&#39;year&#39;].dropna().to_list() Hint: If you get a KeyError, remember, you must declare each key value pair just like any other variable. Use the following code to initialize each year key to the value 0. years = myDF[&#39;year&#39;].dropna().to_list() # get a list containing each unique year unique_years = list(set(years)) # for each year (key), initialize the value (value) to 0 my_dict = {} for year in unique_years: my_dict[year] = 0 Hint: Here are some of the results you should get: print(my_dict[1912]) # 5 print(my_dict[1982]) # 185 print(my_dict[2014]) # 31703 Note: There is a special kind of dict called a defaultdict, that allows you to give default values to a dict, giving you the ability to &quot;skip&quot; initialization. We will show you this when we release the solutions! Relevant topics: dicts Item(s) to submit: Python code used to solve the problem. my_dict printed. 3. After completing question (2) you can easily access the number of vehicles from a given year. For example, to get the number of vehicles on craigslist from 1912, just run: my_dict[1912] # or my_dict.get(1912) dicts store data in key:value pairs. Identify a &quot;key&quot; from my_dict, as well as the associated &quot;value&quot;. As you can imagine, having data in this format can be very beneficial. One benefit is the ability to easily create a graphic using matplotlib. Use matplotlib to create a bar graph with the year on the x-axis, and the number of vehicles from that year on the y-axis. Hint: To use matplotlib, first import it: import matplotlib.pyplot as plt # now you can use it, for example plt.plot([1,2,3,1]) plt.show() Hint: The keys method and values method from dict could be useful here. Relevant topics: dicts, matplotlib Item(s) to submit: Python code used to solve the problem. The resulting plot. A sentence giving an example of a &quot;key&quot; and associated &quot;value&quot; from my_dict. 4. In the hint in question (3), we used a set to quickly get a list of unique years in a list. Some other common uses of sets are when you want to get a list of values that are in one list but not another, or get a list of values that are present in both lists. Examine the following code. You'll notice that we are looping over many values. Replace the code with code that uses no loops whatsoever. listA = [1, 2, 3, 4, 5, 6, 12, 12] listB = [2, 1, 7, 7, 7, 2, 8, 9, 10, 11, 12, 13] # values in list A but not list B onlyA = [] for valA in listA: if valA not in listB and valA not in onlyA: onlyA.append(valA) print(onlyA) # [3, 4, 5, 6] # values in listB but not list A onlyB = [] for valB in listB: if valB not in listA and valB not in onlyB: onlyB.append(valB) print(onlyB) # [7, 8, 9, 10, 11, 13] # values in both lists in_both_lists = [] for valA in listA: if valA in listB and valA not in in_both_lists: in_both_lists.append(valA) for valB in listB: if valB in listA and valB not in in_both_lists: in_both_lists.append(valB) print(in_both_lists) # [1,2,12] Hint: You should use sets. Note: In addition to being easier to read, sets are much faster than loops! Relevant topics: sets Item(s) to submit: Python code used to solve the problem. The output from running the code. 5. The value of a dictionary does not have to be a single value (like we've shown so far). It can be anything. Observe that there is latitude and longitude data for each row in our DataFrame (lat and long, respectively). Wouldn't it be useful to be able to quickly &quot;get&quot; pairs of latitude and longitude data for a given state? First, run the following code to get a list of tuples where the first value is the state, the second value is the lat, and the third value is the long. states_list = list(myDF.loc[:, [&quot;state&quot;, &quot;lat&quot;, &quot;long&quot;]].dropna().to_records(index=False)) states_list[0:3] # [(&#39;az&#39;, 34.4554, -114.269), (&#39;or&#39;, 46.1837, -123.824), (&#39;sc&#39;, 34.9352, -81.9654)] # to get the first tuple states_list[0] # (&#39;az&#39;, 34.4554, -114.269) # to get the first value in the first tuple states_list[0][0] # az # to get the second tuple states_list[1] # (&#39;or&#39;, 46.1837, -123.824) # to get the first value in the second tuple states_list[1][0] # or Now, organize the latitude and longitude data in a dictionary called geoDict such that each state from the state column is a key, and the respective value is a list of tuples, where the first value in each tuple is the latitude (lat) and the second value is the longitude (long). For example: geoDict.get(&quot;in&quot;)[0:2] # [(39.0295, -86.8675), (38.8585, -86.4806)] len(geoDict.get(&quot;in&quot;)) # 5687 Now that you can easily access latitude and longitude pairs for a given state, run the following code to plot the points for Texas (state == tx). Include the the graphic produced below in your solution, but feel free to experiment with other states. from shapely.geometry import Point import geopandas as gpd from geopandas import GeoDataFrame usa = gpd.read_file(&#39;/class/datamine/data/craigslist/cb_2018_us_state_20m.shp&#39;) usa.crs = {&#39;init&#39;: &#39;epsg:4269&#39;} pts = [Point(y,x) for x, y in geoDict.get(&quot;tx&quot;)] gdf = gpd.GeoDataFrame(geometry=pts, crs = 4269) fig, gax = plt.subplots(1, figsize=(10,10)) base = usa[usa[&#39;NAME&#39;].isin([&#39;Hawaii&#39;, &#39;Alaska&#39;, &#39;Puerto Rico&#39;]) == False].plot(ax=gax, color=&#39;white&#39;, edgecolor=&#39;black&#39;) gdf.plot(ax=base, color=&#39;darkred&#39;, marker=&quot;*&quot;, markersize=10) plt.show() # to save to jpg: plt.savefig(&#39;q5.jpg&#39;) Relevant topics: dicts, lists and tuples Item(s) to submit: Python code used to solve the problem. Graphic produced for the given state. 6. Use your new skills to extract some sort of information from our dataset and create a graphic. This can be an simple or complicated as you are comfortable with! Relevant topics: dicts, lists and tuples Item(s) to submit: Python code used to solve the problem. The graphic produced using the code. Project 4 Motivation: We've now been introduced to a variety of core Python data structures. Along the way we've touched on a bit of pandas, matplotlib, and have utilized some control flow features like for loops, if statements. We will continue to touch on pandas and matplotlib, but we will take a deeper dive in this project and learn more about control flow, all while digging into the data! Context: We just finished a project where we were able to see the power of dictionaries and sets. In this project we will take a step back and make sure we are able to really grasp control flow (if/else statements, loops, etc.) in Python. Scope: python, dicts, lists, if/else statements, for loops Learning objectives: List the differences between lists &amp; tuples and when to use each. Explain what is a dict and why it is useful. Demonstrate a working knowledge of control flow in python: if/else statements, while loops, for loops, etc. Make sure to read about, and use the template found here, and the important information about projects submissions here. Dataset The following questions will use the dataset found in Scholar: /class/datamine/data/craigslist/vehicles.csv Questions 1. Unlike in R, where traditional loops are rare and typically accomplished via one of the apply functions, in Python, loops are extremely common and important to understand. In Python, any iterator can be looped over. Some common iterators are: tuples, lists, dicts, sets, pandas Series, and pandas DataFrames. In the previous project we had some examples of looping over lists, let's learn how to loop over pandas Series and Dataframes! Load up our dataset /class/datamine/data/craigslist/vehicles.csv into a DataFrame called myDF. In project (3), we organized the latitude and longitude data in a dictionary called geoDict such that each state from the state column is a key, and the respective value is a list of tuples, where the first value in each tuple is the latitude (lat) and the second value is the longitude (long). Repeat this question, but do not use lists, instead use pandas to accomplish this. Relevant topics: Item(s) to submit: Python code used to solve the problem. Output from running your code. 2. Wow! The solution to question (1) was slow. In general, you'll want to avoid looping over large DataFrames. Here is a pretty good explanation of why, as well as a good system on what to try when computing something. In this case, we could have used indexing to get latitude and longitude values for each state, and would have no need to build this dict. Regardless, we now have an opportunity to practice iterating over a dictionary, list, and tuple, all at once! Loop through geoDict and use f-strings to print the state abbreviation. Print the first latitude and longitude pair, as well as every 5000th latitude and longitude pair for each state. Round values to the hundreths place. For example, if the state was &quot;pu&quot;, and it had 12000 latitude and longitude pairs, we would print the following: pu: Lat: 41.41, Long: 41.41 Lat: 22.21, Long: 21.21 Lat: 11.11, Long: 10.22 In the above example, Lat: 41.41, Long: 41.41 would be the first pair, Lat: 22.21, Long: 21.21 would be the 5000th pair, and Lat: 11.11, Long: 10.22 would be the 10000th pair. Make sure to use f-strings to round the latitude and longitude values to two decimal places. Hint: Enumerate is a useful function that adds an index to our loop. Hint: Using and if statement and the modulo operator could be useful. Note: Whenever we have a loop within another loop, the &quot;inner&quot; loop is called a &quot;nested&quot; loop, as it is &quot;nested&quot; inside of the other. Relevant topics: Item(s) to submit: Python code used to solve the problem. Output from running your code. 3. We are curious about how the year of the car (year) effects the price (price). In R, we could get the median price by year easily, using tapply: tapply(myDF$price, myDF$year, median, na.rm=T) Using pandas, we would do this: res = myDF.groupby([&#39;year&#39;], dropna=True).median() These are very convenient functions that do a lot of work for you. If we were to take a look at the median price of cars by year, it would look like: import matplotlib.pyplot as plt res = myDF.groupby([&#39;year&#39;], dropna=True).median()[&quot;price&quot;] plt.bar(res.index, res.values) Using just the pandas code provided below, and no other pandas code, calculate the median price by year. Replicate the plot generated by running the code above, using your calculated median values. my_list = list(myDF.loc[:, [&quot;year&quot;, &quot;price&quot;,]].dropna().to_records(index=False)) Relevant topics: Item(s) to submit: Python code used to solve the problem. Output from running your code. The barplot. 4. Now, calculate the mean price by year, and create a barplot with the price on the y-axis and year on the x-axis. Whoa! Something is odd here. Explain what is happening. Modify your code to use an if statement to &quot;weed out&quot; the likely erroneous value. Re-plot your values. Relevant topics: Item(s) to submit: Python code used to solve the problem. Output from running your code. The barplot. 5. List comprehensions are a neat feature of Python that allows for a more concise syntax for smaller loops. While at first they may seem difficult and more confusing, eventually they grow on you. For example, say you wanted to capitalize every state in a list full of states: my_states = myDF[&#39;state&#39;].to_list() my_states = [state.upper() for state in my_states] Or, maybe you wanted to find the average price of cars in &quot;excellent&quot; condition (without pandas): my_list = list(myDF.loc[:, [&quot;condition&quot;, &quot;price&quot;,]].dropna().to_records(index=False)) my_list = [price for (condition, price) in my_list if condition == &quot;excellent&quot;] sum(my_list)/len(my_list) Do the following using list comprehensions, and the provided code: my_list = list(myDF.loc[:, [&quot;state&quot;, &quot;price&quot;,]].dropna().to_records(index=False)) Calculate the average price of vehicles from Indiana (in). Calculate the average price of vehicles from Indiana (in), Michigan (mi), and Illinois (il) combined. my_list = list(myDF.loc[:, [&quot;manufacturer&quot;, &quot;year&quot;, &quot;price&quot;,]].dropna().to_records(index=False)) Calculate the average price of a &quot;honda&quot; (manufacturer) that is 2010 or newer (year). Relevant topics: Item(s) to submit: Python code used to solve the problem. Output from running your code. 6. Let's use a package called spacy to try and parse phone numbers out of the description column. First, simply loop through and print the text and the label. What is the label of the majority of the phone numbers you can see? import spacy # get list of descriptions my_list = list(myDF.loc[:, [&quot;description&quot;,]].dropna().to_records(index=False)) my_list = [m[0] for m in my_list] # load the pre-built spacy model nlp = spacy.load(&quot;en_core_web_lg&quot;) # apply the model to a description doc = nlp(my_list[0]) # print the text and label of each &quot;entity&quot; for entity in doc.ents: print(entity.text, entity.label_) Use an if statement to filter out all entities that are not the label you see. Loop through again and see what our printed data looks like. There is still a lot of data there that we don't want to capture, right? Phone numbers in the US are usually 7 (5555555), 8 (555-5555), 10 (5555555555), 11 (15555555555), 12 (555-555-5555), or 14 (1-555-555-5555) digits. In addition to your first &quot;filter&quot;, add another &quot;filter&quot; that keeps only text where the text is one of those lengths. That is starting to look better, but there are still some erroneous values. Come up with another &quot;filter&quot;, and loop through our data again. Explain what your filter does and make sure that it does a better job on the first 10 documents than when we don't use your filter. Note: It can be fun to utilize machine learning and natural language processing, but that doesn't mean it is always the best solution! We could get rid of all of our filters and use regular expressions with much better results! We will demonstrate this in our solution. Relevant topics: Item(s) to submit: Python code used to solve the problem. Output from running your code. 1-2 sentences explaining what your filter does. Project 5 Motivation: Up until this point we've utilized bits and pieces of the pandas library to perform various tasks. In this project we will formally introduce pandas and numpy, and utilize their capabilities to solve data-driven problems. Context: By now you'll have had some limited exposure to pandas. This is the first in a three project series that covers some of the main components of both the numpy and pandas libraries. We will take a two project intermission to learn about functions, and then continue. Scope: python, pandas, numpy, DataFrames, Series, ndarrays, indexing Learning objectives: Distinguish the differences between numpy, pandas, DataFrames, Series, and ndarrays. Use numpy, scipy, and pandas to solve a variety of data-driven problems. Demonstrate the ability to read and write data of various formats using various packages. View and access data inside DataFrames, Series, and ndarrays. Make sure to read about, and use the template found here, and the important information about projects submissions here. Dataset The following questions will use the dataset found in Scholar: /class/datamine/data/stackoverflow/unprocessed/2018.csv Questions 1. Take a look at the pandas docs. There are a lot of formats that pandas has the ability to read. The most popular formats in this course are: csv (with commas or some other separator), excel, json, or some database. CSV is very prevalent, but it was not designed to work well with large amounts of data. Newer formats like parquet and feather are designed from the ground up to be efficient, and take advantage of special processor instruction set called SIMD. The benefits of using these formats can be significant. Let's do some experiments! How much space do each of the following files take up on Scholar: 2018.csv, 2018.parquet, and 2018.feather? How much smaller (as a percentage) is the parquet file than the csv? How much smaller (as a percentage) is the feather file than the csv? Use f-strings to format the percentages. Time reading in the following files: 2018.csv, 2018.parquet, and 2018.feather. How much faster (as a percentage) is reading the parquet file than the csv? How much faster (as a percentage) is reading the feather file than the csv? Use f-strings to format the percentages. To time a piece of code, you can use the block-timer package: from block_timer.timer import Timer with Timer(title=&quot;Using dict to declare a dict&quot;) as t1: my_dict = dict() with Timer(title=&quot;Using {} to declare a dict&quot;) as t2: my_dict = {} # or if you need more fine-tuned values print(t1.elapsed) print(t2.elapsed) Read the 2018.csv file into a pandas DataFrame called my2018. Time writing the contents of my2018 to the following files: 2018.csv, 2018.parquet, and 2018.feather. Write the files to your scratch directory: /scratch/scholar/&lt;username&gt;, where &lt;username&gt; is your username. How much faster (as a percentage) is reading the parquet file than the csv? How much faster (as a percentage) is reading the feather file than the csv? Use f-strings to format the percentages. Relevant topics: Item(s) to submit: Python code used to solve the problem. Output from running your code. 2. A method is just a function associated with an object or class. For example, mean is just a method of the pandas DataFrame: # myDF is an object of class DataFrame # mean is a method of the DataFrame class myDF.mean() ## Series([], dtype: float64) In pandas there are two main methods used for indexing: loc and iloc. Use the column Student and indexing in pandas to calculate what percentage of respondents are students and not students. Consider the respondent to be a student if the Student column is anything but &quot;No&quot;. Create a new DataFrame called not_students that is a subset of the original dataset without students. Relevant topics: Item(s) to submit: Python code used to solve the problem. Output from running your code. 3. In pandas, if you were to isolate a single column using indexing, like this: myDF.loc[:, &quot;Student&quot;] The result would be a pandas Series. A Series is the 1-dimensional equivalent of a DataFrame. type(myDF.loc[:, &quot;Student&quot;]) # pandas.core.series.Series pandas and numpy make it very easy to convert between a Series, ndarray, and list. Here is a very useful graphic to highlight how to do this. Look at the DevType column in not_students. As you can see, a single value may contain a list of semi-colon-separated professions. Create a list with a unique group of all the possible professions. Consider each semi-colon-separated value a profession. How many professions are there? It looks like somehow the profession &quot;Student&quot; got in there even though we filtered by the Student column. Use myDF to get a subset of our data for which the respondents replied &quot;No&quot; to Student, yet put &quot;Student&quot; as a DevType. How many respondents are in that subset? Hint: See here. Relevant topics: Item(s) to submit: Python code used to solve the problem. Output from running your code. The number of professions there are. The number of respondents that replied &quot;No&quot; to Student, yet put &quot;Student&quot; as the DevType. 4. As you can see, while perhaps a bit more strict, indexing in pandas is not that much more difficult than indexing in R. While not always necessary, remembering to put &quot;:&quot; to indicate &quot;all columns&quot; or &quot;all rows&quot; makes life easier. In addition, remembering to put parentheses around logical groupings is also a good thing. Practice makes perfect! Randomly select 100 males and 100 females. How many of each sample is in each Age category? (Do not use the sample method yet, but instead use numeric indexing and random) import random print(f&quot;A random integer between 1 and 100 is {random.randint(1, 101)}&quot;) ## A random integer between 1 and 100 is 86 It would be nice to visualize these results. pandas Series have some built in methods to create plots. Use [this] method to generate a bar plot for both males and females. How do they compare? Hint: You may need to import matplotlib in order to display the graphic: import matplotlib.pyplot as plt # female barplot code here plt.show() # male barplot code here plt.show() Hint: Once you have your male and female DataFrames, the value_counts method found here may be particularly useful. Relevant topics: Item(s) to submit: Python code used to solve the problem. Output from running your code. 5. pandas really helps out when it comes to working with data in Python. This is really cool dataset, use your newfound skills to do a mini-analysis. Your mini-analysis should include 1 or more graphics, along with some interesting observation you made while exploring the data. Relevant topics: Item(s) to submit: Python code used to solve the problem. Output from running your code. A graphic. 1-2 sentences explaining your interesting observation and graphic. STAT 29000 Project 1 Motivation: Extensible Markup Language or XML is a very important file format for storing structured data. Even though formats like JSON, and csv tend to be more prevalent, many, many legacy systems still use XML, and it remains an appropriate format for storing complex data. In fact, JSON and csv are quickly becoming less relevant as new formats and serialization methods like parquet and protobufs are becoming more common. Context: In previous semesters we've explored XML. In this project we will refresh our skills and, rather than exploring XML in R, we will use the lxml package in Python. This is the first project in a series of 5 projects focused on web scraping in R and Python. Scope: python, XML Learning objectives: Review and summarize the differences between XML and HTML/CSV. Match XML terms to sections of XML demonstrating working knowledge. Make sure to read about, and use the template found here, and the important information about projects submissions here. Dataset The following questions will use the dataset found in Scholar: /class/datamine/data/apple/health/watch_dump.xml Resources We realize that for many of you this is a big &quot;jump&quot; right into Python. Don't worry! Python is a very intuitive language with a clean syntax. It is easy to read and write. We will do our very best to keep things as straightforward as possible, especially in the early learning stages of the class. We will be actively updating the examples book with videos and more examples throughout the semester. Ask a question in Piazza and perhaps we will add an example straight to the book to help out. Some potentially useful resources for the semester include: The STAT 19000 projects. We are easing 19000 students into Python and will post solutions each week. It would be well worth 10 minutes to look over the questions and solutions each week. Here is a decent cheat sheet that helps you quickly get an idea of how to do something you know how to do in R, in Python. The Examples Book -- updating daily with more examples and videos. Be sure to click on the &quot;relevant topics&quot; links as we try to point you to topics with examples that should be particularly useful to solve the problems we assign. Questions 1. A good first step when working with XML is to get an idea how your document is structured. Normally, there should be good documentation that spells this out for you, but it is good to know what to do when you don't have the documentation. Start by finding the &quot;root&quot; node. What is the name of the root node of the provided dataset? Hint: Make sure to import the lxml package first: from lxml import etree Relevant topics: lxml, xml Item(s) to submit: Python code used to solve the problem. Output from running your code. 2. Remember, XML can be nested. In question (1) we figured out what the root node was called. What are the names of the next &quot;tier&quot; of elements? Hint: Now that we know the root node, you could use the root node name as a part of your xpath expression. Hint: As you may have noticed in question (1) the xpath method returns a list. Sometimes this list can contain many repeated tag names. Since our goal is to see the names of the second &quot;tier&quot; elements, you could convert the resulting list to a set to quickly see the unique list as set's only contain unique values. Relevant topics: for loops, lxml, xml Item(s) to submit: Python code used to solve the problem. Output from running your code. 3. Continue to explore each &quot;tier&quot; of data until there isn't any left. Name the &quot;full paths&quot; of all of the &quot;last tier&quot; tags. Hint: Let's say a &quot;last tier&quot; tag is just a path where there are no more nested elements. For example, /HealthData/Workout/WorkoutRoute/FileReference is a &quot;last tier&quot; tag. If you try and get the nested elements for it, they don't exist: tree.xpath(&quot;/HealthData/Workout/WorkoutRoute/FileReference/*&quot;) Hint: Here are 3 of the 7 &quot;full paths&quot;: /HealthData/Workout/WorkoutRoute/FileReference /HealthData/Record/MetadataEntry /HealthData/ActivitySummary Relevant topics: lxml, xml, for loops Item(s) to submit: Python code used to solve the problem. Output from running your code. 4. At this point in time you may be asking yourself &quot;but where is the data&quot;? Depending on the structure of the XML file, the data could either be between tags like: &lt;some_tag&gt;mydata&lt;/some_tag&gt; Or, it could be in an attribute: &lt;question answer=&quot;tac&quot;&gt;What is cat spelled backwards?&lt;/question&gt; Collect the &quot;ActivitySummary&quot; data, and convert the list of dicts to a pandas DataFrame. The following is an example of converting a list of dicts to a pandas DataFrame called myDF: import pandas as pd list_of_dicts = [] list_of_dicts.append({&#39;columnA&#39;: 1, &#39;columnB&#39;: 2}) list_of_dicts.append({&#39;columnB&#39;: 4, &#39;columnA&#39;: 1}) myDF = pd.DataFrame(list_of_dicts) Hint: It is important to note that an element's &quot;attrib&quot; attribute looks and feels like a dict, but it is actually a lxml.etree._Attrib. If you try to convert a list of lxml.etree._Attrib to a pandas DataFrame, it will not work out as you planned. Make sure to first convert each lxml.etree._Attrib to a dict before converting to a DataFrame. You can do so like: # this will convert a single `lxml.etree._Attrib` to a dict my_dict = dict(my_lxml_etree_attrib) pandas is a Python package that provides the DataFrame and Series classes. A DataFrame is very similar to a data.frame in R and can be used to manipulate the data within very easily. A Series is the class that handles a single column of a DataFrame. Go through the pandas in 10 minutes page from the official documentation. Sort, find, and print the top 5 rows of data based on the &quot;activeEnergyBurned&quot; column. Relevant topics: pandas, dicts, lists, lxml, xml, for loops Item(s) to submit: Python code used to solve the problem. Output from running your code. 5. Whether or not you ever use XML extensively, I tend to find xpath expressions easier and more concise to use than css selectors, and in the next few projects where we are scraping and parsing data, you'll get to practice a lot. You still have a relatively interesting dataset at your disposal. Parse through more of the data, or use the myDF DataFrame, and create an interesting graphic using matplotlib. This plot could be anything -- it is just to get your feet wet with a new package. Hint: Make sure to import matplotlib: import matplotlib.pyplot as plt Hint: You can find a variety of examples here in the official documentation. In addition, you can find some examples in the book. Relevant topics: matplotlib Item(s) to submit: Python code used to solve the problem. Output from running your code (the graphic). STAT 39000 Project 1 Motivation: Extensible Markup Language or XML is a very important file format for storing structured data. Even though formats like JSON, and csv tend to be more prevalent, many, many legacy systems still use XML, and it remains an appropriate format for storing complex data. In fact, JSON and csv are quickly becoming less relevant as new formats and serialization methods like parquet and protobufs are becoming more common. Context: In previous semesters we've explored XML. In this project we will refresh our skills and, rather than exploring XML in R, we will use the lxml package in Python. This is the first project in a series of 5 projects focused on web scraping in R and Python. Scope: python, XML Learning objectives: Review and summarize the differences between XML and HTML/CSV. Match XML terms to sections of XML demonstrating working knowledge. Make sure to read about, and use the template found here, and the important information about projects submissions here. Dataset The following questions will use the dataset found in Scholar: /class/datamine/data/apple/health/watch_dump.xml Resources We realize that it may be a while since you've used Python. That's okay! We are going to be taking things at a much more reasonable pace than Spring 2020. Some potentially useful resources for the semester include: The STAT 19000 projects. We are easing 19000 students into Python and will post solutions each week. It would be well worth 10 minutes to look over the questions and solutions each week. Here is a decent cheat sheet that helps you quickly get an idea of how to do something you know how to do in R, in Python. The Examples Book -- updating daily with more examples and videos. Be sure to click on the &quot;relevant topics&quot; links as we try to point you to topics with examples that should be particularly useful to solve the problems we assign. Questions 1. A good first step when working with XML is to get an idea how your document is structured. Normally, there should be good documentation that spells this out for you, but it is good to know what to do when you don't have the documentation. Start by finding the &quot;root&quot; node. What is the name of the root node of the provided dataset? Hint: Make sure to import the lxml package first: from lxml import etree Relevant topics: lxml, xml Item(s) to submit: Python code used to solve the problem. Output from running your code. 2. Remember, XML can be nested. In question (1) we figured out what the root node was called. What are the names of the next &quot;tier&quot; of elements? Hint: Now that we know the root node, you could use the root node name as a part of your xpath expression. Hint: As you may have noticed in question (1) the xpath method returns a list. Sometimes this list can contain many repeated tag names. Since our goal is to see the names of the second &quot;tier&quot; elements, you could convert the resulting list to a set to quickly see the unique list as set's only contain unique values. Relevant topics: for loops, lxml, xml Item(s) to submit: Python code used to solve the problem. Output from running your code. 3. Continue to explore each &quot;tier&quot; of data until there isn't any left. Name the &quot;full paths&quot; of all of the &quot;last tier&quot; tags. Hint: Let's say a &quot;last tier&quot; tag is just a path where there are no more nested elements. For example, /HealthData/Workout/WorkoutRoute/FileReference is a &quot;last tier&quot; tag. If you try and get the nested elements for it, they don't exist: tree.xpath(&quot;/HealthData/Workout/WorkoutRoute/FileReference/*&quot;) Hint: Here are 3 of the 7 &quot;full paths&quot;: /HealthData/Workout/WorkoutRoute/FileReference /HealthData/Record/MetadataEntry /HealthData/ActivitySummary Relevant topics: lxml, xml, for loops Item(s) to submit: Python code used to solve the problem. Output from running your code. 4. At this point in time you may be asking yourself &quot;but where is the data&quot;? Depending on the structure of the XML file, the data could either be between tags like: &lt;some_tag&gt;mydata&lt;/some_tag&gt; Or, it could be in an attribute: &lt;question answer=&quot;tac&quot;&gt;What is cat spelled backwards?&lt;/question&gt; Collect the &quot;ActivitySummary&quot; data, and convert the list of dicts to a pandas DataFrame. The following is an example of converting a list of dicts to a pandas DataFrame called myDF: import pandas as pd list_of_dicts = [] list_of_dicts.append({&#39;columnA&#39;: 1, &#39;columnB&#39;: 2}) list_of_dicts.append({&#39;columnB&#39;: 4, &#39;columnA&#39;: 1}) myDF = pd.DataFrame(list_of_dicts) Hint: It is important to note that an element's &quot;attrib&quot; attribute looks and feels like a dict, but it is actually a lxml.etree._Attrib. If you try to convert a list of lxml.etree._Attrib to a pandas DataFrame, it will not work out as you planned. Make sure to first convert each lxml.etree._Attrib to a dict before converting to a DataFrame. You can do so like: # this will convert a single `lxml.etree._Attrib` to a dict my_dict = dict(my_lxml_etree_attrib) pandas is a Python package that provides the DataFrame and Series classes. A DataFrame is very similar to a data.frame in R and can be used to manipulate the data within very easily. A Series is the class that handles a single column of a DataFrame. Go through the pandas in 10 minutes page from the official documentation. Sort, find, and print the top 5 rows of data based on the &quot;activeEnergyBurned&quot; column. Relevant topics: pandas, dicts, lists, lxml, xml, for loops Item(s) to submit: Python code used to solve the problem. Output from running your code. 5. Whether or not you ever use XML extensively, I tend to find xpath expressions easier and more concise to use than css selectors, and in the next few projects where we are scraping and parsing data, you'll get to practice a lot. You still have a relatively interesting dataset at your disposal. Parse through more of the data, or use the myDF DataFrame, and create an interesting graphic using matplotlib. This plot could be anything -- it is just to get your feet wet with a new package. Hint: Make sure to import matplotlib: import matplotlib.pyplot as plt Hint: You can find a variety of examples here in the official documentation. In addition, you can find some examples in the book. Relevant topics: matplotlib Item(s) to submit: Python code used to solve the problem. Output from running your code (the graphic). 6. Use your dataframe from (4), myDF, and calculate the average activeEnergyBurned by appleStandHours. Does it appear, anecdotally, that activeEnergyBurned goes up as appleStandHours goes up? Create a bar graph to illustrate. Hint: If you want an easier way to do a simple plot without matplotlib, just using pandas, see this. Hint: If your myDF.dtypes is all &quot;object&quot;, you'll want to convert your columns of interest to the correct data types first: myDF = myDF.astype({&#39;dateComponents&#39;: &#39;datetime64[ns]&#39;, &#39;activeEnergyBurned&#39;: &#39;float64&#39;, &#39;appleStandHours&#39;: &#39;int64&#39;}) Relevant topics: matplotlib, pandas, pandas groupby Item(s) to submit: Python code used to solve the problem. Output from running your code (including the graphic). "],
["contributors.html", "Contributors", " Contributors We are extremely thankful for all of our contributors! Get your name added to the list by making a contribution. "]
]
