= STAT 29000: Project 5 -- Fall 2021

**Motivation:** A bash script is a powerful tool to perform repeated tasks. RCAC uses bash scripts to automate a variety of tasks. In fact, we use bash scripts on Scholar to do things like link Python kernels to your account, fix potential issues with Firefox, etc. `awk` is a programming language designed for text processing. The combination of these tools can be really powerful and useful for a variety of quick tasks. 

**Context:** This is the first part in a series of projects that are designed to exercise skills around UNIX utilities, with a focus on writing bash scripts and `awk`. You will get the opportunity to manipulate data without leaving the terminal. At first it may seem overwhelming, however, with just a little practice you will be able to accomplish data wrangling tasks really efficiently.

**Scope:** awk, UNIX utilities, bash scripts

.Learning Objectives
****
- Use awk to process and manipulate textual data.
- Use piping and redirection within the terminal to pass around data between utilities.
****

Make sure to read about, and use the template found xref:templates.adoc[here], and the important information about projects submissions xref:submissions.adoc[here].

== Dataset(s)

The following questions will use the following dataset(s):

- `/depot/datamine/data/iowa_liquor_sales/iowa_liquor_sales_cleaner.csv`

== Questions

=== Question 1

While the UNIX tools we've used up to this point are very useful, `awk` enables many new capabilities, and can even replace major functionality of other tools.

In a previous question, we asked you to write a command that printed the number of columns in the dataset. Perform the same operation using `awk`.

Similarly, we've used `head` to print the header line. Use `awk` to do the same.

Similarly, we've used `wc` to count the number of lines in the dataset. Use `awk` to do the same.

.Items to submit
====
- Code used to solve this problem.
- Output from running the code.
====

=== Question 2

In a previous question, we used `sort` in combination with `uniq` to find the stores with the most number of sales. 

Use `awk` to find the 10 stores with the most number of sales. In a previous solution, our output was minimal -- we had a count and a store number. This time, take some time to format the output nicely, _and_ use the store number to find the count (not store name).

[TIP]
====
Sorting an array by values in `awk` can be confusing. Check out https://stackoverflow.com/questions/5342782/sort-associative-array-with-awk[this excellent stackoverflow post] to see a couple of ways to do this. "Edit 2" is the easiest one to follow.
====

[NOTE]
====
You can even use the store number to count the number of sales and save the most recent store name for the store number as you go to _print_ the store names with the output.
====

.Items to submit
====
- Code used to solve this problem.
- Output from running the code.
====

=== Question 3

Calculate the total number of sales (in USD) by county. Do this using any UNIX commands you have available. Then, do this using _only_ `awk`.

[TIP]
====
`gsub` is a powerful awk utility that allows you to replace a string with another string. For example, you could replace all `$`'s in field 2 with nothing by:

----
gsub(/\$/, "", $2)
----
====

[NOTE]
====
The `gsub` operation happens in-place. In a nutshell, what this means is that the original field, `$2` is replaced with the result of the `gsub` operation.
====

.Items to submit
====
- Code used to solve this problem.
- Output from running the code.
====

=== Question 4

Use `awk` and piping to create a new dataset with the following columns, for every store, by month:

- `month_number`: the month number (1-12)
- `store_name`: store name
- `volume_sold`: total volume sold
- `sold_usd`: total amount sold in USD

Call the new dataset `sales_by_store.csv`.

[TIP]
====
Feel free to use the store name as a key for simplicity.
====

[TIP]
====
`split` is another powerful function in `awk` that allows you to split a string into multiple fields. You could, for example, extract the year from the date field as follows.

[source,awk]
----
split($2, dates, "/", seps);
----

Then, you can access the year using `dates[3]`.
====

[TIP]
====
You can use multiple values as a key in `awk`. This is a cool trick to count or calculate something by year, for example.

[source,awk]
----
myarray[$4dates[3]]++
----

Here, `$4` is the 4th field, `dates[3]` is the year. The resulting key would be something like "My Store Name2014", and we would have a new key (and associated value) for each store/year combination.
====

.Items to submit
====
- Code used to solve this problem.
- Output from running the code.
====

=== Question 5

Use `awk` to count how many times each store has sold more than $500,000 in a month. Output should be similar to the following. Sort the output from highest count to lowest.

----
store_name,count
----

.Items to submit
====
- Code used to solve this problem.
- Output from running the code.
====

[WARNING]
====
_Please_ make sure to double check that your submission is complete, and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted, was what you _actually_ submitted.
====