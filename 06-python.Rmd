# Python {#python}

## Getting started {#getting-started-with-python}

### Python on Scholar {#python-on-scholar}

Each year we provide students with a working Python kernel that students are able to select and use from within https://notebook.scholar.rcac.purdue.edu/ as well as within an Rmarkdown document in https://rstudio.scholar.rcac.purdue.edu/. We ask that students use this kernel when completing all Python-related questions for the course. This ensures version consistency for Python and all packages that students will use during the academic year. In addition, this enables staff to quickly modify the Python environment for all students should the need arise.

Let's configure this so every time you access https://notebook.scholar.rcac.purdue.edu/ or https://rstudio.scholar.rcac.purdue.edu/, you will have access to the proper kernel, and the default version of python is correct. Navigate to https://rstudio.scholar.rcac.purdue.edu/, and login using your Purdue credentials.  In the menu, click `Tools > Shell...`. 

You should be presented with a shell towards the bottom left. Click within the shell, and type the following followed by pressing Enter or Return:

`/class/datamine/apps/runme`

After executing the script, in the menu, click `Session > Restart R`. 

In order to run Python within https://rstudio.scholar.rcac.purdue.edu/, log in to https://rstudio.scholar.rcac.purdue.edu/ and run the following in the Console or in an R code chunk:

```{r, eval=F}
datamine_py()
install.packages("reticulate")
```

The function `datamine_py` "activates" the Python environment we have setup for the course. Any time you want to use our environment, simply run the R function at the beginning of any R Session, _prior_ to running anything Python code chunks.

To test if the Python environment is working within https://rstudio.scholar.rcac.purdue.edu/, run the following in a Python code chunk:

```{python, eval=F}
import sys
print(sys.executable)
```

The python executable should be located in the appropriate folder in the following path: `/class/datamine/apps/python/`.

The `runme` script also adds a kernel to the list of kernels shown in https://notebook.scholar.rcac.purdue.edu/. 

To test if the kernel is available and working, navigate to https://notebook.scholar.rcac.purdue.edu/, login, click on `New`, and select the kernel matching the current year. For example, you would select `f2020-s2021` for the 2020-2021 academic year. Once the notebook has launched, you can confirm the version of Python by running the following in a code cell:

```{python, eval=F}
import sys
print(sys.executable)
```

The python executable should be located in the appropriate folder in the following path: `/class/datamine/apps/python/`.

If you already have a a Jupyter notebook running at https://notebook.scholar.rcac.purdue.edu/, you may need to refresh in order for the kernel to appear as an option in `Kernel > Change Kernel`.

If you would like to use the Python environment that is put together for this class, from within a terminal on Scholar, run the following:

```{bash, eval=F}
source /class/datamine/apps/python.sh
```

This will load the environment and `python` will launch our environment's interpreter.

## Variables {#p-variables}

Variables are declared just like in R, but rather than using `<-` and `->`, Python uses a single `=` as is customary for most languages. You can declared variables like this:

```{python, eval=T}
my_var = 4
```

Here, we declared a variable with a value of 4.

**Important note:** _Actually_ this is _technically_ not true. Numbers between -5 and 256 (inclusive) are already pre-declared and exist within Python's memory _before_ you assigned the value to `my_var`. The `=` operator simply forces `my_var` to _point_ to that value that already exists! That is right, `my_var` is technically a pointer. 

One extremely important distinction between declaring variables in Python vs. in R is what is actually happening under the hood. Take the following code:

```{python, eval=T}
my_var = 4
new_var = my_var
my_var = my_var + 1
print(f"my_var: {my_var}\nnew_var: {new_var}")

my_var = [4,]
new_var = my_var
my_var[0] = my_var[0] + 1
print(f"my_var: {my_var}\nnew_var: {new_var}")
```

Here, the first chunk of code behaves as expected because `int`s are immutable, meaning the values cannot be changed. As a result, when we assign `my_var = my_var + 1`, `my_var`'s _value_ isn't changing, `my_var` is just being pointed to a different value of 5, which is _not_ where `new_var` points. `new_var` still points to the value of 4.

The second chunk however is dealing with a mutable `list`. We first assign the first value of our list to a value of 4. Then we assign `my_var` to `new_var`. This does _not_ copy the values of `my_var` to `new_var`, but rather `new_var` now points to the same exact object. Then, when we increment the first value in `my_var`, that same change is reflected when we print the value in `new_var`, because `new_var` and `my_var` are the same object, i.e. `new_var is my_var`.

An excellent article that goes into more detail can be found [here](https://realpython.com/pointers-in-python/). 

### None {#p-none}

`None` is a keyword used to define a null value. This would be the Python equivalent to R's `NULL`. If used in an if statement, `None` represents `False`. This does not mean `None` == `False`, in fact:

```{python}
print(None == False)
```

As you can see, although `None` can represent `False` in an if statement, they are _not_ equivalent.

### bool {#p-bool}

A `bool` has two possible values: `True` and `False`. It is important to understand that technically:

```{python}
print(True == 1)
print(False == 0)
```

With that being said, `True` is _not_ equal to numbers greater than 1:

```{python}
print(True == 2)
print(True == 3)
```

With that being said, numbers not equal to 0 evaluate to `True` when used in an if statement:

```{python}
if 3:
  print("3 evaluates to True")
  
if 4:
  print("4 evaluates to True")
  
if -1:
  print("-1 evaluates to True")
```

### str {#p-str}

`str` are strings in Python. Strings are "immutable sequences of Unicode code points". Strings can be surrounded in single quotes, double quotes, or triple quoted (with either single or double quotes):

```{python}
print(f"Single quoted text is type: {type('test')}")
print(f'Double quoted text is type: {type("test")}')
print(f"Triple quoted with single quotes: {type('''This is some text''')}")
print(f'Triple quoted with double quotes: {type("""This is some text""")}')
```

Triple quoted strings can span multiple lines. All associated whitespace will be incorporated in the string:

```{python}
my_string = """This text
spans multiple 
lines."""
print(my_string)
```

But, this would cause an error:

```{python, eval=F}
my_string = "This text, 
will throw an error"
print(my_string)
```

But, you could make it span multiple lines by adding a `\`, but newlines won't be maintained:

```{python, eval=T}
my_string = "This text, \
will throw an error"
print(my_string)
```

### int {#p-int}

`int`'s are whole numbers. For instance:

```{python}
my_var = 5
print(type(my_var))
```

`int`'s can be added, subtracted, and multiplied without changing types. With that being said, division of 2 `int`'s results in a `float` regardless of whether or not the result of the division is a whole number or not:

```{python}
print(type(6+2))
print(type(6-2))
print(type(6*2))
print(type(6/2))
```

Similarly, any calculation between an `int` and `float` results in a `float`:

```{python}
print(type(6+2.0))
print(type(6-2.0))
print(type(6*2.0))
print(type(6/2.0))
```

### float {#p-float}

`float`'s are floating point numbers, or numbers with decimals. 

```{python}
my_var = 5.0
print(type(my_var))
```

`float`'s can be converted back to `int`'s using the `int` function. This _coercion_ causes the `float` to be truncated, regardless of how close to the "next" number the float is:

```{python}
print(int(5.5))
print(int(5.49))
print(int(5.51))
print(int(5.99999))
```

### complex {#p-complex}

`complex`'s represent complex numbers. `j` can be used to represent an imaginary number. `j` must be preceded by a number, like `1j`.

```{python}
my_var = 1j
print(my_var)
print(type(my_var))
```

Arithmetic with a `complex` always results in a `complex`:

```{python, eval=T}
print(type(1j*2))
print(type(1j*2.0))
print(type(1j*1j))
```

You cannot convert to an `int` or `float`:

```{python, eval=F}
print(int(1j*1j))
print(float(1j*1j))
```

#### Resources

**[Pointers in Python](https://realpython.com/pointers-in-python/)**

An excellent article explaining what happens under the hood when declaring variables in Python.

## Printing {#p-printing}

`print` is a function in Python that allows you to... well... print. Printing values and information about a program while the program is running is still to this day one of the best methods to debug your code. This is just one good reason to learn about and feel comfortable with printing.

You can print simple string literals:

```{python, eval=T}
print("This is a simple string literal being printed...")
```

You can print all types of variables, not just strings:

```{python, eval=T}
print(int(4))
print(float(4.4))
print(False)
```
You can even mix and match what you print:

```{python, eval=T}
print("This is a string and an int:", int(4)) # notice there is a space added between the arguments to print
print("This is a string and an int and a float:", int(4), float(4.4))
print(int(4), "<- is an integer")
```

You can even do arithmetic _inside_ the `print` function:

```{python, eval=T}
print("4 + 4 =", 4+4)
```
There are a series of special characters called [escape characters](https://www.w3schools.com/python/gloss_python_escape_characters.asp) that need to be escaped with a `\`, but that represent a different symbol when processed. For example, a newline character is `\n`, but when you print `\n` it results in a new line:

```{python, eval=T}
print("This is line 1.\nThis is line 2.")
```
Here are a couple more escape characters:

```{python, eval=T}
print("This is a carriage return\rAs you can see it is not a visible character.")
print("This is a .\tAnd another.\tAnd now two tabs.\t\tNice.")
```

You may now be wondering, well what if I want to literally print `\t` or `\n`? There are a couple of options:

```{python, eval=T}
print("You can escape a forward slash with another forward slash: \\")
print("This would then look like: \\t \\n")
print(r"You could also add an 'r' before your string. The 'r' represents raw and will render the text literally: \t \n")
```

Similarly, if you want to use double or single quotes within double or single quotes you can escape them as well:

```{python, eval=T}
print("This sentence has \"double quotes\".")
print('This sentence has \'single quotes\'.')
```

Of course, you can mix and match quotes to avoid needing to escape:

```{python, eval=T}
print('Now it is easy to print "double quotes".')
print("Now it is easy to print 'single quotes'.")
```

### f-strings {#p-f-strings}

f-strings are extremely straightforward, useful, and fast. I would highly recommend using f-strings when the need arrives to print something more than simple text.

f-string stands for "format string". An f-string is a string literal that starts with an `f` or an `F`:

```{python, eval=T}
print(f'This is an f-string.')
print(F'This is an f-string.')
```

Of course, you can use double or single quotes, like normal:

```{python, eval=T}
print(f"This still works.")
print(F"So does this.")
```

What do f-strings do? They allow you to print expressions inline:

```{python, eval=T}
print(f"4+4={4+4}")
```
They allow you to call functions:

```{python, eval=T}
def sum(a, b):
  return(a+b)
  
print(f"4+4={sum(4,4)}")
```

Overall, they are just a really nice feature that makes printing a pleasure. You can even write multi-line f-strings:

```{python, eval=T}
first = 'First'
second = 'Second'
multiline_string = f"First line {first}." \
                    "Second line {second}."
print(multiline_string)
```
But make sure you put an `f` before each line.

```{python, eval=T}
first = 'First'
second = 'Second'
multiline_string = f"First line {first}." \
                   f"Second line {second}."
print(multiline_string)
```

Better yet, use triple quotes with the f-string to handle multiline f-strings:

```{python, eval=T}
multiline_string = f"""First line {first}.
Second line {second}."""
print(multiline_string)
```

Of course, this is not _all_ f-strings are capable of. The "format" comes from somewhere. We can format our dates and times:

```{python, eval=T}
import datetime
dt = datetime.datetime.now()
print(f'This is the datetime: {dt: %Y/%m/%d %H:%M}')
```

As you can see, the content following the `:` is used to specify the format. For numbers, you can specify the number of decimals:

```{python, eval=T}
my_float = 444.44444445
print(f'My float: {my_float:.3f}')
print(f'My float: {my_float:.5f}')
```

Or if you desire leading zeros:

```{python, eval=T}
my_float = 444.44444445
print(f'My float: {my_float:010.3f}')
print(f'My float: {my_float:010.5f}')
print(f'My float: {my_float:10.5f}')
```

Note that the first `0` means "zero pad", and the following `10` represents the total width of the result. In this case it means zero pad until the full number takes up 10 characters (including the decimal place). You could remove the intial `0` if you want to make numbers line up neatly:

```{python, eval=T}
my_float = 444.44444445
print(f'My float: {555.55}')
print(f'My float: {22}')
print(f'My float: {1234.5}')

# vs
print("\nvs.\n")

print(f'My float: {555.55:7.02f}')
print(f'My float: {22:7.02f}')
print(f'My float: {1234.5:7.02f}')
```

#### Resources

**[RealPython f-strings](https://realpython.com/python-f-strings/#f-strings-a-new-and-improved-way-to-format-strings-in-python)**

A good walkthrough on f-strings.

## Logical operators {#p-logical-operators}

Logical operators are symbols that can be used within Python to make comparisons.

Operator | Description
---------|------------
`<`      | less than
`<=`     | less than or equal to
`>`      | greater than
`>=`     | greater than or equal to
`==`     | equal to
`!=`     | not equal to
`not x`     | negation, not x
`x or y`    | x OR y
`x and y`    | x AND y
`x is y` | x and y both point to the same objects in memory
`x == y` | x and y have the same values

It may be important to give a quick example of the difference between `==` and `is`:

```{python, eval=T}
x = -5
y = -5
print(x==y) # True
print(x is y) # True

x = 256
y = 256
print(x==y) # True
print(x is y) # True

x = 257
y = 257
print(x==y) # True
print(x is y) # False
```

This may be a surprising result for some of you. What is going on here? 

Well, Python makes an optimization where numbers between -5 and 256 (inclusive) are already declared internally. When you assign one of those pre-declared values to a variable, the variable points to the already declared object, rather than re-declaring the object. 

This is why the `is` operator is `True` for the first two numbers, and `False` for 257 -- x and y literally point to the same object when `is` results in `True` and does _not_ when `is` results in `False`.

```{python, eval=T}
x = -5
y = -5
print(x==y) # True
print(x is y) # True
print(id(x))
print(id(y))

x = 256
y = 256
print(x==y) # True
print(x is y) # True
print(id(x))
print(id(y))

x = 257
y = 257
print(x==y) # True
print(x is y) # False
print(id(x))
print(id(y))
```
There are a variety of interesting behaviors highlighted in [this](https://codeburst.io/the-unseen-pitfalls-of-python-7ca57f021d08) excellent article. It would be well worthwhile to read it.

## Lists & Tuples {#p-lists-and-tuples}

Lists and tuples are two of the primary data types in Python. 

### Indexing {#p-indexing}

Indexing in R and Python are similar, but have a couple of key differences. The first, and most apparent difference is Python is 0-indexed, whereas R is 1-indexed. What does this mean? In R, if we want the first item in a list, we do the following:

```{r}
my_list <- c("first", "second", "third", "fourth", "fifth")
my_list[1]
```

Take a look at what happens in Python:

```{python}
my_list = ["first", "second", "third", "fourth", "fifth"]
my_list[1]
```

As you can see, `my_list[1]` actually accesses the _second_ value. To access the first value, we do this:

```{python}
my_list[0]
```
When using the `:` this continues to hold. In R:

```{r}
my_list[1:2]
```

But, to achieve this in Python:

```{python}
my_list[0:2]
```
Additionally, Python can support a second `:` that defines a "jump". For example:

```{python}
my_list[0:5:2]
```

One last major difference is how negative indexes work. In R, they remove the value at the given position:

```{r, eval=T}
# remove the first and second values
my_list[c(-1, -2)]

# remove the first through third values
my_list[-1:-3]
```

In Python, negative indexes just mean "start from the back" instead of "start from the front". For example:

```{python, eval=T}
my_list[-1] # last value
my_list[-2] # second to last value
my_list[-5] # first value
```
Its important to be careful when using negative indexes as the its not necessarily intuitive as when `my_list[-5]` is the first value, we would expect `my_list[5]` to be the last value, when, in fact, it produces an IndexError because the last value is `my_list[4]`.

```{python, eval=F}
my_list[5] # causes an error!
```

### List methods {#p-list-methods}

A _method_ is a function for a particular _object_. When you hear or read _method_ just think function. A `list` is one example of an object. In Python, the most common objects like lists, dicts, tuples, sets, etc., all have extremely useful methods built right in!

The following is a table of list methods from [w3schools.com](https://www.w3schools.com/python/python_lists_methods.asp).

|Method|Description|
|------|-----------|
|append()|Adds an element at the end of the list|
|clear()|Removes all the elements from the list|
|copy()|Returns a copy of the list|
|count()|Returns the number of elements with the specified value|
|extend()|Add the elements of a list (or any iterable), to the end of the current list|
|index()|Returns the index of the first element with the specified value|
|insert()|Adds an element at the specified position|
|pop()|Removes the element at the specified position|
|remove()|Removes the item with the specified value|
|reverse()|Reverses the order of the list|
|sort()|Sorts the list|

#### Examples

Let's start by creating a couple of lists:

```{python, eval=T}
list_one = ["first", "second", "third", "Fourth", "fifth"]
list_two = ["sixth", "seventh", "eighth", "ninth"]
```

##### How do I add the string "tenth" to `list_two`?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
list_two.append("tenth")
print(list_two)
```
</details>

##### How do I remove "Fourth" from `list_one` and then add "fourth" back?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
list_one.remove("Fourth")
print(list_one)

list_one.append("fourth")
print(list_one)
```
</details>

##### How do I remove the first element, and save the value in a new variable?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
new_variable = list_one.pop(0)
print(f'The new variable: {new_variable}')
print(f'The old list: {list_one}')
```
</details>

##### How do I combine `list_one` and `list_two` into one big list?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
list_one.extend(list_two)
print(list_one)
```
</details>

### Tuple methods

The following is a table of tuple methods from [w3schools.com](https://www.w3schools.com/python/python_ref_tuple.asp).

|Method|Description|
|------|-----------|
|count()|Returns the number of times a specified value occurs in a tuple|
|index()|Searches the tuple for a specified value and returns the position of where it was found|

## Dicts {#p-dicts}

Dictionaries, commonly referred to as dicts, are used to store _key:value_ pairs. Under the hood, dicts are [hash tables (or hash maps)](https://en.wikipedia.org/wiki/Hash_table). Even with extremely large sets of data, dicts are able to _very_ quickly add, remove, and search for data on average. Dicts are able to accomplish this at the expense of space.

There are two ways to declare a dict, you can either use an empty or populated set of curly braces `{}`, or the `dict` keyword. 

```{python}
# Declaring dicts
my_dict_01 = {}
print(type(my_dict_01))

my_dict_02 = dict()
print(type(my_dict_02))

my_dict_03 = {"first_names": ["John", "Jill",], "last_names": ["Smith", "Johnson", "Chen"]}
print(type(my_dict_03))

my_dict_04 = dict(first_names=["John", "Jill",], last_names=["Smith", "Johnson", "Chen"])
print(type(my_dict_04))
```

Be careful! Dicts are not the only data type that utilizes the curly braces. The following is _not_ a dict, but rather a set.

```{python}
not_a_dict = {"John", "Jill", "Ellen",}
print(type(not_a_dict))
```
There are two primary ways to "get" information from a dict. One is to use the `get` method, the other is to use square brackets and strings.

```{python, eval=F}
my_dict = {"fruits": ["apple", "orange", "pear"], "person": "John", "vegetables": ["carrots", "peas"]}

# If "person" is indeed a key, they will function the same way
my_dict["person"]
my_dict.get("person")

# If the key does not exist, like below, they will not 
# function the same way.
my_dict.get("height") # Returns None when key doesn't exist
my_dict["height"] # Throws a KeyError exception because the key, "height" doesn't exist
```

The following is a table of dict methods from [w3schools.com](https://www.w3schools.com/python/python_ref_dictionary.asp).

|Method|Description|
|------|-----------|
|clear()|Removes all the elements from the dictionary|
|copy()|Returns a copy of the dictionary|
|fromkeys()|Returns a dictionary with the specified keys and value|
|get()|Returns the value of the specified key, or None if the key doesn't exist|
|items()|Returns a list containing a tuple for each key value pair|
|keys()|Returns a list containing the dictionary's keys|
|pop()|Removes and returns the element with the specified key|
|popitem()|Removes the last inserted key-value pair|
|setdefault()|Returns the value of the specified key. If the key does not exist: insert the key, with the specified value|
|update()|Updates the dictionary with the specified key-value pairs|
|values()|Returns a list of all the values in the dictionary|

## Sets {#p-sets}

The following is a table of set methods from [w3schools.com](https://www.w3schools.com/python/python_ref_set.asp).

|Method|Description|
|------|-----------|
|add()|Adds an element to the set|
|clear()|Removes all the elements from the set|
|copy()|Returns a copy of the set|
|difference()|Returns a set containing the difference between two or more sets|
|difference_update()|Removes the items in this set that are also included in another, specified set|
|discard()|Remove the specified item|
|intersection()|Returns a set, that is the intersection of two other sets|
|intersection_update()|Removes the items in this set that are not present in other, specified set(s)|
|isdisjoint()|Returns whether two sets have an intersection or not|
|issubset()|Returns whether another set contains this set or not|
|issuperset()|Returns whether this set contains another set or not|
|pop()|Removes an element from the set|
|remove()|Removes the specified element|
|symmetric_difference()|Returns a set with the symmetric differences of two sets|
|symmetric_difference_update()|Inserts the symmetric differences from this set and another|
|union()|Return a set containing the union of sets|
|update()|Update the set with the union of this set and others|

## Control flow {#p-control-flow}

Control flow in Python is pretty straightforward and simple. Whereas in R you may be less likely to use loops, in Python, loops are used all over the place!

### If/else statements {#p-if-else}

If/else statements work just like they do in R, but syntax is different. For example, in R we have:

```{r, eval=T}
value <- 44

if (value > 44) {
  print("Value is greater than 44.")
} else {
  print("Value is not greater than 44.")
}
```
In Python, the equivalent would be:

```{python, eval=T}
value = 44

if value > 44:
  print("Value is greater than 44.")
else:
  print("Value is not greater than 44.")
```
Very similar! On big difference is there is no need for curly braces around the if statement in Python. In addition, you do not _need_ to have parentheses around the if statement in Python. With that being said, you can:

```{python, eval=T}
value = 44

if (value > 44):
  print("Value is greater than 44.")
else:
  print("Value is not greater than 44.")
```
One important point is that _instead_ of using curly braces, Python has strict "tab" rules. The tabs are what indicate whether or not the following lines are _inside_ the if statement or not. For example:

```{python, eval=T}
if True:
  print("Inside the if statement.")
print("Not inside the if statement.")
```
As you can see, the spacing is critical. If you have nested if statements (an if statement inside an if statement), you just continue to add tabs to indicate inside which statement we are. 

```{python, eval=T}
if True:
  print("Inside the first if statement.")
  if True:
    print("Inside the second if statement.")
  print("Back inside the first if statement.")
print("Outside both if statements.")
```

Let's come back to this example:

```{python, eval=T}
value = 44

if value > 44:
  print("Value is greater than 44.")
else:
  print("Value is not greater than 44.")
```

This is a very common and repeated pattern where we declare a variable some way, and then immediately use it in an if statement. Python has something called a walrus operator `:=` (aptly named due to its appearance if you use your imagination). This operator allows you to declare variables inside of an expression:

```{python, eval=T}
if value := 44 > 44:
  print("Value is greater than 44.")
else:
  print("Value is not greater than 44.")
```

### For loops {#p-for-loops}

#### `enumerate` {#p-enumerate}

#### `break` {#p-break}

`break` is a keyword in Python that stops execution and immediately jumps out of the loop, continuing execution of code immediately following the end of the loop.

```{python}
my_list = list(range(1, 11))

# this will only print "1" as 
# the loop is immediately escaped when
# break is executed
for i in my_list:
  print(i)
  break
```

In the following example, we exit the loop once we get to number "5".

```{python}
my_list = list(range(1, 11))

for i in my_list:
  print(i)
  if i == 5:
    break
```

#### `continue` {#p-continue}

### List comprehensions {#p-list-comprehensions}

## Writing functions {#p-writing-functions}

##### Write a function called `get_filename_from_url` that, given a url to a file, like https://image.shutterstock.com/image-vector/cute-dogs-line-art-border-260nw-1079902403.jpg returns the filename _with_ the extension. {#p-functions-example-01}

<details>
    <summary>Click here for solution</summary>
```{python, eval=F}
import os
from urllib.parse import urlparse

def get_filename_from_url(url: str) -> str:
    """
    Given a link to a file, return the filename with extension.

    Args:
        url (str): The url of the file.

    Returns:
        str: A string with the filename, including the file extension.
    """
    return os.path.basename(urlparse(url).path)
```
</details>

##### Write a function that, given a url to an image, and a full path to a directory, saves the image to the provided directory. By default, have the function save the images to the user's home directory in a unix-like operating system. {#p-functions-example-02}

<details>
    <summary>Click here for solution</summary>
```{python, eval=F}
import requests
from pathlib import Path
import getpass

def scrape_image(from_url: str, to_dir: str = f'/home/{getpass.getuser()}'):
    """
    Given a url to an image, scrape the image and save the image to the provided directory.
    If no directory is provided, by default, save to the user's home directory.

    Args:
        from_url (str): U
        to_dir (str, optional): [description]. Defaults to f'/home/{getpass.getuser()}'.
    """
    resp = requests.get(from_url)
    
    # this function is from the previous example
    filename = get_filename_from_url(from_url)
    
    # Make directory if doesn't already exist
    Path(to_dir).mkdir(parents=True, exist_ok=True)
    
    file = open(f'{to_dir}/{filename}', "wb")
    file.write(resp.content)
    file.close()
```
</details>

## Reading & Writing data {#p-reading-and-writing-data}

### `read_csv` 

Please see [here](#p-pandas-read_csv).

### `csv` {#p-csv-pkg}

`csv` is a Python module that is useful for reading and writing tabular data. Much like the `read.csv` function in R, the `csv` module is useful for data that is _like_ csv but not necessarily comma-separated.

To use the `csv` module, simply import it:

```{python, eval=T}
import csv
```

#### Examples

##### How do you print each row of a csv `flights_sample.csv`?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
# my_csv_file is the variable holding the file
with open('flights_sample.csv') as my_csv_file:
    my_reader = csv.reader(my_csv_file)
    
    # each "row" here is a list where each 
    # value in the list is an element in the row
    for row in my_reader:
        print(row)
        
    # you can change the word "row" to anything you
    # would like, just make sure to change it everywhere!
    # first, we need to "reset" the file so it starts at the beginning
    my_csv_file.seek(0)
    for my_row in my_reader:
      print(my_row)
```
```{python}
# my_csv_file is the variable holding the file
with open('flights_sample.csv') as my_csv_file:
    my_reader = csv.reader(my_csv_file)
    # instead of printing a list, you can use the "join" 
    # string method to neatly format the output
    for this_row in my_reader:
      print(', '.join(this_row))
```
</details>

##### How do you print each row of a csv `grades_semi.csv`, where instead of being comma-separated, values are semi-colon-separated?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
with open('grades_semi.csv') as my_csv_file:
    my_reader = csv.reader(my_csv_file, delimiter=';')
    for row in my_reader:
        print(row)
```
</details>

## `pathlib` {#p-pathlib}

### `Path` {#p-pathlib-path}

#### Examples

##### How do I get the size of a file in bytes? Megabytes? Gigabytes?

```{python}
from pathlib import Path
p = Path("./5000_products.csv")
size_in_bytes = p.stat().st_size
print(f'Size in bytes: {size_in_bytes}')
print(f'Size in megabytes: {size_in_bytes/1000}')
print(f'Size in gigabytes: {size_in_bytes/1_000_000}')
```

## `numpy` {#p-numpy}

## `scipy` {#p-scipy}

## `pandas` {#p-pandas}

### `read_csv` {#p-pandas-read_csv}

`read_csv` is a function from the `pandas` library that allows you to read tabular data into a `pandas` DataFrame.

#### Examples

##### How do I read a csv file called `grades.csv` into a DataFrame? 

<details>
    <summary>Click here for solution</summary>
    
Note that the "." means the current working directory. So, if we were in "/home/john/projects", "./grades.csv" would be the same as "/home/john/projects/grades.csv". This is called a _relative_ path. Read [this](#dots) for a better understanding. 

```{python, eval=T}
import pandas as pd

myDF = pd.read_csv("./grades.csv")
myDF.head()
```
</details>

##### How do I read a csv file called `grades_semi.csv` where instead of being comma-separated, it is semi-colon-separated, into a DataFrame?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
import pandas as pd

myDF = pd.read_csv("./grades_semi.csv", sep=";")
myDF.head()
```
</details>

##### How do I specify the type of 1 or more columns when reading in a csv file?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
import pandas as pd

myDF = pd.read_csv("./grades.csv")
myDF.dtypes

# as you can see, year is of dtype "object"
# object dtype can hold any Python object
# we know that this column should hold strings
# so let's specify this as we read in the data
myDF = pd.read_csv("./grades.csv", dtype={"year": "string"})
myDF.dtypes

# if we wanted to specify that the "grade"
# column should be float64 instead of int64
# we could do that too
myDF = pd.read_csv("./grades.csv", dtype={"year": "string", "grade": "float64"})
myDF.dtypes

# and you can see that they are indeed floats now
myDF.head()
```
</details>

##### Given a list of csv files with the same columns, how can I read them in and combine them into a single dataframe?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
my_csv_files = ["./grades.csv", "./grades2.csv"]

data = []
for file in my_csv_files:
    myDF = pd.read_csv(file)
    data.append(myDF)
    
final_result = pd.concat(data, axis=0)
final_result
```
</details>

### DataFrame {#p-pandas-dataframe}

The DataFrame is one of the primary classes used from the `pandas` package. Much like data.frames in R, DataFrames in `pandas` store tabular, two-dimensional datasets. 

Most operations involve [reading a dataset into a DataFrame](#p-pandas-read_csv), accessing the DataFrame's attributes, and using the DataFrame's methods to perform operations on the underlying data or with other DataFrames.

#### Examples

##### How do I get the number of rows and columns of a DataFrame, `myDF`?

<details>
    <summary>Click here for solution</summary>
```{python}
import pandas as pd

myDF = pd.read_csv("./flights_sample.csv")

# returns a tuple where the first value is the number of rows
# and the second value is the number of columns
myDF.shape 

# number of rows
myDF.shape[0]

# number of columns
myDF.shape[1]
```
</details>

##### How do I get the column names of a DataFrame, `myDF`?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
import pandas as pd

myDF = pd.read_csv("./flights_sample.csv")
myDF.columns
```
</details>

##### How do I change the name of a column "Year" to "year"?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
import pandas as pd

myDF = pd.read_csv("./flights_sample.csv")

# You must set myDF equal to the result
# otherwise, myDF will remain unchanged
myDF = myDF.rename(columns={"Year": "year"})

# Alternatively, you can use the inplace
# argument to make the change directly 
# to myDF
myDF.rename(columns={"year": "YEAR"}, inplace=True)

# As you can see, since we used inplace=True
# the change has been made to myDF without
# setting myDF equal to the result of our 
# operation
myDF.columns
```
</details>

##### How do I display the first _n_ rows of a DataFrame?

<details>
    <summary>Click here for solution</summary>
```{python, eval=F}
import pandas as pd

myDF = pd.read_csv("./flights_sample.csv")

# By default, this returns 5 rows
myDF.head()

# Use the "n" parameter to return a different number of rows
myDF.head(n=10)
```
</details>

##### How can I convert a list of dicts to a DataFrame?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
list_of_dicts = []
list_of_dicts.append({'columnA': 1, 'columnB': 2})
list_of_dicts.append({'columnB': 4, 'columnA': 1}) 

myDF = pd.DataFrame(list_of_dicts)
myDF.head()
```
</details>

#### Resources

**[DataFrame Reference](https://pandas.pydata.org/docs/reference/frame.html)**

A list of DataFrame attributes and methods, with links to detailed docs.

### Series {#p-pandas-series}

#### Resources

**[10 minute intro to pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)**

A great introduction to `pandas`. Very quick.

## Jupyter notebooks {#p-jupyter-notebooks}

## Writing scripts {#p-writing-scripts}

### `argparse` {#p-argparse}

## Scraping {#p-scraping}

Web scraping is the process of programmatically scraping or downloading web content online and processing it into the desired format. It can roughly be broken into two steps:

1. Scraping: The process of copying content from online. Typically the scraped content is HTML, but it can vary. Both the `requests` package and `selenium` package have the capability of scraping data. 
2. Parsing: The process of programmatically extracting the desired information from the scraped content. [Xpath expressions](#xml-xpath), css selectors, and packages like `beautifulsoup4` are particularly useful for this task. `lxml`, `selenium`, and `beautifulsoup4` are all excellent packages to parse scraped content.

With `lxml` and `selenium` we can use xpath expressions to locate the information we want. With that being said, that information is often returned in a Python class with some sort of name like Element (representing an HTML element). Learning how to access the information is important. The following is an example that strives to demonstrate how to: 

1. Access the raw HTML of an element in `lxml`, `selenium`, and `beautifulsoup4`.
2. Access attributes of an element in `lxml`, `selenium`, and `beautifulsoup4`.
3. Access the values (the text between tags) of an element in `lxml`, `selenium`, and `beautifulsoup4`.
4. Access the tag name of an element in `lxml`, `selenium`, and `beautifulsoup4`.

First, let's setup the the tools to each be at the same stage -- with an element ready to go.

```{python, eval=F}
# SELENIUM SETUP
from selenium import webdriver
from selenium.webdriver.firefox.options import Options

firefox_options = Options()
firefox_options.add_argument("window-size=1920,1080")
# Headless mode means no GUI
firefox_options.add_argument("--headless")
firefox_options.add_argument("start-maximized")
firefox_options.add_argument("disable-infobars")
firefox_options.add_argument("--disable-extensions")
firefox_options.add_argument("--no-sandbox")
firefox_options.add_argument("--disable-dev-shm-usage")

# Set the location of the executable Firefox program on Scholar
firefox_options.binary_location = '/class/datamine/apps/firefox/firefox'

# Set the location of the executable geckodriver program on Scholar
driver = webdriver.Firefox(options=firefox_options, executable_path='/class/datamine/apps/geckodriver')
driver.get("https://datamine.purdue.edu")

# LXML SETUP
import requests
import lxml.html

# note that without this header, a website may give you a puzzle to solve
my_headers = {'User-Agent': 'Mozilla/5.0'}

# scrape the webpage
response = requests.get("https://datamine.purdue.edu", headers=my_headers)

# load the webpage into an lxml tree
tree = lxml.html.fromstring(response.text)

# BEAUTIFULSOUP4 SETUP
from bs4 import BeautifulSoup as bsoup

my_headers = {'User-Agent': 'Mozilla/5.0'}
html = requests.get('https://datamine.purdue.edu', headers=my_headers)
soup = bsoup(html.text)
```

At this point in time, when you see us using the `soup` object, we are using `beautifulsoup4`. When you see us using the `tree` object, we are using `lxml`. When you see us using the `driver` object, we are using `selenium`.

Scrape the entire webpage:

```{python, eval=F}
print(soup)

import lxml.html
print(lxml.html.tostring(tree))

print(driver.page_source)
```

Get and print the hero on https://datamine.purdue.edu:

````
<section class="office__hero">
  <h2>The Data Mine</h2>
  <p>Advancing data science for undergraduates through collaboration, learning, research, innovation, and entrepreneurship.
  <b>Open to all undergraduates!</b></p>
</section>
````

```{python, eval=F}
soup_element = soup.find('section', attrs={'class': 'office__hero'})
# or
soup_element = soup.find('section', class_='office__hero')
print(soup_element)

lxml_element = tree.xpath("//section[@class='office__hero']")[0]
print(lxml.html.tostring(lxml_element))

selenium_element = driver.find_element_by_xpath("//section[@class='office__hero']")
print(selenium_element.get_attribute("outerHTML"))
```

Get the tag of our elements:

```{python, eval=F}
print(soup_element.name)

print(lxml_element.tag)

print(selenium_element.tag_name)
```

Get the "class" attribute of our elements:

```{python, eval=F}
print(soup_element.attrs.get("class")[0])

print(lxml_element.attrib.get("class"))

print(selenium_element.get_attribute("class"))
```

Get and print the nested `h2` element:

```{python, eval=F}
nested_soup_element = soup_element.find('h2')
print(nested_soup_element)

nested_lxml_element = lxml_element.xpath("h2")[0]
print(lxml.html.tostring(nested_lxml_element))

nested_selenium_element = selenium_element.find_element_by_xpath("//h2")
print(nested_selenium_element.get_attribute("outerHTML"))
```

Get the contents or values of the nested element:

```{python, eval=F}
print(nested_soup_element.text)

print(nested_lxml_element.text)

print(nested_selenium_element.text)
```

### `requests`

`requests` is a Python package used to make web requests over HTTP. 

To summarize, HTTP is a protocol for communication between servers and clients. An example of a server would be a fancy computer running in an Amazon AWS warehouse. An example of a client would be your laptop when you are web surfing!

HTTP has _requests_ and _responses_. A client (your browser, for example), sends a _request_ to a server. The server then returns a _response_ to the client. 

HTTP has the following methods: GET, POST, PUT, HEAD, DELETE, PATCH, and OPTIONS. You can read more about those [here](https://www.w3schools.com/tags/ref_httpmethods.asp). The important thing is to realize that the `requests` package enables you to easily "use" these methods in Python. For example, the GET method is used to get data from a server:

```{python, eval=T}
import requests
response = requests.get("https://datamine.purdue.edu/")
print(response)
```

For simpler tasks, using `requests` to scrape the data, and a package like `lxml` or `beautifulsoup4` to parse the data, is appropriate.

#### Examples

##### How do I scrape the HTML from https://datamine.purdue.edu/?

<details>
    <summary>Click here for solution</summary>
```{python, eval=T}
response = requests.get("https://datamine.purdue.edu/")
print(response.text[:500])
```
</details>

#### Resources

**[Official documentation](https://requests.readthedocs.io/en/master/)**

The official documentation for the `requests` library.

### `lxml` 

[`lxml`](https://lxml.de/) is a package used for processing XML in Python. See [here](#p-lxml)

### `selenium`

`selenium` is an extremely powerful browser automation tool with official wrappers in Ruby, Java, Python, C#, Javascript. It is a tool that is used extensively in industry, and definitely worth while learning the basics. 

For most websites, the tool combination of `requests` and `lxml` or `beautifulsoup4` will be more than adequate, and easier to jump right in. Where `selenium` really shines is the ability to interact with the browser before, during, and after scraping and parsing data. Many websites use javascript to load various pieces of HTML as the user interacts with the browser. For example, if you browse on https://pinterest.com, you will find that if you scroll very quickly, images will take a second or so to completely load. If you were to scrape these web pages with a tool like `requests`, the content you would be scraping would just be the content that was loaded in the original state. In the case of pinterest, this would mean that the _other_ 20 pictures you wanted to scrape wouldn't be present within the scraped content.

To get by this limitation, we can use `selenium` to emulate a human browsing the web page. We can make the program "scroll down" _before_ scraping the web page, so the pictures would all be present.

Other examples that could change the web page's state, hence changing the content we scrape could be: clicking on filters, using a search bar, hovering, etc.

One other major way `selenium` differs from the other tools mentioned is the ability to interact with the browser, scrape, _and_ parse the data. It can do it all.

Unfortunately `selenium` requires more setup than other packages. To get started with selenium you must first choose a browser: Firefox, Chrome, or Safari. In addition to your chosen browser, you will need an accompanying web driver. For Firefox, the web driver is [geckodriver](https://github.com/mozilla/geckodriver/releases). For Chrome, the web driver is [ChromeDriver](https://github.com/mozilla/geckodriver/releases), and for Safari you need to [enable SafariDriver](https://www.browserstack.com/guide/run-selenium-tests-on-safari-using-safaridriver). For simplicity, we will demonstrate with Firefox and geckodriver on Scholar. 
Here are some sane configurations pre-made for you. We already have compatible Firefox and geckodriver versions available on Scholar. Note that if you were to comment out the `--headless` option, Firefox would literally launch and you could watch your program in action as it is being executed. If you wrote a program to scrape images off of a website, you'd be able to see the images load and the browser slowly scroll. Note that you would need to log in via ThinLinc to do this. By enabling headless mode, you prevent this, and just need to imagine how you would interact with a given web page. Feel free to copy and paste this code in your work.

```{python, eval=F}
from selenium import webdriver
from selenium.webdriver.firefox.options import Options

firefox_options = Options()
firefox_options.add_argument("window-size=1920,1080")
# Headless mode means no GUI
firefox_options.add_argument("--headless")
firefox_options.add_argument("start-maximized")
firefox_options.add_argument("disable-infobars")
firefox_options.add_argument("--disable-extensions")
firefox_options.add_argument("--no-sandbox")
firefox_options.add_argument("--disable-dev-shm-usage")

# Set the location of the executable Firefox program on Scholar
firefox_options.binary_location = '/class/datamine/apps/firefox/firefox'

# Set the location of the executable geckodriver program on Scholar
driver = webdriver.Firefox(options=firefox_options, executable_path='/class/datamine/apps/geckodriver')
```

#### Examples

##### How do I scrape a website using `selenium`?

<details>
    <summary>Click here for solution</summary>
```{python, eval=F}
driver = webdriver.Firefox(options=firefox_options, executable_path='/class/datamine/apps/geckodriver')
driver.get("https://datamine.purdue.edu")
print(driver.page_source[:500])
```
</details>

##### How do I scrape the office "hero" on https://datamine.purdue.edu, with all of its contents?

<details>
    <summary>Click here for solution</summary>
```{python, eval=F}
driver = webdriver.Firefox(options=firefox_options, executable_path='/class/datamine/apps/geckodriver')
driver.get("https://datamine.purdue.edu")
my_element = driver.find_element_by_xpath("//section[@class='office__hero']")
print(my_element.get_attribute("outerHTML"))
```
</details>

##### How do I scrape the office "hero" on https://datamine.purdue.edu, with all of its contents, but _without_ the outermost HTML?

<details>
    <summary>Click here for solution</summary>
```{python, eval=F}
driver = webdriver.Firefox(options=firefox_options, executable_path='/class/datamine/apps/geckodriver')
driver.get("https://datamine.purdue.edu")
my_element = driver.find_element_by_xpath("//section[@class='office__hero']")
print(my_element.get_attribute("innerHTML"))
```
</details>

##### How do I scrape Shutterstock images of dogs from https://www.shutterstock.com/search/dog+side+view?

<details>
    <summary>Click here for solution</summary>
    
Start by opening your favorite browser and inspecting the HTML. Open the webpage https://www.shutterstock.com/search/dog+side+view, and right click on an image and select "Inspect Element". 

![]()

This should open a help menu towards the bottom of the browser that let's you examine the HTML. You can see that the `img` tag contains all of the information we want. Specifically, look at the link in the `src` attribute: https://image.shutterstock.com/image-photo/young-labrador-retriever-4-months-260nw-97138889.jpg. We need to write a function to scrape an image given a link like that. In addition, we first need to figure out how to extract these image links from the rest of the page. 

It looks like the class attribute is not going to be of much value as it looks like a bunch of random numbers and letters. With that being said, it looks like the `data-automation` class _could_ be useful. What if we try to extract all elements where `data-automation` is equal to `mosaic-grid-cell-image`? Let's find out. 

First, let's scrape the entire page using [requests](#p-requests):

```{python, eval=F}
import requests

response = requests.get('https://www.shutterstock.com/search/dog+side+view')
print(response.text[:500])
```

Hmm, the HTML looks like it _might_ be missing what we want. Let's find out for sure using lxml:

```{python, eval=F}
import lxml.html

tree = lxml.html.fromstring(response.text)
elements = tree.xpath("//img[@data-automation='mosaic-grid-cell-image']")
print(len(elements))
```

Actually it looks like we found ~100 elements, great! If we had received a 406 error or some HTML that indicated we were being seen as a robot, we would try adding a header that makes our requests look like they come from a Firefox browser, like this:

```{python, eval=F}
my_headers = {'User-Agent': 'Mozilla/5.0'}
html = requests.get('https://www.shutterstock.com/search/dog+side+view', headers=my_headers)
```

Great, let's continue. We want to get the `src` attribute from each element, because those links contain the paths to the images we want to scrape:

```{python, eval=F}
for element in elements:
    print(element.attrib.get("src"))
```

Unfortunately, something has gone wrong. Only the first 20 or so image links have been scraped! What is going on here? This is a classic case of a website lazy loading images. What this means is the browser is waiting to fully render the images on the page until the user has the content (images) on the screen. In fact, if you load up shutterstock and then rapidly begin to scroll down, you will notice a lag where images don't load until after a few fractions of a second. 

`requests` doesn't have the capability of scraping more images from this website -- at least not easily. This is a job better suited for `selenium` as `selenium` can completely emulate human interaction with the browser. What I mean is, what if we have `selenium` load the page up, scroll a little bit, pause, scroll a bit more, pause, and _then_ try scraping the content from the web page? Would this fix our issue? Let's find out. First, perform the "setup" steps outlined [here](#p-selenium):

**Important note:** These settings will work on Scholar. In order to do the same on your own computer you will have to install compatible binaries for Firefox and geckodriver, and modify the paths in the code below accordingly.

```{python, eval=F}
from selenium import webdriver
from selenium.webdriver.firefox.options import Options

firefox_options = Options()
firefox_options.add_argument("window-size=1920,1080")
# Headless mode means no GUI
firefox_options.add_argument("--headless")
firefox_options.add_argument("start-maximized")
firefox_options.add_argument("disable-infobars")
firefox_options.add_argument("--disable-extensions")
firefox_options.add_argument("--no-sandbox")
firefox_options.add_argument("--disable-dev-shm-usage")

# Set the location of the executable Firefox program on Scholar
firefox_options.binary_location = '/class/datamine/apps/firefox/firefox'

# Set the location of the executable geckodriver program on Scholar
driver = webdriver.Firefox(options=firefox_options, executable_path='/class/datamine/apps/geckodriver')
```

Now, let's try to scroll and see if that fixes our issues:

```{python, eval=F}
driver.get("https://www.shutterstock.com/search/dog+side+view")

# create a scroll function that emulates scrolling
import time
def scroll(driver, scroll_point):  
    driver.execute_script(f'window.scrollTo(0, {scroll_point});')
    time.sleep(5) 
    
# Needed to get the window size set right
height = driver.execute_script('return document.body.scrollHeight')
driver.set_window_size(900,height+100)

# begin scrolling a bit, 1/4 of the page at a time, maybe
scroll(driver, height/4)
scroll(driver, height*2/4)
scroll(driver, height*3/4)
scroll(driver, height)

# extract the image links
elements = driver.find_elements_by_xpath("//img[@data-automation='mosaic-grid-cell-image']")
for element in elements:
  print(element.get_attribute("src"))
```

Excellent! Worked perfectly. Okay, so the next step would be to actually follow all of those links (or crawl them) and scrape the images themselves. You can write functions to do this, or use the examples [here](#p-functions-example-01) and [here](#p-functions-example-02) to help! For convenience:

```{python, eval=F}
import os
from urllib.parse import urlparse

def get_filename_from_url(url: str) -> str:
    """
    Given a link to a file, return the filename with extension.

    Args:
        url (str): The url of the file.

    Returns:
        str: A string with the filename, including the file extension.
    """
    return os.path.basename(urlparse(url).path)
```

```{python, eval=F}
import requests
from pathlib import Path
import getpass

def scrape_image(from_url: str, to_dir: str = f'/home/{getpass.getuser()}'):
    """
    Given a url to an image, scrape the image and save the image to the provided directory.
    If no directory is provided, by default, save to the user's home directory.

    Args:
        from_url (str): U
        to_dir (str, optional): [description]. Defaults to f'/home/{getpass.getuser()}'.
    """
    resp = requests.get(from_url)
    
    # this function is from the previous example
    filename = get_filename_from_url(from_url)
    
    # Make directory if doesn't already exist
    Path(to_dir).mkdir(parents=True, exist_ok=True)
    
    file = open(f'{to_dir}/{filename}', "wb")
    file.write(resp.content)
    file.close()
```

Let's cycle through and scrape each image, now:

```{python, eval=F}
for element in elements:
    scrape_image(element.get_attribute("src"))
```


</details>

## XML {#p-xml}

XML stands for Extensible Markup Language. To read more about XML see [here](#xml).

### `lxml` {#p-lxml}

[`lxml`](https://lxml.de/) is a package used for processing XML in Python. To get started, simply import the package:

```{python, eval=T}
from lxml import etree
```

To load XML from a string, do the following:

```{python}
my_string = f"""<html>
    <head>
        <title>My Title</title>
    </head>
    <body>
        <div>
            <div class="abc123 sktoe-sldjkt dkjfg3-dlgsk">
                <div class="glkjr-slkd dkgj-0 dklfgj-00">
                    <a class="slkdg43lk dlks" href="https://example.com/123456">
                    </a>
                </div>
            </div>
            <div>
                <div class="ldskfg4">
                    <span class="slktjoe" aria-label="123 comments, 43 Retweets, 4000 likes">Love it.</span>
                </div>
            </div>
            <div data-amount="12">13</div>
        </div>
        <div>
            <div class="abc123 sktoe-sls dkjfg-dlgsk">
                <div class="glkj-slkd dkgj-0 dklfj-00">
                    <a class="slkd3lk dls" href="https://example.com/123456">
                    </a>
                </div>
            </div>
            <div>
                <div class="ldg4">
                    <span class="sktjoe" aria-label="1000 comments, 455 Retweets, 40000 likes">Love it.</span>
                </div>
            </div>
            <div data-amount="122">133</div>
        </div>
    </body>
</html>"""
tree = etree.fromstring(my_string)
```

Or, to load an XML file called `example.xml` do the following:

```{python}
tree = etree.parse("example.xml")
```

From there, you can use [xpath expressions](#xml-xpath) to parse the dataset.

#### Examples

##### How do I load a webpage I scraped using `requests` into an `lxml` tree?

<details>
    <summary>Click here for solution</summary>
```{python, eval=F}
import requests
import lxml.html

# note that without this header, a website may give you a puzzle to solve
my_headers = {'User-Agent': 'Mozilla/5.0'}

# scrape the webpage
response = requests.get("https://www.reddit.com/r/puppies/", headers=my_headers)

# load the webpage into an lxml tree
tree = lxml.html.fromstring(response.text)
```
</details>

##### How do I get the name of the root node from my `lxml` tree called `tree`?

<details>
    <summary>Click here for solution</summary>
```{python}
# remember "/" gets the node starting at the root node and "*" is a
# wildcard that means "anything"
tree.xpath("/*")[0].tag
```
</details>

##### If the root node is named "html", how do I get the name of all nested tags?

<details>
    <summary>Click here for solution</summary>
```{python}
list_of_tags = [x.tag for x in tree.xpath("/html/*")]
print(list_of_tags)

# remember, this odd syntax is just a "list comprehension". It is 
# essentially a nice short-hand way of writing a loop in Python.
# It is the exact same as:
for element in tree.xpath("/html/*"):
  print(element.tag)
```
</details>

##### How do I get the attributes of an element?

<details>
    <summary>Click here for solution</summary>
```{python}
import pandas as pd

# as you can see, this prints the attributes in a dict-like object for each div element
# in the node. 
for element in tree.xpath("//div"):
  print(element.attrib)
  
# Note, if you ever want to convert a list of dicts to a pandas dataframe
# you will need to convert to a dict.
list_of_dicts = []
for element in tree.xpath("//div"):
  list_of_dicts.append(element.attrib)

myDF = pd.DataFrame(list_of_dicts)
myDF.head() # unexpected

list_of_dicts = []
for element in tree.xpath("//div"):
  list_of_dicts.append(dict(element.attrib))

myDF = pd.DataFrame(list_of_dicts)
myDF.head() # fixed
```
</details>

##### How do I get the div elements with attribute "data-amount"?

<details>
    <summary>Click here for solution</summary>
```{python}
for element in tree.xpath("//div[@data-amount]"):
  print(element.attrib)
```
</details>

##### How do I get the div elements where data-amount is greater than 50?

<details>
    <summary>Click here for solution</summary>
```{python}
for element in tree.xpath("//div[@data-amount > 50]"):
  print(element.attrib)
```
</details>

##### How do I get the values of the span tags?

<details>
    <summary>Click here for solution</summary>
```{python}
for element in tree.xpath("//span"):
  print(element.text)
```
</details>

## Plotting {#p-plotting}

### `matplotlib` {#p-matplotlib}

#### Resources {#p-matplotlib-resources}

### `plotly` {#p-plotly}

### `plotnine` {#p-plotnine}

### `pygal` {#p-pygal}

### `seaborn` {#p-seaborn}

### `bokeh` {#p-bokeh}

## Classes {#p-classes}

### Attributes

### Methods

## `tensorflow`

## `pytorch`
