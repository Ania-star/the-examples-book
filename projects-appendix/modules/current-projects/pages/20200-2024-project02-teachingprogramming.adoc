= TDM 20200: Project 02 -- 2024

**Motivation:** Web scraping is the process of taking content off of the internet. Typically this goes hand-in-hand with parsing or processing the data. In general, scraping data from websites has always been a popular topic in The Data Mine. We will use the website of "books.toscrape.com" to practice scraping skills

**Context:** In the previous project we gently introduced XML and xpath parse a XML document. In this project, we will learn about web scraping, we will delve into scraping website data using BeautifulSoup

**Scope:** Python, web scraping, BeautifulSoup

.Learning Objectives
****
- Understand webpage structures
- Use BeautifulSoup to scrape data from web pages

****

== Readings and Resources

[NOTE]
====
- Make sure to read about, and use the template found xref:templates.adoc[here], and the important information about projects submissions xref:submissions.adoc[here].
- https://www.crummy.com/software/BeautifulSoup/bs4/doc/[This] link will provide you more information about BeautifulSoap
====

== Questions

=== Question 1 (2 points)
 
[loweralpha]
.. Please use BeautifulSoup to find and print the price of the book titled "Something More Than This" in the Romance books page

=== Question 2 (2 points)
.. In the same category of "Romance", try to find book titled "Black Dust", extract and print book details including product description, upc and availability. Take a look at the page source -- do you think clicking the book link was needed in order to scrape that data? Why or why not?

 
=== Question 3 (2 points)
 
.. Please use BeautifulSoup library to get and display all categories' names from the homepage of the website

[TIP]
====
- Parse the homepage by BeautifulSoup and select categories from the sidebar.

[source,python]
from bs4 import BeautifulSoup
====
[TIP]
====
* You can parse the page with BeautifulSoup
[source,python]
bs = BeautifulSoup(driver.page_source,'html.parser')
====
[TIP]
====
* Review the page source of the website's homepage, including categories located at the sidebar.  The BeautifulSoup "select" method is useful to get names, like this:

[source,python]
categories = [c.text.strip() for c in bs.select('.nav-list li a')]
====

=== Question 4 (2 points)

.. Please get and display a list of book objects (book titles, book price and book availability ) from the first webpage for category "Mystery".

[TIP]
====
* Review the page source, you may find one "article" tag holds one book information. You may use find_all to find all "article" tags, like

[source, python]
articles=bs.find_all("article",class_="product_pod") 
====

[TIP]
====
* You may create an object to hold the book information, like:
[source,python]
book = {
    "title":title,
    "price":price,
    "availability":availability
}
====

[TIP]
====
* You may use a loop to go through the books, like
[source,python] 
for article in articles:
    title = article.h3.a.attrs['title']
    price = article.find('p',class_='price_color').text
    availability = article.find('p',class_='instock availability').text
# create a book object with the extract information
    ....
====

[TIP]
====
* You may need a list to hold all book objects, and add all books to it, like
[source,python]
all_books=[]
...
all_books.append(book)
====
[NOTE]
====
* You may use different ways to solve the question, like use function "map" etc.  
====

=== Question 5 (2 pts)

.. Please update the code from question 3 to include books from the seconde page of the "Mystery" category

[TIP]
====
* You may need to find out the 2nd page' web link
* The pagination link "next" may provide you the next page link
====

 

Project 02 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments and output for the assignment
    ** `firstname-lastname-project02.ipynb` 
* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double check that your submission is complete, and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted, was what you _actually_ submitted.

In addition, please review our xref:projects:current-projects:submissions.adoc[submission guidelines] before submitting your project.
====