= TDM 40100: Project 12 -- 2023

**Motivation:** In general, scraping data from websites has always been a popular topic in The Data Mine. In addition, it was one of the requested topics. We will continue use "books.toscrape.com" to practice scraping skills, visualize scrapped data, use `sqlite3` to save scrapped data to database

**Context:** This is a third project focusing on web scraping combined with sqlite3

**Scope:** Python, web scraping, selenium, BeautifulSoup, sqlite3

.Learning Objectives
****
- Visualize scraped data.
- Create tables for scraped data 
****

Make sure to read about, and use the template found xref:templates.adoc[here], and the important information about projects submissions xref:submissions.adoc[here].

== Questions

=== Question 1 (2 pts)

In the previous project, you have been able to scrape data from "books.toscrape.com", let visualize your scrapped data  

.. Please visualize the books' price of music category with a bar plot, have price ranges as below 20, 20-30, above 30

[TIP] 
====
* You may need to change the price to float, like
[source, python]
prices = [float(book['price'].replace('Â£','')) for book in books]

* books is the book list from the previous project's function "get_all_books", like

books = get_all_books("Music_14")
====
[TIP]
====
* You may use sum to group prices, like
[source,python]
price_less_20 = sum(1 for price in prices if price<20)
price_20_30 = sum(1 for price in prices if 30<=price<50)
...
==== 
[TIP]
====
* You may use a bar chart, like 
[source,python]
price_counts = [price_less_20, price_20_30,price_above_30] 
labels = ["1","2","3"] 
plt.bar(labels,price_counts,color=['purple','orange','green'])
# More plt settings and display statements 
====
 
=== Question 2 (2 pts)

.. Write `CREATE TABLE` statements to create 2 tables,  `categories` table and `books` table.

[TIP]
====
Check on the website for category information, the categories table may contain following fields
- 'id' a unique identifier for each category, auto increments
- 'category' like 'poetry_23'
 
====
[TIP]
====
Check on the website for book information, the "books" table may contain following fields
- 'book_id' like `1000' in the following string for book 'a light in the attic"
- 'category' like 'poetry_23'
- 'title' like 'A Light in the Attic'
- 'price' like 51.77
- 'availability' like in stock(22 available)

====
 
[TIP]
====
Use `sqlite3` to create the tables in a database called `$HOME/onlinebooks.db`. You can do all of this from within Jupyter Lab.

[source,python]
----
%sql sqlite:///$HOME/onlinebooks.db
----

[source,python]
----
%%sql

CREATE TABLE ...
----

Run the following queries to confirm and show your table schemas.

[source, sql]
----
PRAGMA table_info(category);
----

[source, sql]
----
PRAGMA table_info(book);
----
====
 

=== Question 3 (2 pts)

.. Update the function "get_category" from project 11, after get categories information from website, populate "categories" table with those data  
.. Run a couple queries that demonstrate that the data was successfully inserted into the database.

 

=== Question 4 (2 pts)

.. Update the function "get_all_books" from project 11, after get books information from website, populate "books" table with those data   

.. Run a couple queries that demonstrate that the data was successfully inserted into the database.

[TIP]
====
Here is some skeleton code to assist.

[source,python]
----
import sqlite3

# connect to database
con = sqlite3.connect(...)
for link in tqdm(links): # this shows a progress bar for assistance

    # use link_to_blob to get the blob

    # use urlsplit to extract the zpid from the link

    # add values to a tuple for insertion into the database
    to_insert = (linkid, blob)

    # get a cursor
    cur = con.cursor()

    # insert the data into the houses table using the cursor

    # get price history data to insert
    to_insert = get_price_history(blob_to_html(blob))

    # insert id into price history data
    for val in to_insert:
        val.insert(0, linkid)

    # insert the data into the price_history table using the cursor

    # prep the tax history data in the exact same way as price history

    # if there is tax history data, insert the ids just like before

    # insert the data into the tax_history table using the cursor

    # commit the changes 
    con.commit()

# close the connection
con.close()
----
====

Project 12 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments and output for the assignment
    ** `firstname-lastname-project12.ipynb` 
* Submit files through Gradescope
====
[WARNING]
====
_Please_ make sure to double check that your submission is complete, and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted, was what you _actually_ submitted.

In addition, please review our xref:projects:current-projects:submissions.adoc[submission guidelines] before submitting your project.
====