= TDM 20200: Project 03 -- 2024

**Motivation:** Web scraping is the process of taking content off of the internet. Typically this goes hand-in-hand with parsing or processing the data. In general, scraping data from websites has always been a popular topic in The Data Mine. We will continue to use the website of "books.toscrape.com" to practice scraping skills 

**Context:** In the previous projects we gently introduced XML and XPath to parse a XML document, also introduced some basic web scraping skills using ""BeautifulSoup". In this project, we will learn some basic skills to scrap with another library "selenium"

**Scope:** Python, web scraping, BeautifulSoup, selenium

.Learning Objectives
****
- Understand webpage structures
- Use selenium to scrape data from web pages
****

== Readings and Resources

[NOTE]
====
- Make sure to read about, and use the template found xref:templates.adoc[here], and the important information about projects submissions xref:submissions.adoc[here].
- Please check out https://the-examples-book.com/programming-languages/python/selenium[This] Example book content about selenium 
====

== Questions

=== Question 1 (2 points)
 
[loweralpha]
.. Please use selenium to get and display the website's HTML source code https://books.toscrape.com[https://books.toscrape.com]
.. Review the website's HTML source code.  What is the title for that webpage?

[TIP]
====
- You may import the following libraries/ modules, it is for Firefox browser, you may need to update it for your using
[source,python]
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.firefox.service import Service
from webdriver_manager.firefox import GeckoDriverManager
from selenium.webdriver.firefox.options import Options
====
[TIP]
====
- You may refer to the following options to configure a firefox instance to run efficiently
[source,python]
firefox_options = Options()
firefox_options.add_argument("--headless")
firefox_options.add_argument("--disable-extensions")
firefox_options.add_argument("--no-sandbox")
firefox_options.add_argument("--disable-dev-shm-usage")
====
[TIP]
====
- Usually format to create a driver
[source,python]
driver = webdriver.Firefox(service=Service(GeckoDriverManager().install()),options=firefox_options)
====
 
=== Question 2 (2 points)
 
.. Please use the selenium library to get and display all categories' names from the homepage of the website.

[TIP]
====
- Similar to project 2, you will need to explore the webpage source code, find the information you need
- driver method find_elements() with By.CSS_SELECTOR argument will be useful
- You may use a for loop to iterate the categories and print only the category names
====

=== Question 3 (2 points)

.. Now, instead of only getting the names of the categories, get all of the category links from the homepage as well.

.. Update the code from question 3a to get (only) the links for books with the category of "Romance".

[TIP]
====
- Output will be like 
----
romance_url is https://books.toscrape.com/catalogue/category/books/romance_8/index.html
----
- Continue from Question 2, get additional links information. ".get_attribute('href')" method may be useful
- Use a "if" statement to compare category name with "Romance" to get "Romance" category link
====

=== Question 4 (2 points)

.. Starting from the homepage of http://books.toscrape.com. Please get all of the books from the "Romance" category.
.. Find the next pagination link from "Romance" category first webpage, and get all books from the second page of "Romance" category

[TIP]
====
- For next page link, look for an html element with a class usually like 'pager', 'pagination' or similar for a pagination, in the Romance webpage, it will be 
<div>
    <ul class="pager">
        ...
        <li class="next"><a href="page-2.html">next</a></li>
        ...
    </ul>
</div>

You will need to extract the "href" attribute of a tag 
====
[TIP]
====
- Selenium have "click()" method to allow you to dynamic click a link in a webpage
====

=== Question 5 (2 points)

.. In project 2 and Project 3 we used two different libraries "BeautifulSoup" and "Selenium" to accomplish the very similar tasks,  please briefly outline the similarities and differences between these two libraries, when you will use BeautifulSoup or Selenium and the reason.



Project 03 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments and output for the assignment
    ** `firstname-lastname-project03.ipynb` 
* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double check that your submission is complete, and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted, was what you _actually_ submitted.

In addition, please review our xref:projects:current-projects:submissions.adoc[submission guidelines] before submitting your project.
====