= TDM 20100: Project 3 -- 2023

**Motivation:** The need to search files and datasets based on the text held within is common during various parts of the data wrangling process -- after all, projects in industry will not typically provide you with a path to your dataset and call it a day. `grep` is an extremely powerful UNIX tool that allows you to search text using regular expressions. Regular expressions are a structured method for searching for specified patterns. Regular expressions can be very complicated, https://blog.cloudflare.com/details-of-the-cloudflare-outage-on-july-2-2019/[even professionals can make critical mistakes]. With that being said, learning some of the basics is an incredible tool that will come in handy regardless of the language you are working in.


[NOTE]
====
Regular expressions are not something you will be able to completely escape from. They exist in some way, shape, and form in all major programming languages. Even if you are less-interested in UNIX tools (which you shouldn't be, they can be awesome), you should definitely take the time to learn regular expressions.
====

**Context:** We've just begun to learn the basics of navigating a file system in UNIX using various terminal commands. Now we will go into more depth with one of the most useful command line tools, `grep`, and experiment with regular expressions using `grep`, R, and later on, Python.

**Scope:** `grep`, regular expression basics, utilizing regular expression tools in R and Python

.Learning Objectives
****
- Use `grep` to search for patterns within a dataset.
- Use `cut` to section off and slice up data from the command line.
- Use `wc` to count the number of lines of input.
****

Make sure to read about, and use the template found xref:templates.adoc[here], and the important information about projects submissions xref:submissions.adoc[here].

== Dataset(s)

The following questions will use the following dataset(s):

- `/anvil/projects/tdm/data/consumer_complaints/processed.csv`
- `/anvil/projects/tdm/data/fips/fips.csv`


[NOTE]
====
`grep` stands for (g)lobally search for a (r)egular (e)xpression and (p)rint matching lines. As such, to best demonstrate `grep`, we will be using it with textual data.

Let's assume for a second that we _didn't_ provide you with the location of this projects dataset, and you didn't know the name of the file either. With all of that being said, you _do_ know that it is the only dataset with the text "That's the sort of fraudy fraudulent fraud that Wells Fargo defrauds its fraud-victim customers with. Fraudulently." in it. You may use 'grep' command to search for the dataset. 

You can start in the `/anvil/projects/tdm/data` directory to reduce the amount of text being searched. In addition, use a wildcard (*) to reduce the directories we search to only directories that start with a `con` inside the `/anvil/projects/tdm/data` directory such as
[source,bash]
/anvil/projects/tdm/data/con*

Just know that you'd _eventually_ find the file without using the wildcard, but we don't want to waste your time.
====
[NOTE]
====
Use `man` to read about some of the options with `grep`. For example, you'll want to search _recursively_ through the entire contents of the directories starting with a `con` with option -R or -r.

[source, bash]

grep -Rin 'fraudy fraudulent fraud' /anvil/projects/tdm/data/con*

- R: This flag tells grep to search recursively, meaning it will traverse through the specified directory and all of its subdirectories, looking for the pattern in every file it encounters.
- i: This flag makes the search case-insensitive. So, "FRAUDY", "Fraudy", and "fraudy" would all match.
- n: With this flag, grep will also display the line numbers in the files where the matches are found.
- 'fraudy fraudulent fraud': This is the pattern grep is looking for. It will search for the exact phrase "fraudy fraudulent fraud" in files.
- /anvil/projects/tdm/data/con*: This is the path where grep should start its search. Specifically, it tells grep to look in the /anvil/projects/tdm/data/ directory and search in all files and directories starting with con.
====
[TIP]
====
When you search for this sentence in the file, make sure that you type the single quote in "That's" so that you get a regular ASCII single quote.  Otherwise, you will not find this sentence. Or, just use a unique _part_ of the sentence that will likely not exist in another file.
====

=== Question 1 (1 pt)

[upperalpha]
.. Write a `grep` command that finds the dataset, which contains text "朝阳区" in all directories that start with `air` inside the `/anvil/projects/tdm/data` directory, it will be case-insensitive, output need to display the line numbers for the text location


=== Question 2 (1.5 pts)

[upperalpha]
.. Use command 'head' to print out the first line _only_ for one of the previous example output files (/anvil/projects/tdm/data/consumer_complaints/processed.csv) 
 
+

[TIP]
====
Use command 'head' that could quickly print out the first _n_ lines of a file. A csv file typically has a header row to explain what data each column holds. 

[source, bash]

head -n numberoflines filename
====
//[arabic]
+
[start=b]

.. Print out first 5 lines of 3 columns data - 'Date Received', 'Issue' and 'Company response to consumer' from file '/anvil/projects/tdm/data/consumer_complaints/processed.csv'
+
[TIP] 
====
Use command cat to view all file contents, command 'head' to control the row and command 'cut' to select columns 

[source, bash]

cat filename | head -n rowNumbers |cut -d 'delimiter' -f field1,field2,...

====
//[arabic]
+
[start=c]
.. Print out only 4 columns 'Date Received', 'Issue','Consumer complaint narrative' and 'Company response to consumer' for the _single_ line where we heard about the "That's the sort of fraudy fraudulent fraud"

[TIP]
====
Use `cat`, `head`, `tail`, and `cut` commands to isolate the 4 columns and the _single_ line
 
You can find the exact line from the file where the "fraudy fraudulent fraud" occurs, by using the `n` option from `grep`. That will tell you the line number, which can then be used with `head` and `tail` to isolate the single line.

[source, bash]

cat filename |head -n thelinenumberoffinding |tail -n 1| cut -d "dilimiter" -f field1,field2,field3,field4
====


=== Question 3 (2 pts)

//[arabic]
[upperalpha]

.. Extract from file '/anvil/projects/tdm/data/consumer_complaints/processed.csv', use one line statement to create a _new_ dataset called `southeast.csv`, the _new_ dataset will meet the following requirments

    * it will only contains the data for the four states/city - Indiana(IN), Texas (TX), Washington DC (DC), and South Carolina(SC)
    * it will only the contain the following five columns - 'Date Received', 'Issue','Consumer complaint narrative','Company response to consumer' and 'state'
+
[TIP]
====
- Be careful you don't accidentally get lines with a word like "CAPITAL" in them (AL is the state code of Alabama and is present in the word "CAPITAL"). 
- Use '>' redirection operator to create file e.g.
[source, bash]
>'pathtofile'/southeast.csv

====
//[arabic]
[start=b]
.. Plase describe how many rows of data remain and How many megabytes is the new file

[TIP] 
====
- Use 'wc' to count rows
- Use `cut` to isolate _just_ the data we ask for. For example, _just_ print the number of rows, and _just_ print the value (in Mb) of the size of the file:

[source, bash]

cut -d 'dilimiter' -f positionofrequestedfield
====

.output like this
----
520953
----

.output not like this
----
520953 /home/x-nzhou1/southeast.csv
----

=== Question 4 (1.5 pt)

//[arabic]
[upperalpha]
.. Use grep command to get  information from the _new_ data set 'southeast.csv', the output will need to meet the following requirements

* Contain one of the following words, the search is case-insensitive : "improper", "struggling", or "incorrect" 
* Use 'head' command to limit the output to only 5 rows  

 

=== Question 5 (2 pts)

[upperalpha]
.. Use `grep` to find the narratives that contain at least one dollar amount enclosed in curly braces `{` and `}`, only output the amount between $200 -$500.  Use `head` to limit output to only the first 50 results

[TIP]
====
- Use the option `-E` to use extended regular expressions in 'grep' command. This will make your regular expressions less messy (less escaping). 
- Identify an alphanumeric with [^a-zA-Z0-9]*: This matches zero or more characters that are NOT alphanumeric (i.e., not a letter or a digit). The ^ inside the square brackets [ ] negates the character class, and the * quantifier specifies "zero or more" of the preceding element.
- Identify whitespace with \s*: Matches zero or more whitespace characters.
- Example to check number range from 100 to 200: 

[source, bash]

(1[0-9]{2}|200)\b
 
  -- \b: Represents a word boundary, ensuring that the number is not part of a larger word or number.
====

[NOTE]
====
There are instances like `{>= $1000000}` and `{ XXXX }`. The first example qualifies, but the second doesn't. Make sure the following are matched:

- {$0.00}
- { $1,000.00 }
- {>= $1000000}
- { >= $1000000 }

And that the following are _not_ matched:

- { XXX }
- {XXX}
====

[TIP]
====
Regex is hard. Try the following logic. 

. Match a "{"
. Match 0 or more of any character that isn't a-z, A-Z, or 0-9
. Match 1 or more "$"
. Match 1 or more of any character that isn't "}"
. Match "}"
====


Project 03 Assignment Checklist
====
- Code used to solve quesiton 1 to 5
- Output from running th code
- Copy thes code and outputs to a new Python File  
    * `firstname-lastname-project03.ipynb`.
- Submit files through gradescope
====

[WARNING]
====
_Please_ make sure to double check that your submission is complete, and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted, was what you _actually_ submitted.
                                                                                                                             
In addition, please review our xref:submissions.adoc[submission guidelines] before submitting your project.
====
