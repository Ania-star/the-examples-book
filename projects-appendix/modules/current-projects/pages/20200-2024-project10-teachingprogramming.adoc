= TDM 20200: Project 10 -- 2024
 
**Motivation:** Machine learning and AI are huge buzzwords in industry, in next two projects we will delve into introduction of some python machine learning related libraries like `tensorflow`, `scikit-learn` to understand basic machine learning workflow concepts.   

**Context:** The purpose of these projects is to give you exposure to machine learning tools, some basic functionality, and to show _why_ they are useful, without needing any special math or statistics background. we will try to build a model to predict the arrival delay (ArrDelay) of flights based on features like departure delay, distance of the flight, departure time, arrival time, etc. 

**Scope:** Python,tensorflow, scikit-learn

== Dataset

`/anvil/projects/tdm/data/flights/2014.csv`

== Readings and Resources

[NOTE]
====
- Make sure to read about, and use the template found xref:templates.adoc[here], and the important information about projects submissions xref:submissions.adoc[here].
- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html[Pandas read_csv]
- https://scikit-learn.org/stable/documentation.html[scikit-learn documentation]
- https://scikit-learn.org/stable/tutorial/index.html[scikit-learn tutorial]
- https://www.tensorflow.org/tutorials[tensorflow tutorial]
- https://www.youtube.com/tensorflow[youtube for tensorflow]

====

[WARNING]
====
You need to use 2 cores for your Jupyter Lab session for Project 9 this week.
====
[TIP]
====
You can use `pd.set_option('display.max_columns', None)` if you want to see all of the columns in a very wide data frame.
====

== Questions

=== Question 1 (2 points)

[loweralpha]

.. Explore the dataset columns and figure out the data types for the following specific columns, define a dictionary variable 'col_types' to hold values
+
[source, python]
----
cols = [
    'DepDelay', 'ArrDelay', 'Distance',
    'CarrierDelay', 'WeatherDelay',
    'DepTime', 'ArrTime', 'Diverted', 'AirTime'
]
----
.. For quick experimentation purpose, load only first 10,000 rows from the dataset with the specific columns  
[TIP]
====
- You may refer to - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html[pandas read_csv] to know how to read partial data
- You may define 'nrows=10000' for read_csv()
====
 
=== Question 2 (2 points)

.. import the following libraries
+
[source,python]
----
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np
import time
----

.. Now let us try to understand how to clean our data. Please check on the following example code, state how missing values of a dataset can impact a machine learning model, and the reasons we need to fill the missing values. You may edit or create your own code if needed

.. While filling numerical missing values, how can we decide the more appropriate values to fill like the median, mode, or mean?
 
[source,python]
----
for col in myDF.columns:
    if myDF[col].dtype == 'object':
        myDF[col] = myDF[col].fillna(myDF[col].mode()[0])
    else:
        myDF[col] = myDF[col].fillna(myDF[col].median())
----
 
=== Question 3 ( 2 points)

.. Now let look into how to prepare our features and labels for the machine learning model by following example code, what is the difference between features and labels?
+
[source,python]
----
# Splitting features and labels
features = myDF.drop('ArrDelay', axis=1)
labels = myDF['ArrDelay']
----
.. check on the following Example code, why we need have our data split into training and testing sets?

[source,python]
----
# Split
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)
----

=== Question 4 ( 2 points)

.. Now let us standardize our data. Check on the following example code. Please state what scaling does to the data and the reason we need it for machine learning models 
+
[source,python]
----
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)
X_test_scaled = scaler.transform(X_test).astype(np.float32)
----
.. Check on the following Example code, try to explain how TensorFlow datasets conduct model training with batch processing

[source,python]
----
train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train)).batch(16)
test_dataset = tf.data.Dataset.from_tensor_slices((X_test_scaled, y_test)).batch(16)
----

=== Question 5 (2 points)

.. Now let us we build a machine learning model, train, and evaluate it in TensorFlow. Check the following Example code, it defines a model architecture, compiles the model, trains the model on a dataset and evaluating it on a separate dataset to ensure the model's effectiveness. Please create and run the whole program from Question 1 load dataset to the end of clean up the model 
+

[source,python]
====
# Define model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1)
])

# Compile
model.compile(optimizer='adam',
              loss='mean_squared_error',
              metrics=['mean_absolute_error'])

# Train
history = model.fit(train_dataset, epochs=10, validation_data=test_dataset)
 
# Cleanup
del X_train_scaled, X_test_scaled, train_dataset, test_dataset

====
.. Please state the necessary steps involved in developing a machine learning model, from data preparation to model evaluation.
 

Project 10 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments and outputs for the assignment
    ** `firstname-lastname-project10.ipynb` 
* Python file with code and comments for the assignment
    ** `firstname-lastname-project10.py`
 
* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double check that your submission is complete, and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted, was what you _actually_ submitted.

In addition, please review our xref:projects:current-projects:submissions.adoc[submission guidelines] before submitting your project.
====