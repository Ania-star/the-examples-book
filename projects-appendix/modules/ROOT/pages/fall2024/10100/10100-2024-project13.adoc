= TDM 10100: R Project 13 -- 2024

**Motivation:** Up until the previous project, we've been hyperfocused on numbers and letters; we've learned how to handle, transform, store, and reformat data to do whatever we need. However, as important as data is, most people don't enjoy staring at spreadsheets and attempting to parse out patterns and meaning. That is why **visualization** is such a key aspect of data analysis. This project will cap our exploration of `ggplot2` by exploring new types of visuals and providing some more open-ended questions for you to test your creative and data science skills learned throughout the semester.

**Context:** A working understanding of piping, `dplyr`, and common `tidyverse` utilities will be helpful for this project. A strong understanding of the typical structure of a call to `ggplot2` will also be good for this project.

**Scope:** Data visualization, `ggplot2`, `dplyr`, `tidyverse`, R

.Learning Objectives:
****
- Learn about different types of `ggplot2` visuals
- Create visuals of different types based on problem goals
- Answer open-ended questions with visuals and analysis of your own design
****

Make sure to read about, and use the template found xref:templates.adoc[here], and the important information about project submissions xref:submissions.adoc[here].

== Dataset(s)

This project will use the following dataset(s):

- `/anvil/projects/tdm/data/youtube/*`

== Questions

=== Question 1 (2 pts)

[IMPORTANT]
====
While this is the last _content-based_ project, you will have one more graded project that is dedicated to providing feedback and advice on how to improve the course. It should be relatively quick and easy to complete, so I would recommend taking some time to be sure you get that easy 100%!
====

To cap off this semester's content, we will be learning about some interesting and unique types of visuals included in `ggplot2` and their use cases along with providing a few open-ended questions that provide you the opportunity to showcase the skills you've been developing all semester!

To start, read the data from `/anvil/projects/tdm/data/youtube/*` into a new data structure called `USvids`. We will be working with the YouTube data again this project, both because you should already be roughly familiar with it and because you will be able to contrast your work now against that of the last project's and decide which plot types you like best.

`ggplot2` comes with a huge variety of plot types to choose from, with each having its own specific use cases based on functional benefits along with providing aesthetic choices between similar plot types for added customization.

One great example of this is the **histogram**, which is one of the most common types of plots used to look at the distribution of data. Take a look at the below example, where we use a histogram to display the distribution of likes on videos in `USvids`.

[source, r]
----
# specify data to plot
ggplot(USvids, aes(y=likes)) + 
    # create histogram with 30 bins
    geom_histogram(bins=30) + 
    ggtitle("Video Like Distribution") + 
    xlab("Video Likes") + 
    ylab("Count")
----

As you can see from the above example, our distribution is _extremely_ right-tailed, with a super high frequency centered around 0 video likes. Because this obscures many of the smaller distribution patterns in the data, we may want to try and focus on important parts of the data or scale our graph in some way.

For example, we could filter our existing data and then create a histogram of likes only within the first and third quartile of our data, like so:

[source, r]
----
# filter data between Q1 and Q3
filtered_USvids <- filter(USvids, 
                          likes >= quantile(USvids$likes)["25%"],
                          likes <= quantile(USvids$likes)["75%"])

# specify data to plot
ggplot(filtered_USvids, aes(likes)) + 
    # create histogram with 30 bins
    geom_histogram(bins=50) + 
    ggtitle("Video Like Distribution; Q1-Q3") + 
    xlab("Video Likes") + 
    ylab("Count")
----

For this question, do the following:

- Create a histogram of `comment_count` in `USvids`
- Create a histogram of `comment_count` in `USvids`, filtered for data only between the first and third quartile
- In a markdown cell, compare the two distributions. How are they similar, how are they different, and why?

[IMPORTANT]
====
As always, remember to properly style and label _all_ plots that you submit for full credit.
====

.Deliverables
====
- Histogram of `comment_count`
- Histogram of `comment_count` within the IQR for `comment_count`
- 2-4 sentences comparing your two distributions and positing reasons for any similarities or differences between the two
====

=== Question 2 (2 pts)

Histograms can be useful for looking purely at the distribution of values in data, but oftentimes we want to make more complex comparisons over time to identify trends.

A great and very useful way to do this is to combine the `lubridate` functions we learned about in a previous project with `ggplot2` 's `geom_line()` plot type. 

Take a look at the below example, where we make a line plot of likes over time. Run the code, and examine the resulting visual.

[source, r]
----
ggplot(USvids, aes(x=publish_time)) +
    geom_line(aes(y=likes)) + 
    labs(title="a",
         subtitle="b",
         caption="c",
         y="Like Count")
----

As you can see, the default behavior of plotting all of our time along the same axis seems to obscure any trends, as the massive amount of likes in later years completely outweigh any of the earlier years. There are plenty of ways we could handle this, with one of which being instead plotting the _average_ amount of likes for each period of time. For example, the below code will plot the average amount of likes on a video published in a given month and year.

[source, r]
----
# create a tibble of average likes per month
avg_M_Y <- USvids %>% 
    # Create a new variable for month and year pairs
    mutate(publish_month = format(publish_time, "%m"),
           publish_year = format(publish_time, "%Y")) %>%
    # get the average for each month-year pair
    group_by(publish_month, publish_year) %>%
    summarize(avg_M_Y = mean(likes, na.rm=TRUE), .groups='drop')

# Plotting with ggplot2
avg_M_Y %>%
  ggplot(aes(x = month_year, y = avg_M_Y, group = 1)) +
  geom_line() +
  labs(x = "Month_Year", y = "Average Comment Count", title = "Average Comment Count per Month_Year") +
  theme_minimal() +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
----

Another approach could be to plot each year with its own line for easy comparison between years, like so:

[source, r]
----
# create a tibble of average likes per month
avg_M_Y <- USvids %>% 
    # Create a new variable for month and year pairs
    mutate(publish_month = format(publish_time, "%m"),
           publish_year = format(publish_time, "%Y")) %>%
    # get the average for each month-year pair
    group_by(publish_month, publish_year) %>%
    summarize(avg_M_Y = mean(likes, na.rm=TRUE), .groups='drop')

# Convert publish_month and publish_year back to Date format
avg_M_Y <- avg_M_Y %>%
  mutate(month_year = as.Date(paste(publish_year, publish_month, "01", sep = "-")))

# Plotting with ggplot2
avg_M_Y %>%
  ggplot(aes(x = publish_month, y = avg_M_Y, color = publish_year, group = publish_year)) +
  geom_line() +
  labs(x = "Month", y = "Average Comment Count", title = "Average Comment Count per Month by Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
----

As you can see, the general approach above was to first isolate the data we wanted to plot and then plot it. While there are myriad approaches to this problem, some potentially more concise, separating the data explicitly like this can make pre-processing and grouping much simpler, and we recommend you take a similar approach throughout the rest of this project.

To finish this question, create two plots as described below:

- create a `geom_line()` plot that displays average comment_count for each month, with all the years along the same axis (as in the first example)
- create a `geom_line()` plot that displays average comment_count for each month, with each year represented by a different line of a different color (as in example two) 

.Deliverables
====
- A one-line plot of average `comment_count` per month
- A line plot of average `comment_count` per month, using different lines for each year
====

=== Question 3 (2 pts)

Now that we've developed a solid approach for observing time-based patterns in our data, we are ready to build on it for further comparisons. 

Load the data from `/anvil/projects/tdm/data/youtube/CAvideos.csv` and `/anvil/projects/tdm/data/youtube/FRvideos.csv`. Using the _faceting_ that you learned about in the last project, create a line plot that compares the average comment count per month in each country. 

Each plot should be a multi-line plot, where each line is a different year in the data for that country. We'll provide some starter code that demonstrates how to quickly combine the country data below.

[source, r]
----
# Combine data from all three tibbles
combined_data <- bind_rows(
  USvids %>% mutate(country = "USA"),
  CAvids %>% mutate(country = "Canada"),
  FRvids %>% mutate(country = "France")
)

# Create a tibble of average likes per month
# EXERCISE LEFT TO THE READER

# Plotting with ggplot2, facet by country
# EXERCISE LEFT TO THE READER
----

While this may seem like a lot, it is almost entirely copy-paste from the previous question. For a reminder on exactly how faceting works, take a look back at Question 5 from Project 12 for a digestible example. Depending on how much you take from the previous question, this problem can be solved by adding only one extra line to the starter code! (Not counting any copy-pasted lines)

Finish this question off by writing a few sentences analyzing the patterns between countries. Is there anything of note?

.Deliverables
====
- A faceted line plot, for the US, France, and Canada data
- A few sentences, in a markdown cell, describing any trends or differences you see between countries.
====

=== Question 4 (2 pts)

Now that we've looked at a few examples of more complex plots available to us, its your turn to express your creativity and skill learned throughout the semester. Using a visualization of your choice from http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html[this list], create a plot that demonstrates the average number of likes, by category, videos in the `USvideos` dataset got. You may not use any plot type already covered in this project. 

You may find the following code helpful to map the numerical category IDs to their actual names, such that your plot is easier to understand.

[source, r]
----
# create dict of ID-name pairs
name_ids <- c("Film & Animation" = 1,
             "Autos and Vehicles" = 2,
            "Music" = 10,
            "Pets & Animals" = 15,
            "Sports" = 17,
            "Short Movies" = 18,
            "Travel & Events" = 19,
            "Gaming" = 20,
            "Videoblogging" = 21,
            "People & Blogs" = 22,
            "Comedy" = 23,
            "Entertainment" = 24,
            "News and Politics" = 25,
            "Howto & Style" = 26,
            "Education" = 27,
            "Science & Technology" = 28,
            "Nonprofits & Activism" = 29,
            "Movies" = 30,
            "Anime/Animation" = 31,
            "Action/Adventure" = 32,
            "Classics" = 33,
            "Comedy" = 34,
            "Documentary" = 35,
            "Drama" = 36,
            "Family" = 37,
            "Foreign" = 38,
            "Horror" = 39,
            "Sci-Fi/Fantasy" = 40,
            "Thriller" = 41,
            "Shorts" = 42,
            "Shows" = 43,
            "Trailers" = 44)

# map the dictionary to the numerical IDs present in our data
US_vids["category"] <- names(name_ids)[match(US_vids$category_id, name_ids)]
----

For full credit, ensure your plot is well-formatted and makes clear what categories had the highest and lowest average likes. Be sure to include appropriate axes labels and a legend!

.Deliverables
====
- A plot demonstrating average likes, by category, for `USvids`
====

=== Question 5 (2 pts)

To finish off this project, and the course content as a whole for the semester, we are going to provide you the opportunity to create your own question.

To receive full credit, you must think of a question about the data and then, using a plot, answer that question to the best of your abilities. Your final answer should include a markdown cell containing your created question, a `ggplot2` plot of a type that we have not used, and that you didn't use in the last question, and another markdown cell answering your question, linking the plot you created to your provided answer.

Take a look at the below for some examples of acceptable questions. Feel free to build on these, but don't just copy them and use them for your own:

- Do different countries have similar trends for popularity of videos over time?
- Which category of video has the highest comment count, on average?
- Are different categories of video published more often at specific times?

If you're really struggling to think of a question, consider using one of the above examples, but making comparisons between the different countries available to us. Take the time to develop a question that's interesting to you, and create a quality answer to it.

.Deliverables
====
- Your invented question along with its associated plot and answer.
====

== Submitting your Work

With this project complete, you've now finished all of the new course content for TDM 10100! While this may signify the end of our formal learning together _in this class_, we really hope to see you continue with The Data Mine and are so grateful for the opportunity to get to know each of you better throughout this semester. 

If you have _any_ feedback about this course, including what projects you thought were too easy/difficult, logistics you think needed improving, or anything else that comes to mind, please use Project 14 as your time to voice those thoughts and help us improve this class going forward.

Regardless, we are so grateful for the opportunity to interact with you this semester, and we hope to be able to continue to support you in your learning journey in the future. Thanks so much, and have a great winter break!

.Items to submit
====
- firstname_lastname_project13.ipynb
====

[WARNING]
====
You _must_ double check your `.ipynb` after submitting it in gradescope. A _very_ common mistake is to assume that your `.ipynb` file has been rendered properly and contains your code, markdown, and code output even though it may not. **Please** take the time to double check your work. See https://the-examples-book.com/projects/submissions[here] for instructions on how to double check this.

You **will not** receive full credit if your `.ipynb` file does not contain all of the information you expect it to, or if it does not render properly in Gradescope. Please ask a TA if you need help with this.
====