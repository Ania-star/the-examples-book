= 301 Project 03 - K-Nearest Neighbor Model Introduction II

== Project Objectives 

This project we will continue to understand foundational knowledge of the K-Nearest Neighbors (KNN) algorithm  

== Reading and Resources 

- [An Introduction to Statistical Learning](www.statlearning.com/)
- https://www.ibm.com/topics/knn[What is the k-nearest neighbors (KNN) algorithm]
== Dataset 

- `/anvil/projects/tdm/data/boston.csv`

[NOTE]
====
This dataset contains various features of houses in Boston.The target variable is the median value of owner-occupied homes.

[source, python]
----
     
import pandas as pd

my_df = pd.read_csv('/anvil/projects/tdm/data/boston.csv')

----
====

== Questions

=== Question 1 (2 points):

.. What are the mean, median, and standard deviation of the median value of owner-occupied homes (target variable)?

[NOTE]
====

After load the data, let us do Pre-process for data  

[source,python]
----
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Split the dataset into training and testing sets
X = my_df.drop('MEDV', axis=1)
y = my_df['MEDV']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
----
====

=== Question 2 (2 points)

.. Explain how standardizing the features affects the performance of the KNN model.

[NOTE]
====
Now let us select features of the data with `SelectKBest`

https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html[Here] you can get `SelectKBest` introduction

[source,python]
----
from sklearn.feature_selection import SelectKBest, f_regression

# Select the top 5 features
selector = SelectKBest(score_func=f_regression, k=5)
X_train_selected = selector.fit_transform(X_train, y_train)
X_test_selected = selector.transform(X_test)
----
====

=== Question 3 (2 points)

.. Describe how feature selection improves model performance and explain the role of the `SelectKBest` method.


[NOTE]
====

The following code are an example to do Hyperparameter Tuning 

[source, python]
----
from sklearn.model_selection import GridSearchCV

# Define the parameter grid

param_grid = {
        'n_neighbors': range(1, 21),
        'weights': ['uniform', 'distance'],
        'metric': ['euclidean', 'manhattan']
    }

# Initialize the GridSearchCV
grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')
grid_search.fit(X_train_selected, y_train)

# Get the best parameters
best_params = grid_search.best_params_
print(f'Best parameters: {best_params}')
----
====

=== Question 4 (2 points)

..  Explain the importance of choosing the right hyperparameters in KNN and how Grid Search assists in this process.

[NOTE]
====

We can do the evaluation using cross_val_score like

[source,python]
---- 

from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score

# Initialize the KNN model with the best parameters
knn_best = KNeighborsRegressor(n_neighbors=best_params['n_neighbors'],
                                   weights=best_params['weights'],
                                   metric=best_params['metric'])

# Perform cross-validation
cv_scores_best = cross_val_score(knn_best, X_train_selected, y_train, cv=5, scoring='neg_mean_squared_error')
mean_cv_mse_best = -cv_scores_best.mean()
print(f'Cross-validated MSE for the best parameters: {mean_cv_mse_best}')

# Train the optimized model on the entire training set
knn_best.fit(X_train_selected, y_train)

# Predict and evaluate on the test set
 y_pred_best = knn_best.predict(X_test_selected)
mse_best = mean_squared_error(y_test, y_pred_best)
print(f'MSE for the best parameters: {mse_best}')
----
====

=== Question 5 (2 points)

..  Discuss the significance of using cross-validation in evaluating a KNN model and interpret the cross-validated mean squared error results.


Project 03 Assignment Checklist
====

* Jupyter Lab notebook with your code, comments, and output for the assignment
    ** `firstname-lastname-project03.ipynb` 

* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double-check that your submission is complete and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted was what you _actually_ submitted.

In addition, please review our xref:projects:current-projects:submissions.adoc[submission guidelines] before submitting your project.
====
 