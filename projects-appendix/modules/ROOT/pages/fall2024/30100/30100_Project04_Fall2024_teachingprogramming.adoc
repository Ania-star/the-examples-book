= 301 Project 04 - Linear Regression 

== Project Objectives

Understand the core components of a simple linear regression model. 

Linear regression is a method that allows us to predict new values! If the model can learn enough about the patterns in the existing data, it can attempt to predict new values. 

Note that the model assumes that the predictions follow a similar specific pattern, both now and in the future. If they don't, the model won't do very well. There are other modeling techniques that handle different data patterns. 

Linear regression is also a core technique that many more advanced modeling types build off of.

== Reading and Resources

- https://www.statlearning.com/[An Introduction to Statistical Learning - 3.1]
- https://www.ibm.com/topics/linear-regression[What is Linear Regression?]

== Dataset

- '/anvil/projects/tdm/data/youtube/USvideos.csv' (Referred to as 'USvideos.csv' in some places in this project)

=== Question 1 (2 points)
 
Linear regression takes input (independent) variables and attempts to predict an output (dependent) variable. 

For example, you could use linear regression to take the number of views on a YouTube video (independent variable) and try to predict the number of likes (dependent variable) on that same video. 

First, let's load the dataset:

[source,python]
----
import pandas as pd

# Load the dataset
my_df = pd.read_csv('/anvil/projects/tdm/data/youtube/USvideos.csv')

# Display the first few rows of the dataset
print(my_df.head())
----

The following code is used to create a boxplot for the data:

[source,python]
----
import matplotlib.pyplot as plt

# Set the size
plt.figure(figsize=(8, 6))

# Boxplot for 'views'
plt.boxplot(my_df['views'], vert=True, patch_artist=True)

# Title and labels
plt.title('Boxplot - Views ')
plt.ylabel('Views')

# Show the plot
plt.show()
----
.. Please run the code above and analyze to tell what you get from plot.  

=== Question 2 (2 points)
 
We can remove outliers and clean the dataset by removing extreme values to make data cleaner. Python has a library called `scipy` that provides utilities for this purpose. 

[source,python]
----
from scipy.stats import zscore

# Remove outliers using z-score
my_df['z_scores'] = zscore(my_df['views'])
my_df = my_df[my_df['z_scores'].abs() < 3]
my_df = my_df.drop(columns=['z_scores'])
----

.. Please use Z-score to remove the outliers for the 'views' column.
.. Use your own words to explain the code you used to accomplish the task.

=== Question 3 (2 points)

After remove the outliers, we can run the code to plot the distribution to better understand the data, which has more accurate and meaningful insights

.. Please visualize the boxplot for the 'views' column after removing outliers. How does the plot differ from the original one before removing outliers?


=== Question 4 (2 points)

Scaling the data can ensure that features contribute equally to the model, improving model performance.

The following is an example code to do scaling for the 'views' column. It ensures that this variable is treated appropriately, even if its values are in the thousands, compared to other variables.

[source,python]
----
from sklearn.preprocessing import StandardScaler

# Scaling the 'views' column
scaler = StandardScaler()

# Feature and target
X = my_df[['views']]  # Independent variable (feature)
y = my_df['likes']    # Dependent variable (target)


# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the 'views' column
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
----

.. What is scaling, and why is it important in linear regression? Provide an example.

=== Question 5 (2 points)

We build a linear regression model by fitting a line to the data, which minimizes the sum of the squared differences between the observed values and the values predicted by the line. The least value of this sum is called the Least Squares Error (LSE).

The following is an example program to create a Linear Regression model:

[source,python]
----
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Load the dataset
my_df = pd.read_csv('/anvil/projects/tdm/data/youtube/USvideos.csv')

# Remove outliers using z-score
from scipy.stats import zscore
my_df['z_scores'] = zscore(my_df['views'])
my_df = my_df[my_df['z_scores'].abs() < 3]
my_df = my_df.drop(columns=['z_scores'])

# Feature and target
X = my_df[['views']]  # Independent variable (feature)
y = my_df['likes']    # Dependent variable (target)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the 'views' column
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Instantiate and fit the model
model = LinearRegression()
model.fit(X_train_scaled, y_train)

# Predict for the test set
predictions = model.predict(X_test_scaled)

# Calculate Least Squares Error (LSE) or Residual Sum of Squares (RSS)
lse = ((y_test - predictions) ** 2).sum()
print(f'Least Squares Error: {lse}')
----

.. What is Least Squares Error (LSE) of your output?
.. Please use your own words to describe how LSE is used in linear regression?  
 

Project 04 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments, and output for the assignment
    ** `firstname-lastname-project04.ipynb`

* Submit files through Gradescope
====


[WARNING]
====
_Please_ make sure to double-check that your submission is complete and contains all of your code and output before submitting. If you have a spotty internet connection, it is recommended to download your submission after submitting it to ensure what you _think_ you submitted is what you _actually_ submitted.

In addition, please review our https://the-examples-book.com/projects/submissions[submission guidelines] before submitting your project.
====