= 301 Project 04 - Linear Regression 

== Project Objectives

To understand the core components of a simple linear regression model.

== Reading and Resources

- https://www.statlearning.com/[An Introduction to Statistical Learning]
- https://www.ibm.com/topics/linear-regression[What is Linear Regression]

== Dataset

- '/anvil/projects/tdm/data/youtube/USvideos.csv' (Referred to as 'USvideos.csv' in some places in the file)



=== Question 1 (2 points)

 
Linear regression takes input (independent) variables and attempts to predict an output (dependent) variable. 

For example, taking the number of views (independent variable) and trying to predict the number of likes (dependent variable).  

First, let's load the dataset

[source,python]
----
import pandas as pd

# Load the dataset
my_df = pd.read_csv('/anvil/projects/tdm/data/youtube/USvideos.csv')

# Display the first few rows of the dataset
print(my_df.head())
----

.. What is the size of the dataset 'USvideos.csv' (How many rows and columns)?
.. Based on the explanation, identify the independent and dependent variables in the dataset.
.. Based on the initial exploration, what are the mean, median, and standard deviation of the 'likes' column (the dependent variable)?
 

=== Question 2 (2 points)

Linear regression is a method that allows us to predict new values! If the model can learn enough about the patterns in the existing data, it can attempt to predict new values. 

Note that the model assumes that the predictions follow a similar specific pattern, both now and in the future. If they don't, the model won't do very well. There are other modeling techniques that handle different data patterns. 

Linear regression is also a core technique that many more advanced modeling types build off of.
 
We can remove outliers and clean the dataset by removing extreme values to make data cleaner. Python has a library called `scipy` that provides utilities for this purpose. 

[source,python]
----
from scipy.stats import zscore

# Remove outliers using z-score
my_df['z_scores'] = zscore(my_df['views'])
my_df = my_df[my_df['z_scores'].abs() < 3]
my_df = my_df.drop(columns=['z_scores'])
----

.. Please use Z-score to remove the outliers for the 'views' column.
.. Use your own words to explain the statement you used to accomplish the task.




=== Question 3 (2 points)


The following code is used to create a boxplot for the original data:

[source,python]
----
import matplotlib.pyplot as plt

# Set the size
plt.figure(figsize=(8, 6))

# Boxplot for 'views'
plt.boxplot(my_df['views'], vert=True, patch_artist=True)

# Title and labels
plt.title('Boxplot - Views Before Removing Outliers')
plt.ylabel('Views')

# Show the plot
plt.show()
----

.. Please visualize the boxplot for the 'views' column after removing outliers. How do the plots differ?



=== Question 4 (2 points)

Scaling the data can ensure that features contribute equally to the model, improving model performance.

For example, scaling the 'views' column ensures that this variable is treated appropriately, even if its values are in the thousands, compared to other variables.

[source,python]
----
from sklearn.preprocessing import StandardScaler

# Scaling the 'views' column
scaler = StandardScaler()
my_df['views'] = scaler.fit_transform(my_df[['views']])
----

.. What is scaling, and why is it important in linear regression? Provide an example.



=== Question 5 (2 points)


We build a linear regression model by fitting a line to the data, which minimizes the sum of the squared differences between the observed values and the values predicted. The least value of this sum is called the Least Squares Error (LSE).

The following is the example program to create a Linear Regression model

[source,python]
----
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Load the dataset
my_df = pd.read_csv('/anvil/projects/tdm/data/youtube/USvideos.csv')

# Remove outliers using z-score
from scipy.stats import zscore
my_df['z_scores'] = zscore(my_df['views'])
my_df = my_df[my_df['z_scores'].abs() < 3]
my_df = my_df.drop(columns=['z_scores'])

# Feature and target
X = my_df[['views']]  # Independent variable (feature)
y = my_df['likes']    # Dependent variable (target)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the 'views' column
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Instantiate and fit the model
model = LinearRegression()
model.fit(X_train_scaled, y_train)

# Predict for the test set
predictions = model.predict(X_test_scaled)

# Calculate Least Squares Error (LSE) or Residual Sum of Squares (RSS)
lse = ((y_test - predictions) ** 2).sum()
print(f'Least Squares Error: {lse}')
----

.. What is Least Squares Error (LSE) of your output?
.. Please use your own words to describe how is LSE used in linear regression?  
 

Project 04 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments, and output for the assignment
    ** `firstname-lastname-project04.ipynb`

* Submit files through Gradescope
====


[WARNING]
====
_Please_ make sure to double-check that your submission is complete and contains all of your code and output before submitting. If you have a spotty internet connection, it is recommended to download your submission after submitting it to ensure what you _think_ you submitted is what you _actually_ submitted.

In addition, please review our https://the-examples-book.com/projects/submissions[submission guidelines] before submitting your project.
====