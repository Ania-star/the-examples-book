= 301 Project 01 - Choosing a Model

== Project Objectives

In this project, we will briefly understand different machine learning models. You do not need to understand how the models work for now but just at a high level what the differences are between those models.

- Flexibility vs. Interpretability
- Classification vs. Regression
- Prediction vs. Inference
- Supervised vs. Unsupervised Learning
- Non-parameterization with Splines

== Extra Reading and Resources

- https://the-examples-book.com/starter-guides/data-science/data-modeling/choosing-model/[DataMine Examples Book - Choosing a Model]
- https://www.statlearning.com/[An Introduction to Statistical Learning 2.1.3-2.1.5 ]

== Dataset
- `/anvil/projects/tdm/data/boston.csv`



== Questions


=== Question 1 (2 points)



Before building and training the specific models, the data will need to be understood and it must be decided which are the independent variables (features) and the dependent variables (labels). 

Then you will need to split the data into training and testing sets.

Please read https://www.geeksforgeeks.org/how-to-split-the-dataset-with-scikit-learns-train_test_split-function/[this article] to get more information on the split concepts and how to do it.

Then a scaler is useful to standardize the dataset. Please read https://medium.com/analytics-vidhya/why-scaling-is-important-in-machine-learning-aee5781d161a[this article] to learn about scaling, standardization and normalization

The following is an example of loading, splitting, and scaling the data

[source,python]
----
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

file_path = '/anvil/projects/tdm/data/boston.csv'  
my_df = pd.read_csv(file_path)

# Split the dataset into features and target variable
X = my_df.drop('MEDV', axis=1)   
y = my_df['MEDV']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"X-train pre-scaling:\n------------------------------------\n{X_train.head(1)}\n------------------------------------\n\n")
print(f"X-train post-scaling:\n------------------------------------\n{X_train_scaled[0]}\n------------------------------------")
# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


# Print X_train before and after scaling
print(f"X-train pre-scaling:\n------------------------------------\n{X_train.head(1)}\n------------------------------------\n\n")
print(f"X-train post-scaling:\n------------------------------------\n{X_train_scaled[0]}\n------------------------------------")
----
You should notice the X_train is a pandas DataFrame but X_train_scaled is a numpy array


.. Please use your own words to describe what a training dataset is, what a testing dataset is, and why we need to split the dataset.
.. Please explain what a scaler is, and what benefit a scaler can offer



=== Question 2 (2 points)

**Flexibility vs. Interpretability**

Flexible models are used for complex and unstructured datasets more effectively, but they are usually considered as "black boxes"; their outputs are not easily explainable.

Interpretable models' outputs are easily understood and provide insight into which features are responsible for the prediction.

Please read https://www.baeldung.com/cs/ml-flexible-and-inflexible-models[this article] to learn more about flexibility, inflexibility, and interpretability.  
 
.. Please describe the main difference between flexible and interpretable models in your own words.
.. Please read https://the-examples-book.com/starter-guides/data-science/data-modeling/choosing-model/flexibility-interpret[this Examples book page], and choose one model for each that are flexible or interpretable

 


=== Question 3 (2 points)


**Classification vs. Regression**

Classification is when we classify data into distinct groups such as eye color like blue or black, or animal types like dog or cat.

Classification model will put existing data into different groups.

A regression model will produce predicted future data as numeric values like income or age.

For example: Logistic regression is for binary classification. A binary classification problem is one where the output can only be one of two possible values, usually true or false, 0 or 1, etc.

In contrast, linear regression is for predicting a continuous target variable as numeric data, for example: predicting a house's price based on the house's features.


.. Describe the main difference between classification problems and regression problems in your own words.
.. Describe a situation where classification would be useful vs. regression and vice versa.
  


=== Question 4 (2 points)


**Prediction vs. Inference**

Predictive models focus on forecasting, like using historical house prices to predict future house prices.

Inferential models focus on understanding relationships, like understanding underlying factors that impact house prices.

Visit https://www.datascienceblog.net/post/commentary/inference-vs-prediction/[this link] to learn more on the comparison of prediction and inference.

 
.. Explain when you would use prediction versus inference in modeling and why, in your own words.



=== Question 5 (2 points)


**Supervised vs. Unsupervised Learning**

Supervised learning is when correct predictions are provided to the model; it allows the model to learn the mapping from inputs to the desired outputs, like using labeled data that has features and a labeled column to predict if an animal is a dog or a cat, and learning from the correct or incorrect predictions made.

Unsupervised learning does not provide model with correct predictions, instead it provides incentive for the model to grow unstructured in the right direction; it uncovers patterns or structures within the data.

Please read https://domino.ai/blog/supervised-vs-unsupervised-learning[this article], which provides more comparison of supervised and unsupervised learning.


**Parameterization vs. Non-Parameterization**

Parameterization involves assigning parameters (starting values) to develop a function.

Non-Parameterization uses the data itself to derive the function parameters instead of predefined parameters.

Please read https://www.geeksforgeeks.org/difference-between-parametric-and-non-parametric-methods/[this article] for an in-depth look at the concepts of parameterization and non-parameterization.

.. Use your own words to explain the difference between supervised and unsupervised learning with simple examples.
.. Use your own words to describe the difference between Parametric models and non-parametric models.


Project 01 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments, and output for the assignment
    ** `firstname-lastname-project01.ipynb` 

* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double-check that your submission is complete and contains all of your code and output before submitting. If you have a spotty internet connection, it is recommended to download your submission after submitting it to ensure what you _think_ you submitted is what you _actually_ submitted.

In addition, please review our https://the-examples-book.com/projects/submissions[submission guidelines] before submitting your project.
====
