= 301 Project 01- Choosing a Model 

== Project Objectives

This project we will briefly understand different machine learning models. You do not need to understand how the models work for now but just in a high level what are the differences between those models

- Flexibility vs. Interpretability
- Classification vs. Regression
- Prediction vs. Inference
- Supervised vs. Unsupervised Learning
- Non-parameterization with Splines

== Reading and Resources

- https://the-examples-book.com/starter-guides/data-science/data-modeling/choosing-model/[DataMine Examples Book-Choosing model]
- https://www.statlearning.com/[An Introduction to Statistical Learning]

== DataSet
- `/anvil/projects/tdm/data/boston.csv`

[NOTE]
====
Before building and training the specific models, the data will need to be understood and split to independent feature variables and dependant variable. You may get more information on the split concepts and how to do it from https://www.geeksforgeeks.org/how-to-split-the-dataset-with-scikit-learns-train_test_split-function/[here]. Then scaler is useful to standardize the dataset. You can get more information or concepts related to scaler from https://medium.com/analytics-vidhya/why-scaling-is-important-in-machine-learning-aee5781d161a[here]


The following is an example code

[source,python]
----
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
file_path = '/anvil/projects/tdm/data/boston.csv'  
my_df = pd.read_csv(file_path)

# Split the dataset into features and target variable
X = my_df.drop('MEDV', axis=1)   
y = my_df['MEDV']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
----
====
 

== Questions

=== Question 1 ( 2 points)

.. Please describe what is training dataset, testing dataset and why we need to split dataset 
.. Please explain what scaler is, and the reason we need to use scaler

[NOTE]
====
Flexibility vs. Interpretability

Flexible models are used for complex and unstructured datasets more effectively, but they usually be considered as "black boxes", their outputs are not easily explainable

Interpretable models' outputs are easily understood and have insight into which features are responsible for the prediction

https://www.baeldung.com/cs/ml-flexible-and-inflexible-models[Here] is an article to introduce more about flexibility, inflexibility and Interpretability  
====

=== Question 2 (2 points)
 
.. Please describe the main difference between flexible and interpretable models in your own words.

.. Please research and provide the models that typical used for Flexibility vs. used for Interpretability

[NOTE]
====
Classification vs. Regression

We classify data into distinct groups such as eye color, animal types while we use classification model 
Regression model will produce outputs like income or age

For example: Logistic regression is for binary classification. A binary classification problem is also called Binomial, which the output can only be one of two possible values, usually true or false, 0 or 1 etc.

and Linear regression is for predicting a continuous target variable, which is numeric data  
====

=== Question 3 (2 points)

.. Describe the main difference between classification problems and regression problems in your own words.
  
[NOTE]
====
Prediction vs. Inference

Prediction models focus on forecasting
Inference models focus on understanding relationships

https://www.datascienceblog.net/post/commentary/inference-vs-prediction/[This link] introduces more on the comparison of prediction and inference

====


=== Question 4 (2 points)

.. Explain when you would use prediction versus inference in modeling and the differences in your own words and why


[NOTE]
====

Supervised vs. Unsupervised Learning

Supervised learning has both input and output provided, it allows the model to learn mapping from inputs to outputs

Unsupervised learning only use input data without any labeled output, it will uncover patterns or structures within the data
 
https://domino.ai/blog/supervised-vs-unsupervised-learning[This article] provides more comparison of supervised and unsupervised
====

[NOTE]
====
Parameterization vs. Non-Parameterization

Parameterization has assigning parameters(coefficients) to develop a function

Non-Parameterization uses data itself to get the function parameters instead of predefined parameters

You can also refer to https://www.geeksforgeeks.org/difference-between-parametric-and-non-parametric-methods/[here] for the concepts of parameterization and non-parameterization
====


=== Question5 (2 points)

.. Explain the difference between supervised and unsupervised learning.
 

Project 01 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments, and output for the assignment
    ** `firstname-lastname-project01.ipynb` 

* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double-check that your submission is complete and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted was what you _actually_ submitted.

In addition, please review our xref:projects:current-projects:submissions.adoc[submission guidelines] before submitting your project.
====
