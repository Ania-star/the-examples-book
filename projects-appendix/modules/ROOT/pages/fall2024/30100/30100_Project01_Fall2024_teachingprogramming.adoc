= 301 Project 01 - Choosing a Model

== Project Objectives

In this project, we will briefly understand different machine learning models. You do not need to understand how the models work for now but just at a high level what the differences are between those models.

- Flexibility vs. Interpretability
- Classification vs. Regression
- Prediction vs. Inference
- Supervised vs. Unsupervised Learning
- Non-parameterization with Splines

== Reading and Resources

- [DataMine Examples Book - Choosing a Model](https://the-examples-book.com/starter-guides/data-science/data-modeling/choosing-model/)
- [An Introduction to Statistical Learning](https://www.statlearning.com/)

== DataSet
- `/anvil/projects/tdm/data/boston.csv`

[NOTE]
====

Before building and training the specific models, the data will need to be understood and it must be decided which are the independent feature variables and the dependent variable. 

Then you will need to split the data into training and testing sets.

You may get more information on the split concepts and how to do it from [here](https://www.geeksforgeeks.org/how-to-split-the-dataset-with-scikit-learns-train_test_split-function/). 

Then a scaler is useful to standardize the dataset. You can get more information or concepts related to scaling from [here](https://medium.com/analytics-vidhya/why-scaling-is-important-in-machine-learning-aee5781d161a).

The following is an example code:

[source,python]
----
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

file_path = '/anvil/projects/tdm/data/boston.csv'  
my_df = pd.read_csv(file_path)

# Split the dataset into features and target variable
X = my_df.drop('MEDV', axis=1)   
y = my_df['MEDV']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
----
====

== Questions

=== Question 1 (2 points)

.. Please use your own words to describe what a training dataset is, what a testing dataset is, and why we need to split the dataset.
.. Please explain what a scaler is, and the reason we need to use a scaler.

[NOTE]
====

**Flexibility vs. Interpretability**

Flexible models are used for complex and unstructured datasets more effectively, but they are usually considered as "black boxes"; their outputs are not easily explainable.

Interpretable models' outputs are easily understood and provide insight into which features are responsible for the prediction.

[Here](https://www.baeldung.com/cs/ml-flexible-and-inflexible-models) is an article to introduce more about flexibility, inflexibility, and interpretability.  
====

=== Question 2 (2 points)

.. Please describe the main difference between flexible and interpretable models in your own words.
.. Please research and provide one model that is typically used for flexibility and one model typically used for interpretability.

[NOTE]
====

**Classification vs. Regression**

We classify data into distinct groups such as eye color like blue or black, or animal types like dog or cat when we use a classification model.

A regression model will produce outputs as numeric values like income or age.

For example: Logistic regression is for binary classification. A binary classification problem is also called binomial, where the output can only be one of two possible values, usually true or false, 0 or 1, etc.

Linear regression is for predicting a continuous target variable, which is numeric data like predicting the house price based on the house's features.

====

=== Question 3 (2 points)

.. Describe the main difference between classification problems and regression problems in your own words.
  
[NOTE]
====

**Prediction vs. Inference**

Prediction models focus on forecasting, like using historical house prices to predict future house prices.

Inference models focus on understanding relationships, like understanding the factors that impact house prices.

[This link](https://www.datascienceblog.net/post/commentary/inference-vs-prediction/) introduces more on the comparison of prediction and inference.

====

=== Question 4 (2 points)

.. Explain when you would use prediction versus inference in modeling and the differences in your own words and why.

[NOTE]
====

**Supervised vs. Unsupervised Learning**

Supervised learning has both input and output provided; it allows the model to learn the mapping from inputs to outputs, like using labeled data that has features and a labeled column to predict if an animal is a dog or a cat.

Unsupervised learning only uses input data without any labeled output; it uncovers patterns or structures within the data.

[This article](https://domino.ai/blog/supervised-vs-unsupervised-learning) provides more comparison of supervised and unsupervised learning.
====

[NOTE]
====

**Parameterization vs. Non-Parameterization**

Parameterization involves assigning parameters (coefficients) to develop a function.

Non-Parameterization uses the data itself to derive the function parameters instead of predefined parameters.

You can also refer to [here](https://www.geeksforgeeks.org/difference-between-parametric-and-non-parametric-methods/) for the concepts of parameterization and non-parameterization.
====

=== Question 5 (2 points)

.. Use your own words to explain the difference between supervised and unsupervised learning with simple examples.
.. Use your own words to describe how a non-parameterization model can derive the function parameters.


Project 01 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments, and output for the assignment
    ** `firstname-lastname-project01.ipynb` 

* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double-check that your submission is complete and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted was what you _actually_ submitted.

In addition, please review our [submission guidelines](xref:projects:current-projects:submissions.adoc) before submitting your project.
====
