= 301 Project 02- K-nearest neighbor Model introduction 

== Project Objectives

This project we will go through the  following steps to train and evaluate a K-Nearest Neighbors (KNN) classifier,  

- Load and Explore the Data
- Pre-process the Data
- Train the KNN Classifier
- Evaluate the Model

== Reading and Resources

- https://www.statlearning.com/[An Introduction to Statistical Learning]

== DataSet
- `/anvil/projects/tdm/data/iris.csv`
 
[NOTE]
====
Overview of the Iris Dataset

- The Iris dataset consists of 150 samples of iris flowers, each with four features: sepal length, sepal width, petal length, and petal width. There are three classes of iris flowers: Setosa, Versicolor, and Virginica.

- Features sometime also called Xs, they are input variables used by models to make predictions
- Classes are the outputs based on the input features, refer to labels or categories that data points belong to
====

== Questions

[NOTE]
====
The first step is to Load and Explore the Data

[source,python]
----
import pandas as pd
from sklearn.datasets import load_iris

# Load the Iris dataset
iris = load_iris()
data = pd.DataFrame(data=iris.data, columns=iris.feature_names)
feature_names = iris.feature_names
data['target'] = iris.target

# Display the first few rows of the dataset
print(data.head())
----
====

=== Question 1 (2 points)

.. Based on the initial exploration, what are the mean, median, and standard deviation of the sepal length for each iris class (Setosa, Versicolor, and Virginica are represented by 0,1 and 2 in the target column correspondingly)?

[TIP]
====
- The following statement can be used to map the iris class description with numbers (0, 1, 2) with a new column 'class' created

[source, python]
----
iris_class_names = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}
data['class'] = data['target'].map(iris_class_names)
----
- Then `groupby()` will be useful to group the data 
====

[NOTE]
====
Then you will need to Pre-process the Data; Split the dataset into training and testing sets 
Training set is the data used to train the model
Testing set is when you get model, you test the performance with it

[source,python]
----
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)

----

The following code is used to standardize the data, in order to improving the model's performance.

[source,python]
----
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
----

The following provided function can be used to plot the distribution of features  

[source,python]
----
import matplotlib.pyplot as plt
feature_names = iris.feature_names
# Function to plot the distribution of features using matplotlib
def plot_distribution_matplotlib(X, title):
    plt.figure(figsize=(12, 8))
    for i in range(X.shape[1]):
        plt.subplot(2, 2, i + 1)
        plt.hist(X[:, i], bins=20, alpha=0.75, edgecolor='black')
        plt.title(f'{title} - {feature_names[i]}')
        plt.xlabel(feature_names[i])
        plt.ylabel('Frequency')
    plt.tight_layout()
    plt.show()
----
Run the function for "X_train" before and after standardizing the Features
[source,python]
plot_distribution_matplotlib(X_train, 'Original Training Data')
[source,python]
plot_distribution_matplotlib(X_train, 'Standardized Training Data')
====

=== Question 2 (2 points)
.. How does the distribution of each feature change after standardization? Provide a comparison of the distributions before and after standardization by plotting the distribution of the training data

[NOTE]
====
- The following step will be  `Initialize and Train the KNN Classifier`

- The parameter `k` in K-Nearest Neighbors (KNN) is the number of nearest neighbors, change `k` will impact the model's performance:

    - k = 1: one neighbor, it is highly flexible (low bias) but can be high variance as well.
    - k = 5: five neighbors, it is less sensitive to noise compared to k = 1 
    - k = 10: ten neighbors,it is even less sensitive with lower variance.
- However, for the small clean datasets like iris.csv, since the dataset is pretty well-separated and easy to classify, you may get all perfect accuracy for different K values

[source, python]
----
from sklearn.neighbors import KNeighborsClassifier

# Initialize the KNN classifier
knn = KNeighborsClassifier(n_neighbors=3)

# Train the classifier
knn.fit(X_train, y_train)
----
====
=== Question 3 (2 points)

.. What impact does changing the number of neighbors (k) have on the model's performance? Test k values of 1, 5, and 10, and compare their accuracies

[TIP]
====
You will need to import library for calculating the accuracy 

[source,python]
----
from sklearn.metrics import accuracy_score
# make prediction
y_pred = knn.predict(X_test)
# Calculate the accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy with k={k}: {accuracy:.4f}')
print(f"\nEvaluation for k={k}:")
print(classification_report(y_test, y_pred))
----      
====
 

[NOTE]
====
-  You may get  all perfect (1.0000) for different k values in a KNN model for iris dataset, but we can use decision boundaries to dig insights. Decision boundaries can tell how the model makes classifications and how it deals with unseen data.

- The following code can be used to visualize decision boundaries for different k values with two features of the Iris dataset:

[source,python]
----
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split

# Load the Iris dataset
iris = load_iris()
data = iris.data
target = iris.target

# Use only the first two features for visualization
X = data[:, :2]
y = target

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

def plot_decision_boundaries(X, y, k_values):
    h = .02  # step size in the mesh
    cmap_light = plt.cm.Paired  # for mesh
    cmap_bold = plt.cm.jet  # for points
    
    for k in k_values:
        knn = KNeighborsClassifier(n_neighbors=k)
        knn.fit(X, y)
        
        # Plot the decision boundary. For that, we will assign a color to each point in the mesh [x_min, x_max]x[y_min, y_max].
        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
        
        Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])
        Z = Z.reshape(xx.shape)
        
        plt.figure()
        plt.pcolormesh(xx, yy, Z, cmap=cmap_light)
        
        # Plot also the training points
        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)
        plt.title(f"Decision boundary with k={k}")
        plt.xlim(xx.min(), xx.max())
        plt.ylim(yy.min(), yy.max())
        plt.show()

# Define the k values to test
k_values = [1, 5, 10]

# Plot the decision boundaries for different k values
plot_decision_boundaries(X_train, y_train, k_values)
----
====
=== Question 4 ( 2 points)

.. How does the complexity of the decision boundary change with different K values?
 
=== Question 5 (2 points)

.. How do different k values affect the classification of new, unseen data points near the decision boundaries?

[TIP]
====
 
- Visualize the decision boundaries for different k values.
- Observe changes in classification near the boundaries.
- Consider the model's sensitivity to noise with different k values.
- Evaluate the stability of classifications as k  varies.
- Analyze the model's robustness and generalization ability.
====

 
Project 02 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments, and output for the assignment
    ** `firstname-lastname-project02.ipynb` 
* Python file with code and comments for the assignment
    ** `firstname-lastname-project02.py`
* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double-check that your submission is complete and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted was what you _actually_ submitted.

In addition, please review our xref:projects:current-projects:submissions.adoc[submission guidelines] before submitting your project.
====
 