= 301 Project 4 - Classifiers - Basics of Classification

== Project Objectives

In this project, we will learn about the basics of classification. We will explore some of the most common classifiers, and their strengths and weaknesses.


.Learning Objectives
****
- Learn about the basics of classification
- Learn classification specific terminology
- Learn how to evaluate the performance of a classifier
****

== Questions

=== Question 1 (2 points)

A classifier, as you may remember from Project 2, is a machine learning model that uses input features to classify the data. Classifiers can be used to determine if email is spam or not, or determine what kind of flower a plant is. We can split classifiers into 2 major categories: binary classification and multi-class classification.

.Deliverables
====
- How are binary and multi-class classification different?
- What is a real world example of binary classification?
- What is a real world example of multi-class classification?
====

=== Question 2 (2 points)

There are many different classification models. In this course, we will go more in depth into the K-Nearest Neighbors (KNN) model, the Decision Tree model, and the Random Forest model. Each of these models has its own strengths and weaknesses, and is better suited for different types of data. In addition to these, there are Support Vector Machines (SVM), Naive Bayes, and Neural Networks. 

We won't go into detail about these models in this project, but it is important to know that they exist and behave differently.

.Deliverables
====
- Can you name 3 other models that could be used for classification?
- Why is it important to understand the strengths and weaknesses of different classification models?
====

=== Question 3 (2 points)

There are many metrics that can be used to evaluate the performance of a classifier. Some of the most common metrics are accuracy, precision, recall, and F1 score.

Accuracy is simply the percentage of correct predictions made by the model. As we learned in Project 3, our data is split into training and testing sets. We can calculate the accuracy of our model by comparing the predicted values on the testing set to the actual values in the testing set.

Precision is a metric that tells us how many of the predictions of a certain class were actually correct. It is calculated by dividing the number of true positives by the number of true positives (number of correct predictions) plus the number of false positives (number of incorrect predictions).

Recall is a metric that tells us how many of the actual instances of a certain class were predicted correctly. It is calculated by dividing the number of true positives by the number of true positives plus the number of false negatives.

Finally, the F1 score is the harmonic mean of precision and recall. It is calculated as 2 times the product of precision and recall divided by the sum of precision and recall. This metric is useful when we want to balance precision and recall.

.Deliverables
====
- Why is accuracy not always the best metric to evaluate the performance of a classifier?
- In your own words, what is the difference between precision and recall?
====

=== Question 4 (2 points)

There are many applications of classification in the real world. One common application is in the medical field, where classifiers can be used to predict whether a patient has a certain disease based on their symptoms. Another application is in the financial industry, where classifiers can be used to predict whether a transaction is fraudulent or not.

In more recent years, classifiers have been used in the field of image recognition. For example, classifiers can be used to determine whether an image contains a cat or a dog. More advanced classifiers, such as Haar cascades, can be used to detect faces in images by looking for patterns of light and dark pixels.


.Deliverables
====
- Are there any ethical concerns associated with using classifiers in the real world? If so, what are they?
- Are there any image recognition applications that you interact with on a daily basis?
====

=== Question 5 (2 points)

Although classifiers are powerful tools, they are not without their limitations. One significant limitation is that classifiers rely heavily on the data they are trained with. If the training data is biased, incomplete, or not representative of the real world, the classifier may make incorrect predictions. 

Class imbalance is a common problem in classification, where one class has significantly more instances than another. This can lead to classifiers that are biased towards the majority class and perform poorly on the minority class. For example, if my dataset contains 99% cats and 1% dogs, a classifier may simply not have enough data to learn how to classify dogs correctly.

Feature engineering is another important aspect of classification. Feature engineering is the process of manually selecting or transforming input features in the dataset that are most relevant to the problem at hand. The more irrelevant features a classifier has to work with, the more likely it is to make incorrect predictions.

.Deliverables
====
- What are some ways to address class imbalance in a dataset?
- Why is feature engineering important in classification?
====

== Submitting your Work

.Items to submit
====
- firstname_lastname_project4.ipynb
====

[WARNING]
====
You _must_ double check your `.ipynb` after submitting it in gradescope. A _very_ common mistake is to assume that your `.ipynb` file has been rendered properly and contains your code, markdown, and code output even though it may not. **Please** take the time to double check your work. See https://the-examples-book.com/projects/submissions[here] for instructions on how to double check this.

You **will not** receive full credit if your `.ipynb` file does not contain all of the information you expect it to, or if it does not render properly in Gradescope. Please ask a TA if you need help with this.
====