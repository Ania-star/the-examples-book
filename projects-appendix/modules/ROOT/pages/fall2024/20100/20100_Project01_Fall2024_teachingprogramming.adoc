= 201 Project 01 - Data Wrangling with GNU Command Line Utilities

== Project Objectives

- Learn basic command line operations for handling CSV files
- Analyze raw data to understand it better, and learn some basic data manipulation skill

== Reading and Resources

- https://www.gnu.org/software/coreutils/manual/coreutils.html[GNU Coreutils Documentation]
- https://www.gnu.org/software/gawk/manual/gawk.html[GNU Awk User's Guide]

== Dataset

- `/anvil/projects/tdm/data/noaa/2010.csv`
- `/anvil/projects/tdm/data/surplus.txt`

== Questions  

=== Question 1 (2 points) 

Read the following documentation on the `ls`, `head` and `tail` commands:

- https://www.gnu.org/software/coreutils/manual/coreutils.html#head-invocation[head]
- https://www.gnu.org/software/coreutils/manual/coreutils.html#tail-invocation[tail]
- https://www.gnu.org/software/coreutils/manual/coreutils.html#ls-invocation[ls]

[NOTE]
====

To get basic file information and view specific rows, the following commands are useful:

- `ls` to list file details, replace the file_name with the file you want to check such as /anvil/projects/tdm/data/noaa/2010.csv to get file information

- You can use command line or at Jupyter Notebook, you need to have `%%bash` to for the commands

    - `%%` is a magic function use to run cells with bash. You can find more information about the magic functions https://www.geeksforgeeks.org/jupyter-notebook-cell-magic-functions/[here]


[source,bash]
ls -lh file_name

- `head` to display the first few lines for a file, like  

[source,bash]
head -n 20  file_name

- `tail` to display the last few lines for a file, like   

[source,bash]
tail -n 20  file_name

====

.. Use the `ls -lh ` command to view file '2010.csv' information and explain the output.
.. Use the `head`,`tail` commands and pipe (`|`) to display first 10 lines of the 2010.csv file and content from the 33rd line.

[TIP]
====

A pipeline or simple as pipe (`|` ) is used to pass the output of one command to the input of another command. Like in the following example get first 20 lines of the file 2010.csv then use it as input to the next command `tail` to get the last line of them 

[source,bash]
head -n 20 2010.csv | tail -n 1

====

=== Question 2 (2 points)

https://www.gnu.org/software/gawk/manual/gawk.html[GNU Awk User's Guide] may be helpful to learn to use `awk` command 

[NOTE]
====
- You can use `wc` to analyze file such as to count the total number of records

[source, bash]
wc -l file_name

- You can use `awk` to manipulate data and generate data information like to get and print out the number of fields in the current record 
- Refer to https://www.tutorialspoint.com/awk/awk_basic_syntax.htm[awk -F] for more `awk -F` examples

[source,bash]
awk -F, '{print NF}'
 
====

.. Please use `wc`, `awk` and pipeline to count how many records are in 2010.csv that with an ELEMENT of "TAVG" (column 3)
 
[TIP]
====
The following is a example to filter a file to only have 3rd column is "TMAX" and save the output to a file 

[source,bash]
awk -F, '$3=="TMAX"' 2010.csv > 'filter_TMAX.txt'

 
====

=== Question 3 (2 points) 

[NOTE]
====
- You can use `>` to save data to a file, the following is an syntax example

[source,bash]
awk -F, 'condition' file_name > filtered_filename

- You can use '||'  as 'or' logic
====

.. Select a value for the `column 3` from `TMAX`, `TMIN`, or `TAVG`, use `awk` command to compare and save filtered data to a file named "2010_filtered.csv"  

 
=== Question 4 (2 points)

[NOTE]
====
You can extract unique values by using combination of commands like `sort`,`uniq` etc

- `sort` can be used to sort lines of text files alphabetically

[source,bash]
sort file_name

- `uniq` can be used to remove adjacent duplicated lines

[source,bash]
uniq file_name

====

.. Use `awk`, `sort`, `uniq` and pipeline to get the unique stations which is column 1 in the file, and save the output to a file named 'stations_output.txt' 

[TIP]
====
You can get column n's content by using the following example; you will need to replace n with the real column number and file_name with the file name of your file

[source,bash]
awk -F, '{print $n}' file_name
====

=== Question 5 (2 points) 

[NOTE]
====
- `awk` action block can also include selection or repetition structures, for example we use the surplus.txt file contains following:

[cols="3,2" ]
|===
|table,| 20
|printer,|100
|bike,|10
|printer,|60
|bike,|30
|===


We want to reduce each printer by 5, we can do

[source,bash]
awk -F, '{if ($1 == "printer") $2 = $2 - 5; print}' surplus.txt

or we can do a pattern and action way like

[source,bash]
awk -F, '$1 == "printer" { $2 = $2 - 5; print }' surplus.txt
====

.. Please add 15 to each the bike number at the surplus.txt file
.. Please add 100 to each table at the surplus.txt file




Project 01 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments and output for the assignment
    ** `firstname-lastname-project01.ipynb` 

* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double check that your submission is complete, and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted, was what you _actually_ submitted.

In addition, please review our xref:projects:submissions.adoc[submission guidelines] before submitting your project.
====