= 201 Project 01 - Data Wrangling with GNU Command Line Utilities

== Project Objectives

- Learn basic command line operations for handling CSV files
- Analyze raw data to understand it better, and learn some basic data manipulation skill

== Reading and Resources

- https://www.gnu.org/software/coreutils/manual/coreutils.html[GNU Coreutils Documentation]
- https://www.gnu.org/software/gawk/manual/gawk.html[GNU Awk User's Guide]

== Dataset

- `/anvil/projects/tdm/data/noaa/2010.csv`
- `/anvil/projects/tdm/data/surplus.txt`

== Questions  

=== Question 1 (2 points) 

Read the following documentation on the `ls`, `head` and `tail` commands:

- https://www.gnu.org/software/coreutils/manual/coreutils.html#head-invocation[head]
- https://www.gnu.org/software/coreutils/manual/coreutils.html#tail-invocation[tail]
- https://www.gnu.org/software/coreutils/manual/coreutils.html#ls-invocation[ls]

[NOTE]
====

To get basic file information and view specific rows, the following commands are useful:

- `ls` to list file details, replace the file_name with the file you want to check such as /anvil/projects/tdm/data/noaa/2010.csv to get file information

- You can use command line or at Jupyter Notebook, you need to have `%%bash` to for the commands

    - `%%` is a magic function use to run cells with bash. You can find more information about the magic functions https://www.geeksforgeeks.org/jupyter-notebook-cell-magic-functions/[here]


[source,bash]
ls -lh file_name

- `head` to display the first few lines for a file, like  

[source,bash]
head -n 20  file_name

- `tail` to display the last few lines for a file, like   

[source,bash]
tail -n 20  file_name

====

.. Use the `ls -lh ` command to view file '2010.csv' information and explain the output.
.. Use the `head`,`tail` commands and pipe (`|`) to display first 10 lines of the 2010.csv file and content from the 33rd line.

[TIP]
====

A pipeline or simple as pipe (`|` ) is used to pass the output of one command to the input of another command. Like in the following example get first 20 lines of the file 2010.csv then use it as input to the next command `tail` to get the last line of them 

[source,bash]
head -n 20 2010.csv | tail -n 1

====

=== Question 2 (2 points)

[NOTE]
====

- You can use `wc` to analyze file such as to count the total number of lines

[source, bash]
wc -l file_name

- Refer to https://www.tutorialspoint.com/awk/awk_basic_syntax.htm[awk -F] for more `awk -F` examples

- You can use `awk` to manipulate data and generate data information like to get and print out the number of fields in the current record, like

[source,bash]
----
 # 'NF' refers to number of fields, the input is the output from the previous command, the first line of the file
head -n 1 '/anvil/projects/tdm/data/noaa/2010.csv'| awk -F, '{print NF}' 
----
====

.. Please use `wc`, `awk` and pipeline to count how many records are in 2010.csv that with an ELEMENT of "TAVG" ($3 refers to the 3rd field or column)
 
[TIP]
====

The following is an example to filter for only lines that have a value of "TMAX" on the 3rd column and save the output to a file 

[source,bash]
awk -F, '$3=="TMAX"' 2010.csv > 'filter_TMAX.txt'

====

=== Question 3 (2 points) 

[NOTE]
====

- You can use `>` to save data to a file, the following is a syntax example

[source,bash]
awk -F, 'condition' file_name > filtered_filename

====

.. Use `awk` to filter the 2010.csv data to only get lines whose value for the 3rd column is `TAVG`, and save filtered data to a file named "filtered_TAVG.csv"  

 
=== Question 4 (2 points)

You can extract unique values by using combination of commands like `sort`,`uniq` etc

- `sort` can be used to sort lines of text files alphabetically

[source,bash]
sort '/anvil/projects/tdm/data/noaa/2010.csv'

- `uniq` can be used to remove adjacent duplicated lines

[source,bash]
uniq '/anvil/projects/tdm/data/noaa/2010.csv'

.. Use `awk` to get the first column data from 2010.csv
+
[TIP]
====
You can get column n's content by using the following example; you will need to replace n with the real column number and file_name with the file name of your file

[source,bash]
awk -F, '{print $n}' file_name
====
.. Then pipe the output from the first part of this question to `sort`, then output pipe to `uniq` to get the unique 'stations' from 2010.csv, (the first column/field in each line is the station), save the output to a file named 'stations_output.txt'

=== Question 5 (2 points) 

[NOTE]
====

- `awk` action block can also include conditional structures, for example we use the surplus.txt file contains following:

table, 20 +
printer, 100 +
bike,10 +
printer,60 +
bike,30 + 

We want to reduce each printer by 5, we can do

[source,bash]
awk -F, '{if ($1 == "printer") $2 = $2 - 5; print}' surplus.txt

or we can do a pattern and action way like

[source,bash]
awk -F, '$1 == "printer" { $2 = $2 - 5; print }' surplus.txt
====

.. Please add 15 to each the bike number at the surplus.txt file
.. Please add 100 to each table at the surplus.txt file


Project 01 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments and output for the assignment
    ** `firstname-lastname-project01.ipynb` 

* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double-check that your submission is complete and contains all of your code and output before submitting. If you have a spotty internet connection, it is recommended to download your submission after submitting it to ensure what you _think_ you submitted is what you _actually_ submitted.

In addition, please review our https://the-examples-book.com/projects/submissions[submission guidelines] before submitting your project.
====